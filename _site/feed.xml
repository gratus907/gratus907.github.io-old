<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-09-19T03:09:55+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Gratus907’s Study Note</title><subtitle>Hello World!</subtitle><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><entry><title type="html">서울대학교 프로그래밍 대회 (SNUPC) 2021 후기 / 풀이(A-G) &amp;amp; Whining</title><link href="http://localhost:4000/cp-rounds/snupc-2021/" rel="alternate" type="text/html" title="서울대학교 프로그래밍 대회 (SNUPC) 2021 후기 / 풀이(A-G) &amp;amp; Whining" /><published>2021-09-12T00:00:00+09:00</published><updated>2021-09-12T00:00:00+09:00</updated><id>http://localhost:4000/cp-rounds/snupc-2021</id><content type="html" xml:base="http://localhost:4000/cp-rounds/snupc-2021/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#snupc&quot; id=&quot;markdown-toc-snupc&quot;&gt;SNUPC&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#phase-1--easy-problems-0분---60분&quot; id=&quot;markdown-toc-phase-1--easy-problems-0분---60분&quot;&gt;Phase 1 : Easy problems (0분 - 60분)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#a-b&quot; id=&quot;markdown-toc-a-b&quot;&gt;A, B&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#g--자연수-색칠하기&quot; id=&quot;markdown-toc-g--자연수-색칠하기&quot;&gt;G : 자연수 색칠하기&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#f--and와-or&quot; id=&quot;markdown-toc-f--and와-or&quot;&gt;F : AND와 OR&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#phase-2--spurt-60분---120분&quot; id=&quot;markdown-toc-phase-2--spurt-60분---120분&quot;&gt;Phase 2 : Spurt (60분 - 120분)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#e--뛰는-기물&quot; id=&quot;markdown-toc-e--뛰는-기물&quot;&gt;E : 뛰는 기물&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#c--실-전화기&quot; id=&quot;markdown-toc-c--실-전화기&quot;&gt;C : 실 전화기&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#d--누텔라-트리&quot; id=&quot;markdown-toc-d--누텔라-트리&quot;&gt;D : 누텔라 트리&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#phase-3--too-hard&quot; id=&quot;markdown-toc-phase-3--too-hard&quot;&gt;Phase 3 : Too hard&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#대회가-끝나고&quot; id=&quot;markdown-toc-대회가-끝나고&quot;&gt;대회가 끝나고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;9월 11일 (토)에 진행된 서울대학교 프로그래밍 경시대회 (SNUPC) 2021 Division 2에 참가해 6등 했습니다.&lt;/p&gt;

&lt;h2 id=&quot;snupc&quot;&gt;SNUPC&lt;/h2&gt;
&lt;p&gt;SNUPC는 한국에서 열리는 프로그래밍 대회 중 개인 대회로는 아마 가장 높은 난이도를 자랑하는 대회가 아닌가 싶습니다. Division 1과 2로 나누어 수행되는데, 기억에는 Division 1의 참가자 상당수가 ACM-ICPC World Final 참가자들 급의 실력을 가진 (실제 WF 무대를 경험한 사람들도 10명은 있을 겁니다) 것으로 기억합니다. 제가 참가한 Division 2는 (공식적으로는) 퍼플 이하의 참가자들을 위한 대회이기 때문에 난이도가 훨씬 덜하지만, 다른 대학 대회들과 비교하면 오히려 정상적인 수준입니다.&lt;/p&gt;

&lt;p&gt;저는 2019년에 Div2 9등 (3등상), 2020년에 7등 (3등상), 올해 6등 (3등상) 의 성적을 얻었습니다. 제 실력은 분명 조금씩 발전하고 있지만, 대회가 점점 더 고여가기 때문에 제가 내년에도 Div2 우승을 노리는 것보다는 아마 Div1에 나가지 않을까 싶습니다. SNUPC는 대학원생들도 꽤 많이 나오고, 저한테는 앞으로도 당분간은 좋은 취미일 (?) PS를 즐길수있게 해주는 좋은 대회이기 때문에 석사과정 정도까지는 토요일 하루 빼서 나와볼만 하다고 생각합니다.&lt;/p&gt;

&lt;h2 id=&quot;phase-1--easy-problems-0분---60분&quot;&gt;Phase 1 : Easy problems (0분 - 60분)&lt;/h2&gt;
&lt;h3 id=&quot;a-b&quot;&gt;A, B&lt;/h3&gt;
&lt;p&gt;A, B 두 문제는 워낙 쉬운 문제라서 딱히 commentate할 부분은 없습니다.&lt;/p&gt;

&lt;p&gt;B 퍼솔을 먹어서 기분이 좀 좋았습니다. :)&lt;/p&gt;

&lt;p&gt;C를 조금 손대 보았고, 실제로 맞는 관찰을 헀지만, 구현에서 실수가 조금 있어서 AC를 받지 못했습니다. 스코어보드를 보고 의외로 G가 쉬운 문제라고 판단하여 G로 갔습니다.&lt;/p&gt;

&lt;h3 id=&quot;g--자연수-색칠하기&quot;&gt;G : 자연수 색칠하기&lt;/h3&gt;
&lt;p&gt;서로소인 두 색을 서로 다른 색으로 색칠해야 한다는 조건이 있는데, 이 조건의 충분조건으로 다음과 같은 색칠을 생각합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;소수는 모두 서로소이므로, 소수끼리는 서로 다른 색으로 칠합니다.&lt;/li&gt;
  &lt;li&gt;소수가 아닌 수는, 무조건 가장 큰 소인수에 해당하는 색으로 칠합니다. 
이렇게 칠하면, $\pi(n) + 1$ 개의 색을 쓰게 됩니다 (1은 따로 칠해야 하므로) 소수는 모두 서로 다른 색으로 칠해야 하므로 이보다 적게 색깔을 쓰는 방법은 없습니다. 또한, 두번째 조건에 의해 서로소인 수는 소인수를 공유하지 않으므로 다른 색으로 칠하게 되어, 이 칠하는 방법이 올바릅니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;f--and와-or&quot;&gt;F : AND와 OR&lt;/h3&gt;
&lt;p&gt;두 수 $a, b$를 두 수 $c, d$로 바꾸되, 이때 $a, b$와 $c, d$는 각각 AND한 값과 OR한 값이 같아야 합니다. $N$개의 수가 주어지고, 이 수들에 대해 이 연산을 원하는 만큼 수행한 후, 곱을 최소화하는 문제입니다.&lt;br /&gt;
생각해 보면, 두 수에 모두 켜져 있는 비트는 c, d 에서도 켜져 있어야 하고, 한쪽에만 켜져 있는 비트는 한쪽에만 켜져 있어야 하고… 해서 각 비트 단위로 조건을 생각하면 $a + b = c + d$ 여야 한다는 것을 알 수 있습니다 (충분조건은 아닙니다)&lt;/p&gt;

&lt;p&gt;따라서, $N$개의 수에 대해 그 합을 바꿀 방법은 없습니다. 합을 유지하면서 곱을 최소화하는 방법은 최대한 큰 수와 최대한 작은 수로 수의 크기 갭을 벌리는 것입니다. 이를 위해, 모든 수를 OR하여 하나를 만들고, 앞으로 그 수는 건드리지 않는 방법으로 모든 수에 켜진 bit의 union에 해당하는 수를 하나 만들어서 앞으로의 연산에서 제외하는 식으로 진행하면 됩니다.&lt;/p&gt;

&lt;p&gt;이 구현은 $O(N^2)$ 이기 때문에, 더 줄여야 합니다. 특정 비트 $k$번을 생각하고, $k$번 비트가 $N$개의 수를 통틀어 몇 번 켜지는지 확인하여 구현하면 $O(30 N)$ 에 해결할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이문제까지 해결한 다음, 다시 스코어보드를 확인했는데 CDEFG가 풀린 숫자가 거기서 거기인 신기한 스코어보드를 보고 좀 당황했습니다.&lt;/p&gt;
&lt;h2 id=&quot;phase-2--spurt-60분---120분&quot;&gt;Phase 2 : Spurt (60분 - 120분)&lt;/h2&gt;
&lt;h3 id=&quot;e--뛰는-기물&quot;&gt;E : 뛰는 기물&lt;/h3&gt;
&lt;p&gt;가로와 세로로 나이트처럼 움직이되, $(m, n)$칸 움직일 수 있는 (또는 $(n, m), (-n, m)$ 등) $(m, n)$-나이트를 정의합니다. 무한한 정수 격자점 $\Z^2$를 무한히 많은 나이트 move로 커버하기 위해, 최소 몇 개의 시작점 (몇 마리의 나이트) 가 필요한지에 대한 문제입니다.&lt;/p&gt;

&lt;p&gt;어렵지 않은 관찰로 시작합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\gcd(m, n) = g &amp;gt; 1$ 이면, 전체 보드를 $g * g$ 칸 정사각형으로 분할했을 때, 같은 정사각형 안에서는 움직일 방법이 없습니다. 즉, 적어도 $g^2$ 개는 필요합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서, $m, n$이 서로소인 경우만 해결하면 됩니다.&lt;br /&gt;
여기서 추가로, $(1, 1)$ 나이트 같은 경우, $x + y$ 좌표의 홀짝성을 바꿀 수 있는 방법이 없습니다. 이는 $(3, 3)$나이트나, $(3, 5)$ 등 다른 (홀수, 홀수) 나이트도 가지고 있는 문제입니다. 이유는 $x + y$, $x - y$ 가 모두 짝수이기 때문입니다. 이를 해결하기 위해 적어도 2마리가 필요할 것입니다.&lt;/p&gt;

&lt;p&gt;그렇지 않고, $(2, 3)$ 나이트같은 경우 이 나이트가 모든 칸을 방문할 수 있음을 주장합니다. 이 증명을 엄밀하게 하는 것은 상당히 귀찮은 일이며, 풀이 슬라이드에 잘 나와 있습니다. ㅋㅋ! 저는 엄밀한 증명까지는 하지 않고, 그림을 몇개 그려 보고 대충 지그재그로 잘 움직이다가 밑으로 훅 내려오는 것을 반복하면 $(1, 0)$에 도달할 수 있다고 믿었습니다.&lt;/p&gt;

&lt;p&gt;간단히 아이디어만 소개하자면, $(m, n)$ 나이트에서 일반성을 잃지 않고 $n &amp;gt; m$ 이라고 하겠습니다. 이때 $n &amp;gt; 2m$ 인 경우, $n &amp;lt; 2m$ 인 경우를 나누어, 나이트로 잘 움직여서 $(m, n)$ 나이트가 다른 어떤 $(a, b)$ 나이트의 행동을 모두 할 수 있음을 보이고, (이때 a, b를 n, m보다 작게 줄이면서) base case로 $(1, 2)$ 나이트가 $(1, 0)$에 도달 가능함을 이용합니다.&lt;/p&gt;

&lt;p&gt;참고로, 체스를 좋아한다면 $(1, 2)$ 나이트로 엔드게임 시점에 바로 옆 칸에 가기 위해 3번의 움직임을 쓰는 상황을 calculate해본 경험이 많을 것입니다. 저는 그래서 조금 재밌었습니다. (비슷한 이치로 장기를 잘 두는 사람은 $(2, 3)$ 나이트도 추가로 머릿속에서 그려지는듯 합니다.)&lt;/p&gt;

&lt;p&gt;별개로 저는 이 문제에서 사소한 실수로 4틀했습니다. :( 페널티 싸움에서 패배해서 등수가 낮아진 매우 중요한 원인이 되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;c--실-전화기&quot;&gt;C : 실 전화기&lt;/h3&gt;
&lt;p&gt;정오각형으로 노드가 배치된 그래프를 평면에 임베딩하기 위해, 노드를 최소 몇개 움직여야 하는지 찾는 문제.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;완전그래프 $K_5$는 평면 임베딩이 불가능함이 알려져 있으며, 예제로 주어져 있습니다.&lt;/li&gt;
  &lt;li&gt;여기서 edge를 하나 빼면 평면에 올릴 수 있고, 최대 2개만 움직이면 됩니다.&lt;/li&gt;
  &lt;li&gt;노드를 1개 움직여서 가능한지 아닌지만 판정하면 되고,&lt;/li&gt;
  &lt;li&gt;노드 한개를 충분히 멀리 움직이는 것이 없애는 것과 같은 효과이므로, 하나를 없애서 나머지가 충돌하지 않는지 확인하면 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;d--누텔라-트리&quot;&gt;D : 누텔라 트리&lt;/h3&gt;
&lt;p&gt;트리에 검정색과 빨간색으로 칠해진 정점들이 있는데, 여기서 검정색에서 출발하여 빨간색들만 밟는 ‘누텔라 경로’ 가 몇 개 있는지 세는 문제입니다.&lt;/p&gt;

&lt;p&gt;빨간색에 한번 도달하면, 연결된 빨간색들 중 어디에 멈출지만 정하면 되기 때문에, 그 component에서 가능한 경우의 수는 빨간색의 개수입니다. 
이를 DSU로 미리 묶어서 처리하면 쉽게 해결 가능합니다.&lt;/p&gt;

&lt;h2 id=&quot;phase-3--too-hard&quot;&gt;Phase 3 : Too hard&lt;/h2&gt;

&lt;p&gt;7문제를 푼 순간, 제가 참가자들 중 가장 먼저 7솔브에 도달했기 떄문에 이거 Div2 우승하는거 아니냐 ㅋㅋ 라고 생각하며 잠깐 설렜습니다. 그런데 생각해보면 CDEFG의 난이도가 비슷해서 생긴 일이므로, 지금 (120분 시점) 6솔인 사람들은 시간이 주어진다면 충분히 7솔브가 가능하고, 저는 E번을 4틀하면서 페널티에서 엄청 밀렸으므로 8솔브를 해야 우승을 노릴 수 있었습니다 (그렇지 않더라도 사실 이 상황에서 저한테 달라질건 없지만요). H와 I 중 무엇을 풀지 고민하다가, H가 인터랙티브라서 I를 풀고자 시도했는데 I번에서도 뭔가 어려움이 많았습니다. $N \sqrt{N}$ 정도까지는 어떻게 잘 우기면 될거 같은데, $N = 2e6$이라서 루트도 허용하지 않는 처참한 시간제한을 보고 다시 H로 도망쳤지만 답이 없었습니다.&lt;/p&gt;

&lt;h2 id=&quot;대회가-끝나고&quot;&gt;대회가 끝나고&lt;/h2&gt;
&lt;p&gt;매년 SNUPC는 정말 많은 생각이 들게 합니다. 매년 뛰어난 사람들이 몰려오고 있고, 나는 정체된 것이 아닌가 하는 회의감부터, 그럼에도 불구하고 하나씩 풀어나갈 때 나름의 즐거움과 생각하는 과정의 즐거움은 PS를 그만둘 수 없게 하기도 합니다.&lt;/p&gt;

&lt;p&gt;내년에는 Div1에 나가보고 싶지만, 어떻게 될지는 모르겠습니다. 내년에 학교에 있을지도 불분명한 상황이라… 이번 H번을 보고, CP 대회에 대한 의욕을 갑자기 훅 잃은 것도 있습니다.&lt;/p&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="cp-rounds" /><summary type="html">Contents SNUPC Phase 1 : Easy problems (0분 - 60분) A, B G : 자연수 색칠하기 F : AND와 OR Phase 2 : Spurt (60분 - 120분) E : 뛰는 기물 C : 실 전화기 D : 누텔라 트리 Phase 3 : Too hard 대회가 끝나고 9월 11일 (토)에 진행된 서울대학교 프로그래밍 경시대회 (SNUPC) 2021 Division 2에 참가해 6등 했습니다. SNUPC SNUPC는 한국에서 열리는 프로그래밍 대회 중 개인 대회로는 아마 가장 높은 난이도를 자랑하는 대회가 아닌가 싶습니다. Division 1과 2로 나누어 수행되는데, 기억에는 Division 1의 참가자 상당수가 ACM-ICPC World Final 참가자들 급의 실력을 가진 (실제 WF 무대를 경험한 사람들도 10명은 있을 겁니다) 것으로 기억합니다. 제가 참가한 Division 2는 (공식적으로는) 퍼플 이하의 참가자들을 위한 대회이기 때문에 난이도가 훨씬 덜하지만, 다른 대학 대회들과 비교하면 오히려 정상적인 수준입니다. 저는 2019년에 Div2 9등 (3등상), 2020년에 7등 (3등상), 올해 6등 (3등상) 의 성적을 얻었습니다. 제 실력은 분명 조금씩 발전하고 있지만, 대회가 점점 더 고여가기 때문에 제가 내년에도 Div2 우승을 노리는 것보다는 아마 Div1에 나가지 않을까 싶습니다. SNUPC는 대학원생들도 꽤 많이 나오고, 저한테는 앞으로도 당분간은 좋은 취미일 (?) PS를 즐길수있게 해주는 좋은 대회이기 때문에 석사과정 정도까지는 토요일 하루 빼서 나와볼만 하다고 생각합니다. Phase 1 : Easy problems (0분 - 60분) A, B A, B 두 문제는 워낙 쉬운 문제라서 딱히 commentate할 부분은 없습니다. B 퍼솔을 먹어서 기분이 좀 좋았습니다. :) C를 조금 손대 보았고, 실제로 맞는 관찰을 헀지만, 구현에서 실수가 조금 있어서 AC를 받지 못했습니다. 스코어보드를 보고 의외로 G가 쉬운 문제라고 판단하여 G로 갔습니다. G : 자연수 색칠하기 서로소인 두 색을 서로 다른 색으로 색칠해야 한다는 조건이 있는데, 이 조건의 충분조건으로 다음과 같은 색칠을 생각합니다. 소수는 모두 서로소이므로, 소수끼리는 서로 다른 색으로 칠합니다. 소수가 아닌 수는, 무조건 가장 큰 소인수에 해당하는 색으로 칠합니다. 이렇게 칠하면, $\pi(n) + 1$ 개의 색을 쓰게 됩니다 (1은 따로 칠해야 하므로) 소수는 모두 서로 다른 색으로 칠해야 하므로 이보다 적게 색깔을 쓰는 방법은 없습니다. 또한, 두번째 조건에 의해 서로소인 수는 소인수를 공유하지 않으므로 다른 색으로 칠하게 되어, 이 칠하는 방법이 올바릅니다. F : AND와 OR 두 수 $a, b$를 두 수 $c, d$로 바꾸되, 이때 $a, b$와 $c, d$는 각각 AND한 값과 OR한 값이 같아야 합니다. $N$개의 수가 주어지고, 이 수들에 대해 이 연산을 원하는 만큼 수행한 후, 곱을 최소화하는 문제입니다. 생각해 보면, 두 수에 모두 켜져 있는 비트는 c, d 에서도 켜져 있어야 하고, 한쪽에만 켜져 있는 비트는 한쪽에만 켜져 있어야 하고… 해서 각 비트 단위로 조건을 생각하면 $a + b = c + d$ 여야 한다는 것을 알 수 있습니다 (충분조건은 아닙니다) 따라서, $N$개의 수에 대해 그 합을 바꿀 방법은 없습니다. 합을 유지하면서 곱을 최소화하는 방법은 최대한 큰 수와 최대한 작은 수로 수의 크기 갭을 벌리는 것입니다. 이를 위해, 모든 수를 OR하여 하나를 만들고, 앞으로 그 수는 건드리지 않는 방법으로 모든 수에 켜진 bit의 union에 해당하는 수를 하나 만들어서 앞으로의 연산에서 제외하는 식으로 진행하면 됩니다. 이 구현은 $O(N^2)$ 이기 때문에, 더 줄여야 합니다. 특정 비트 $k$번을 생각하고, $k$번 비트가 $N$개의 수를 통틀어 몇 번 켜지는지 확인하여 구현하면 $O(30 N)$ 에 해결할 수 있습니다. 이문제까지 해결한 다음, 다시 스코어보드를 확인했는데 CDEFG가 풀린 숫자가 거기서 거기인 신기한 스코어보드를 보고 좀 당황했습니다. Phase 2 : Spurt (60분 - 120분) E : 뛰는 기물 가로와 세로로 나이트처럼 움직이되, $(m, n)$칸 움직일 수 있는 (또는 $(n, m), (-n, m)$ 등) $(m, n)$-나이트를 정의합니다. 무한한 정수 격자점 $\Z^2$를 무한히 많은 나이트 move로 커버하기 위해, 최소 몇 개의 시작점 (몇 마리의 나이트) 가 필요한지에 대한 문제입니다. 어렵지 않은 관찰로 시작합니다. $\gcd(m, n) = g &amp;gt; 1$ 이면, 전체 보드를 $g * g$ 칸 정사각형으로 분할했을 때, 같은 정사각형 안에서는 움직일 방법이 없습니다. 즉, 적어도 $g^2$ 개는 필요합니다. 따라서, $m, n$이 서로소인 경우만 해결하면 됩니다. 여기서 추가로, $(1, 1)$ 나이트 같은 경우, $x + y$ 좌표의 홀짝성을 바꿀 수 있는 방법이 없습니다. 이는 $(3, 3)$나이트나, $(3, 5)$ 등 다른 (홀수, 홀수) 나이트도 가지고 있는 문제입니다. 이유는 $x + y$, $x - y$ 가 모두 짝수이기 때문입니다. 이를 해결하기 위해 적어도 2마리가 필요할 것입니다. 그렇지 않고, $(2, 3)$ 나이트같은 경우 이 나이트가 모든 칸을 방문할 수 있음을 주장합니다. 이 증명을 엄밀하게 하는 것은 상당히 귀찮은 일이며, 풀이 슬라이드에 잘 나와 있습니다. ㅋㅋ! 저는 엄밀한 증명까지는 하지 않고, 그림을 몇개 그려 보고 대충 지그재그로 잘 움직이다가 밑으로 훅 내려오는 것을 반복하면 $(1, 0)$에 도달할 수 있다고 믿었습니다. 간단히 아이디어만 소개하자면, $(m, n)$ 나이트에서 일반성을 잃지 않고 $n &amp;gt; m$ 이라고 하겠습니다. 이때 $n &amp;gt; 2m$ 인 경우, $n &amp;lt; 2m$ 인 경우를 나누어, 나이트로 잘 움직여서 $(m, n)$ 나이트가 다른 어떤 $(a, b)$ 나이트의 행동을 모두 할 수 있음을 보이고, (이때 a, b를 n, m보다 작게 줄이면서) base case로 $(1, 2)$ 나이트가 $(1, 0)$에 도달 가능함을 이용합니다. 참고로, 체스를 좋아한다면 $(1, 2)$ 나이트로 엔드게임 시점에 바로 옆 칸에 가기 위해 3번의 움직임을 쓰는 상황을 calculate해본 경험이 많을 것입니다. 저는 그래서 조금 재밌었습니다. (비슷한 이치로 장기를 잘 두는 사람은 $(2, 3)$ 나이트도 추가로 머릿속에서 그려지는듯 합니다.) 별개로 저는 이 문제에서 사소한 실수로 4틀했습니다. :( 페널티 싸움에서 패배해서 등수가 낮아진 매우 중요한 원인이 되었습니다. C : 실 전화기 정오각형으로 노드가 배치된 그래프를 평면에 임베딩하기 위해, 노드를 최소 몇개 움직여야 하는지 찾는 문제. 완전그래프 $K_5$는 평면 임베딩이 불가능함이 알려져 있으며, 예제로 주어져 있습니다. 여기서 edge를 하나 빼면 평면에 올릴 수 있고, 최대 2개만 움직이면 됩니다. 노드를 1개 움직여서 가능한지 아닌지만 판정하면 되고, 노드 한개를 충분히 멀리 움직이는 것이 없애는 것과 같은 효과이므로, 하나를 없애서 나머지가 충돌하지 않는지 확인하면 됩니다. D : 누텔라 트리 트리에 검정색과 빨간색으로 칠해진 정점들이 있는데, 여기서 검정색에서 출발하여 빨간색들만 밟는 ‘누텔라 경로’ 가 몇 개 있는지 세는 문제입니다. 빨간색에 한번 도달하면, 연결된 빨간색들 중 어디에 멈출지만 정하면 되기 때문에, 그 component에서 가능한 경우의 수는 빨간색의 개수입니다. 이를 DSU로 미리 묶어서 처리하면 쉽게 해결 가능합니다. Phase 3 : Too hard 7문제를 푼 순간, 제가 참가자들 중 가장 먼저 7솔브에 도달했기 떄문에 이거 Div2 우승하는거 아니냐 ㅋㅋ 라고 생각하며 잠깐 설렜습니다. 그런데 생각해보면 CDEFG의 난이도가 비슷해서 생긴 일이므로, 지금 (120분 시점) 6솔인 사람들은 시간이 주어진다면 충분히 7솔브가 가능하고, 저는 E번을 4틀하면서 페널티에서 엄청 밀렸으므로 8솔브를 해야 우승을 노릴 수 있었습니다 (그렇지 않더라도 사실 이 상황에서 저한테 달라질건 없지만요). H와 I 중 무엇을 풀지 고민하다가, H가 인터랙티브라서 I를 풀고자 시도했는데 I번에서도 뭔가 어려움이 많았습니다. $N \sqrt{N}$ 정도까지는 어떻게 잘 우기면 될거 같은데, $N = 2e6$이라서 루트도 허용하지 않는 처참한 시간제한을 보고 다시 H로 도망쳤지만 답이 없었습니다. 대회가 끝나고 매년 SNUPC는 정말 많은 생각이 들게 합니다. 매년 뛰어난 사람들이 몰려오고 있고, 나는 정체된 것이 아닌가 하는 회의감부터, 그럼에도 불구하고 하나씩 풀어나갈 때 나름의 즐거움과 생각하는 과정의 즐거움은 PS를 그만둘 수 없게 하기도 합니다. 내년에는 Div1에 나가보고 싶지만, 어떻게 될지는 모르겠습니다. 내년에 학교에 있을지도 불분명한 상황이라… 이번 H번을 보고, CP 대회에 대한 의욕을 갑자기 훅 잃은 것도 있습니다.</summary></entry><entry><title type="html">논문읽기 : VEQ</title><link href="http://localhost:4000/cs-adventure/VEQ/" rel="alternate" type="text/html" title="논문읽기 : VEQ" /><published>2021-09-11T00:00:00+09:00</published><updated>2021-09-11T00:00:00+09:00</updated><id>http://localhost:4000/cs-adventure/VEQ</id><content type="html" xml:base="http://localhost:4000/cs-adventure/VEQ/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#key-ideas&quot; id=&quot;markdown-toc-key-ideas&quot;&gt;Key Ideas&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#filtering--dag-graph-dp&quot; id=&quot;markdown-toc-filtering--dag-graph-dp&quot;&gt;Filtering : DAG Graph DP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#adaptive-matching-order--static-equivalence&quot; id=&quot;markdown-toc-adaptive-matching-order--static-equivalence&quot;&gt;Adaptive Matching Order : Static Equivalence&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#run-time-pruning--dynamic-equivalence&quot; id=&quot;markdown-toc-run-time-pruning--dynamic-equivalence&quot;&gt;Run time pruning : Dynamic Equivalence&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dynamic-equivalence-예시&quot; id=&quot;markdown-toc-dynamic-equivalence-예시&quot;&gt;Dynamic Equivalence 예시&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#실험-performance-analysis&quot; id=&quot;markdown-toc-실험-performance-analysis&quot;&gt;실험 (Performance Analysis)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thoughts&quot; id=&quot;markdown-toc-thoughts&quot;&gt;Thoughts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;Kim, H., Choi, Y., Park, K., Lin, X., Hong, S. H., &amp;amp; Han, W. S. (2021). Versatile Equivalences: Speeding up Subgraph Query Processing and Subgraph Matching. Proceedings of the ACM SIGMOD International Conference on Management of Data, 925–937. https://doi.org/10.1145/3448016.3457265&lt;/p&gt;

&lt;p&gt;관련 포스팅 : &lt;strong&gt;&lt;a href=&quot;/cs-adventure/sub-iso-note&quot;&gt;Subgraph Isomorphism : Introduction&lt;/a&gt;&lt;/strong&gt; 을 먼저 읽어주세요!&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;이번에 정리할 논문은 제가 2020년 2학기에 연구실 학부생 인턴으로 지도 받았던 서울대학교 컴퓨터이론 및 응용 연구실 (박근수 교수님 연구팀) 에서 이번 2021년 SIGMOD에 발표한 논문이자, 제 이번 창의통합설계와 밀접한 관련이 있는 논문입니다. (그래서 다른 논문에 비해 훨씬 자세히 읽었습니다. 이 논문을 똑같이 구현할 각오(?) 를 하고 있었기 때문에…)&lt;/p&gt;

&lt;p&gt;Subgraph isomorphism에 관한 논문 정리할게 2편 더 남았는데, introduction에 매우 큰 공통점이 있으므로, &lt;strong&gt;&lt;a href=&quot;/cs-adventure/sub-iso-note&quot;&gt;Subgraph Isomorphism : Introduction&lt;/a&gt;&lt;/strong&gt; 라는 포스팅을 별도로 작성했습니다. 이 포스팅으로 Intro 내용 대부분을 때우게 되었습니다.&lt;/p&gt;

&lt;p&gt;이 알고리즘도 크게는 위 포스팅에서 다룬, Filtering - Matching order - Backtracking 의 틀 위에서 설명될 수 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;key-ideas&quot;&gt;Key Ideas&lt;/h1&gt;
&lt;h2 id=&quot;filtering--dag-graph-dp&quot;&gt;Filtering : DAG Graph DP&lt;/h2&gt;
&lt;p&gt;더 강한 필터링을 위해, 우리는 어떤 적당한 순서로 DP를 돌려서 Candidate Set (CS) 라는 자료구조를 구축합니다. 그래프에서 DP를 돌리기 위해서는 DP할 순서가 필요하기 때문에, Query Graph로부터 DAG를 만듭니다. 이때 DAG는 label이 좀 unique하면서 degree가 큰 정점을 하나 잡아서, 그 정점에서 BFS를 돌려서 얻을 것입니다. 이를 $q_D$라고 하고, 나중에 역방향으로 돌리기 위해 $q_D$의 inverse DAG $q_D^{-1}$ 로 만듭니다.&lt;/p&gt;

&lt;p&gt;CS는 각 $u \in V_q$에 대해, 집합 $C(u)$ 와 그 집합의 $v_{ip} \in C(u_i)$, $v_{jq} \in C(u_j)$ 사이에 이어진 간선을 저장하는 자료구조입니다. 이 자료구조는 DAF[^ref-daf] 에서 제시된 자료구조이지만, VEQ에서는 더 개선된 버전으로 적용됩니다. 최초의 CS는 label과 $G$에서의 연결관계만 가지고 대충 만들어 놓고 (label이 같은 정점들을 집어넣고, 그 정점과 연결되어 있는 정점을 BFS 순서로 돌면서 빌드) 이를 줄여나갈 것입니다.&lt;/p&gt;

&lt;p&gt;DAG DP는 기본적으로 $\abs{V_q}\abs{V_G}$ 크기의 큰 boolean DP 테이블을 채워나가는 방법입니다. 이 테이블 D는 $D(u_i, v_j)$ 가 곧 $v_j \in C(u_i)$를 의미하는 DP가 됩니다. DAG의 리프부터 시작해서 올라오면서, 다음을 계산합니다.&lt;/p&gt;

&lt;p&gt;$D(u, v)$ 가 1일 필요충분조건 : $u$의 모든 자식 노드 $u_c$에 대해,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$^\exists v_c$ adjacent to $v$, $D(u_c, v_c) = 1$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 조건까지는 DAF에서 사용한 DP의 정의입니다. VEQ에서는 여기서 더 강한 조건을 요구하여 더 강한 필터링을 달성합니다.&lt;br /&gt;
$D(u, v)$ 가 1일 필요충분조건 : $u$의 모든 자식 노드 $u_c$에 대해 DAF에서의 조건을 만족하며, $(u, v)$가 모든 label $l$에 대해 다음을 만족한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;label이 $l$인 $u$의 인접 노드 $u_{l_i}$들에 대해, $C(u_{l_i})$에 포함되는 정점들을 모두 모은 다음, 그들 중 $v$와 연결되어 있는 정점들 (즉, $v$에서 extend 가능한) 만 챙겨서, 이를 $N(u, v, l)$ 이라 합니다.&lt;/li&gt;
  &lt;li&gt;이 $N(u, v, l)$의 크기가, 적어도 $u$의 인접 노드들 중 label이 $l$인 노드보다는 많아야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉, 직관적으로, 만약 $u_1$을 $v_1$에 매핑해놓고 보니까 $u_1$에는 라벨이 $l$인 이웃이 여섯개 있는데 $v_1$에서 extend가능한 라벨 $l$인 이웃이 네개밖에 없는 상황을 미리 판단해서 방지한다는 것입니다.&lt;/p&gt;

&lt;p&gt;이 조건을 VEQ 논문에서는 “Neighbor-Safety”라고 정의했습니다. 이 조건은 미리 preprocessing을 빡세게 해서 잘 구현하면 원래의 DP와 같은 시간 복잡도 $O(\abs{E_q}\abs{E_G})$에 가능하다고 합니다.&lt;/p&gt;

&lt;p&gt;또한, 이 DP를 최대한 잘 줄이기 위해, query DAG를 여러개 쓰면 더 좋은 결과를 얻을 수 있습니다. 실제로는 $q_D, q_D^{-1}, q_D$ 순서로 반복하면서 쓰면 되는데, 논문에 의하면 3번만 하면 더이상 큰 의미 없다고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;adaptive-matching-order--static-equivalence&quot;&gt;Adaptive Matching Order : Static Equivalence&lt;/h2&gt;
&lt;p&gt;Adaptive Matching Order란, Matching order를 미리 정하지 않고, 백트래킹 하는 중에 다이나믹하게 정해 나가겠다는 의미입니다. 현재까지 찾은 partial embedding $M$에 대해, $M$에 이미 포함된 정점과 이웃한 정점들을 extendable하다고 정의하고, 이때 Candidate set $C(u)$에 들어 있는 정점들 중 partial embedding $M$을 고려할 때 $u$와 매칭 가능한 정점들을 $C_M(u)$ 라고 정의하겠습니다. (즉, $C(u)$에 있더라도, 이미 $M$에서 이웃들을 매칭했을 때 $u_c$를 $v_c$에다가 대고 매치했다면, $v_c$와 이웃하는 점만 남기고 나머지는 날리겠다는 말입니다)&lt;/p&gt;

&lt;p&gt;Extendable vertex중 하나를 택해서 다음 정점으로 삼고 backtracking해야 합니다. CFL-Match와 DAF의 경우 이부분에서 vertex를 core-forest-leaf 또는 core-leaf로 나눠서 매칭하는 전략을 쓰는데, 이 논문에서는 이와 같은 decomposition전략이 leaf가 적을 때 느려서 별로 좋지 않다고 주장합니다.&lt;/p&gt;

&lt;p&gt;대신에, 다음과 같은 방법을 씁니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;DAG DP를 할 때, 미리 query에 대해서 NEC (Neighbor Equivalence Class) 라는 기법을 이용해서 리프 노드를 합칠 것입니다. NEC는 2013년 Turbo-Iso라는 알고리즘 (Postech의 한욱신 교수님 연구팀) 논문 중에 제시된 방법으로, label이 같고 이웃하는 vertex가 같은 leaf를 하나로 합쳐버린 다음 (즉, $u_3$에 리프 $u_4$ 와 $u_5$가 달려있는데 두 라벨이 같으면) 이를 기록해두는 것입니다. 이게 말이 되는 이유는 어차피 $u_4$가 매칭될 수 있는 노드라면 $u_5$도 항상 매칭 가능해서, 두개의 임베딩이 동시에 찾아지기 때문입니다 (둘다 리프이므로 다른 노드를 고려할 필요가 없습니다)&lt;/li&gt;
  &lt;li&gt;만약 리프 $u$가 존재하여, $\abs{NEC(u)}$의 개수를 고려할 때 아직 매칭되지 않은 $C_M(u)$의 노드가 충분히 있다면 이쪽으로 가서 매칭합니다.&lt;/li&gt;
  &lt;li&gt;그렇지 않다면, 리프를 우선적으로 매칭하고,&lt;/li&gt;
  &lt;li&gt;리프가 없으면, $\abs{C_M(u)}$가 작은 노드부터 매칭합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;참고로, DAF의 경우 두개의 adaptive matching order 중 하나를 사용합니다. 이때 두 가지 중 하나가 $C_M(u)$의 크기가 작은 노드부터 매칭하는 것입니다.&lt;/p&gt;

&lt;h2 id=&quot;run-time-pruning--dynamic-equivalence&quot;&gt;Run time pruning : Dynamic Equivalence&lt;/h2&gt;
&lt;p&gt;백트래킹을 하는 중에도, 계속 Search space를 줄이고 싶습니다. 이를 위해서, Candidate Space를 잘 관찰하여 &lt;strong&gt;Equivalence Tree&lt;/strong&gt;의 개념을 정립합니다.&lt;/p&gt;

&lt;p&gt;$C(u)$의 원소 $v_i, v_j$에 대해, $v_i, v_j$와 연결된 $C(u_c)$의 vertex 가 모든 $u$의 이웃 $u_c$ 에 대해 같으면, 두 노드를 Neighbor equivalent in $C(u)$라고 정의합니다. 이를 통해, Cell 이라는 개념을 정의하는데, cell $\pi(u, v)$는 $C(u)$에서 $v$와 equivalent한 $v_i$들의 집합으로 정의합니다. 이미지는 VEQ 원본 논문의 이미지인데, 말로 설명하면 조금 귀찮지만 개념 자체는 직관적입니다.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;
&lt;img src=&quot;/images/337968b2f03d6ee99afdeed8b69da7c4e989a3071b5c6d6a0180f8525a86a1df.png&quot; alt=&quot;figure&quot; width=&quot;60%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Partial embedding $M$과, $C(u)$에서 equivalent한 노드 $v_i, v_j$가 있을때, $u \to v_i$를 매칭해 본 정보를 가지고 있다고 하겠습니다. 이때, $v_j$와 $v_i$는 그 특성이 매우 비슷한 노드이기 때문에, $u \to v_j$를 정말 모두 확인하는 것은 뭔가 기분이 매우 나쁩니다.&lt;/p&gt;

&lt;p&gt;논문에서는 이를 위해, 마지막으로 subtree equivalence를 정의합니다. Partial embedding 을 탐색 트리처럼 쓰고 있다는 점에 주의해서 notation을 읽어야 합니다.&lt;/p&gt;

&lt;p&gt;$M \cup (u, v_i)$를 루트로 하는 서브트리에서, $(u’, v_i)$는 더이상 나타나서는 안 되는 conflict들입니다 ($v_i$는 이미 $u$와 매칭되었으므로) 이들을 $I_M(u, v_i)$라 하고, 이 서브트리에서 $v_i \not\in \pi(u’, v’)$인 모든 매핑 (즉, $v_i$와 equivalence관계를 갖지 않는 매핑) 들의 집합을 $O_M(u, v_i)$ 라 합니다. 이때, Negative cell $\pi^{-}(u, v_i)$를 다음과 같이 정의합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;만약 $v_i$에 대한 conflict가 한번이라도 있었다면, $\pi(u, v_i)$와 $\cap_{(u’, v_i) \in I_M(u, v_i)} \pi(u’, v_i)$의 intersection. 즉, $v_i$와 매칭되고 싶어한다는 이유로 conflict를 만드는 $u’$들에 대해, $v_i$를 따라다니면서 모든 곳에서 $v_i$와 equivalent한 노드의 집합.&lt;/li&gt;
  &lt;li&gt;Conflict가 없었다면 $\pi(u, v_i)$로 그대로 가져갑니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;또한, $\delta_{M}(u, v_i)$를 다음과 같이 정의합니다.
\(\bigcup_{(u', v') \in O_M(u, v_i)} \pi(u', v')\)
직관적으로 이는, $v_i$와 equivalent하지 않은 모든 매핑들에 대해서, 그 equivalence class들을 모은 것입니다.&lt;/p&gt;

&lt;p&gt;이를 이용하여, Equivalence set $\pi_M(u, v_i)$를 정의합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;한번이라도 이 서브트리에서 성공한 사례가 있는 경우, $\pi^{-}(u, v_i) - \delta_M(u, v_i)$를 씁니다.&lt;/li&gt;
  &lt;li&gt;모두 실패한 경우, $\pi^{-}(u, v_i)$를 씁니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 equivalence class는, 진정한 subtree equivalence이기 때문에, $v_j \in \pi_M(u, v_i)$ 인 경우, $v_j$를 $v_i$대신 이용하는 모든 임베딩이 대칭적으로 존재합니다. 따라서, $u \to v_j$ 매칭을 아예 시도하지 않고 버릴 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;dynamic-equivalence-예시&quot;&gt;Dynamic Equivalence 예시&lt;/h2&gt;
&lt;p&gt;아래 그림도 VEQ 논문의 그림인데, 일부만 해석해 보도록 하겠습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;
&lt;img src=&quot;/images/89c1e22afed14b52504b0155821bff13faec7d6422f021a7f423b42fdb77d10f.png&quot; alt=&quot;figure&quot; width=&quot;90%&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;$\pi_M(u_2, v_3)$ 을 생각해 보겠습니다. (이 equivalence set을 완전히 아는 것은 $u_2 \to v_3$ 쪽의 서브트리를 모두 돌고 난 뒤입니다) 트리를 관찰해 보면, $v_3$ 와 매칭되고 싶어해서 conflict를 내는 노드 $u_5$ 가 보입니다. 따라서, $I_M(u_2, v_3) = \set{(u_5, v_3)}$ 입니다. Conflict가 발생한 적이 있으므로, $\pi^{-}(u_2, v_3)$ 을 계산할 때 $\pi(u_2, v_3)$ 와 $\pi(u_5, v_3)$의 intersection을 구합니다. 이는 figure 5를 보고 구하면 $\set{v_4}$고, 서브트리에서 성공해본 적이 없으므로 $\pi_M(u_2, v_3) = \pi^{-}(u_2, v_3) = \set{v_4}$ 입니다. 그러므로 $v_3 \equiv v_4$ 이고, $u_2 \to v_3$에서 성공해 본 적이 없으므로 $u_2 \to v_4$도 성공하는 임베딩이 없음을 알게 되어 탐색하지 않고 prune할수 있습니다.&lt;/p&gt;

&lt;p&gt;이 $\pi_M(u, v)$가 subtree equivalence의 필요충분이라는 증명은 proceeding에 발표된 버전에서는 빠져 있는데, 이후에 증명하게 된다면 채워 넣겠습니다. 직관적으로는, 이후의 서브트리 매칭 시도에서 생기는 모든 conflict와 equivalence를 기억해서 반영하고 있기 때문에 증명은 technical하겠지만 그렇게 이상하지는 않은것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;실험-performance-analysis&quot;&gt;실험 (Performance Analysis)&lt;/h2&gt;
&lt;p&gt;이 논문의 저자들은 VEQ 알고리즘을 기존의 SOTA 알고리즘들과 비교하여 성능을 측정하는 실험을 실행했고, 절대적인 소요 시간을 많이 줄일 수 있었습니다. 특히, 재미있는 결과 몇가지만 소개합니다. 비교 대상인 알고리즘들은 같은 큰 틀을 공유하는 CFL-Match, DAF, GQL, RI와 Constraint programming 기반의 Glasgow (시간만 비교) 입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Matching order는 차치하고, 결국은 필터링을 빡세게 걸고 백트래킹하는게 알고리즘들의 틀입니다. 여기서, 필터링을 열심히 할수록 백트래킹할게 적은데, 백트래킹은 최악의 경우 지수 시간이 걸리지만 필터링은 어쨌든 다항시간에 할 수 있으므로, 필터링 시간이 크고 백트래킹 시간이 작다면 알고리즘의 성능이 데이터셋에 대해 좀더 stable합니다. 이 점에서 VEQ는 필터링을 extended DP로 강하게 하고, Dynamic pruning으로 백트래킹 시간을 많이 줄이기 때문에 최소 50%에서 최대 95% 정도의 시간을 필터링에 쓰고, 백트래킹은 정말 최소화합니다.&lt;/li&gt;
  &lt;li&gt;이것은, Extended DP를 했기 때문이기도 하지만, 필터링 결과 자체의 차이보다도 오히려 필터링 과정에서 얻는 Cell이라는 엄청나게 강한 정보를 이후에 이용할 수 있었던 점이 가장 중요해 보입니다. 즉, 다항시간에 할수있는 일들을 최대한 처리했기 때문에 가능했을 것입니다.&lt;/li&gt;
  &lt;li&gt;실제로, Dynamic Equivalence를 수행하여 날릴 수 있었던 search space가 많은 케이스에서 99% 가까이 나오기도 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Neighbor safety에서, 이 논문에서는 1-neighbor만을 고려하여 safety를 계산합니다. 더 많은, 예를들어 2-neighbor (거리가 2인 노드들까지) 까지 고려하면 더 강한 필터링이 가능할텐데, 그러지 않은 이유는 아마도 필터링에 소요하는 시간에 비해 필터링의 효용이 크지 않다고 보았기 때문일 것입니다. 그렇다면, label의 frequency가 높을 때 (즉 label frequency가 생각보다 더 중요할 때) 는 고려하는 neighbor의 수를 더 늘리는 방식처럼 뭔가 다이나믹하게 계산가능한 파라미터를 잡을수는 없을까요?&lt;/li&gt;
  &lt;li&gt;Equivalence를 Hashing 등을 통해 잘 관리하면 더 빠르게 처리할 수 있을까요?&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="cs-adventure" /><summary type="html">Contents Introduction Key Ideas Filtering : DAG Graph DP Adaptive Matching Order : Static Equivalence Run time pruning : Dynamic Equivalence Dynamic Equivalence 예시 실험 (Performance Analysis) Thoughts Kim, H., Choi, Y., Park, K., Lin, X., Hong, S. H., &amp;amp; Han, W. S. (2021). Versatile Equivalences: Speeding up Subgraph Query Processing and Subgraph Matching. Proceedings of the ACM SIGMOD International Conference on Management of Data, 925–937. https://doi.org/10.1145/3448016.3457265 관련 포스팅 : Subgraph Isomorphism : Introduction 을 먼저 읽어주세요! Introduction 이번에 정리할 논문은 제가 2020년 2학기에 연구실 학부생 인턴으로 지도 받았던 서울대학교 컴퓨터이론 및 응용 연구실 (박근수 교수님 연구팀) 에서 이번 2021년 SIGMOD에 발표한 논문이자, 제 이번 창의통합설계와 밀접한 관련이 있는 논문입니다. (그래서 다른 논문에 비해 훨씬 자세히 읽었습니다. 이 논문을 똑같이 구현할 각오(?) 를 하고 있었기 때문에…) Subgraph isomorphism에 관한 논문 정리할게 2편 더 남았는데, introduction에 매우 큰 공통점이 있으므로, Subgraph Isomorphism : Introduction 라는 포스팅을 별도로 작성했습니다. 이 포스팅으로 Intro 내용 대부분을 때우게 되었습니다. 이 알고리즘도 크게는 위 포스팅에서 다룬, Filtering - Matching order - Backtracking 의 틀 위에서 설명될 수 있습니다. Key Ideas Filtering : DAG Graph DP 더 강한 필터링을 위해, 우리는 어떤 적당한 순서로 DP를 돌려서 Candidate Set (CS) 라는 자료구조를 구축합니다. 그래프에서 DP를 돌리기 위해서는 DP할 순서가 필요하기 때문에, Query Graph로부터 DAG를 만듭니다. 이때 DAG는 label이 좀 unique하면서 degree가 큰 정점을 하나 잡아서, 그 정점에서 BFS를 돌려서 얻을 것입니다. 이를 $q_D$라고 하고, 나중에 역방향으로 돌리기 위해 $q_D$의 inverse DAG $q_D^{-1}$ 로 만듭니다. CS는 각 $u \in V_q$에 대해, 집합 $C(u)$ 와 그 집합의 $v_{ip} \in C(u_i)$, $v_{jq} \in C(u_j)$ 사이에 이어진 간선을 저장하는 자료구조입니다. 이 자료구조는 DAF[^ref-daf] 에서 제시된 자료구조이지만, VEQ에서는 더 개선된 버전으로 적용됩니다. 최초의 CS는 label과 $G$에서의 연결관계만 가지고 대충 만들어 놓고 (label이 같은 정점들을 집어넣고, 그 정점과 연결되어 있는 정점을 BFS 순서로 돌면서 빌드) 이를 줄여나갈 것입니다. DAG DP는 기본적으로 $\abs{V_q}\abs{V_G}$ 크기의 큰 boolean DP 테이블을 채워나가는 방법입니다. 이 테이블 D는 $D(u_i, v_j)$ 가 곧 $v_j \in C(u_i)$를 의미하는 DP가 됩니다. DAG의 리프부터 시작해서 올라오면서, 다음을 계산합니다. $D(u, v)$ 가 1일 필요충분조건 : $u$의 모든 자식 노드 $u_c$에 대해, $^\exists v_c$ adjacent to $v$, $D(u_c, v_c) = 1$ 이 조건까지는 DAF에서 사용한 DP의 정의입니다. VEQ에서는 여기서 더 강한 조건을 요구하여 더 강한 필터링을 달성합니다. $D(u, v)$ 가 1일 필요충분조건 : $u$의 모든 자식 노드 $u_c$에 대해 DAF에서의 조건을 만족하며, $(u, v)$가 모든 label $l$에 대해 다음을 만족한다. label이 $l$인 $u$의 인접 노드 $u_{l_i}$들에 대해, $C(u_{l_i})$에 포함되는 정점들을 모두 모은 다음, 그들 중 $v$와 연결되어 있는 정점들 (즉, $v$에서 extend 가능한) 만 챙겨서, 이를 $N(u, v, l)$ 이라 합니다. 이 $N(u, v, l)$의 크기가, 적어도 $u$의 인접 노드들 중 label이 $l$인 노드보다는 많아야 합니다. 즉, 직관적으로, 만약 $u_1$을 $v_1$에 매핑해놓고 보니까 $u_1$에는 라벨이 $l$인 이웃이 여섯개 있는데 $v_1$에서 extend가능한 라벨 $l$인 이웃이 네개밖에 없는 상황을 미리 판단해서 방지한다는 것입니다. 이 조건을 VEQ 논문에서는 “Neighbor-Safety”라고 정의했습니다. 이 조건은 미리 preprocessing을 빡세게 해서 잘 구현하면 원래의 DP와 같은 시간 복잡도 $O(\abs{E_q}\abs{E_G})$에 가능하다고 합니다. 또한, 이 DP를 최대한 잘 줄이기 위해, query DAG를 여러개 쓰면 더 좋은 결과를 얻을 수 있습니다. 실제로는 $q_D, q_D^{-1}, q_D$ 순서로 반복하면서 쓰면 되는데, 논문에 의하면 3번만 하면 더이상 큰 의미 없다고 합니다. Adaptive Matching Order : Static Equivalence Adaptive Matching Order란, Matching order를 미리 정하지 않고, 백트래킹 하는 중에 다이나믹하게 정해 나가겠다는 의미입니다. 현재까지 찾은 partial embedding $M$에 대해, $M$에 이미 포함된 정점과 이웃한 정점들을 extendable하다고 정의하고, 이때 Candidate set $C(u)$에 들어 있는 정점들 중 partial embedding $M$을 고려할 때 $u$와 매칭 가능한 정점들을 $C_M(u)$ 라고 정의하겠습니다. (즉, $C(u)$에 있더라도, 이미 $M$에서 이웃들을 매칭했을 때 $u_c$를 $v_c$에다가 대고 매치했다면, $v_c$와 이웃하는 점만 남기고 나머지는 날리겠다는 말입니다) Extendable vertex중 하나를 택해서 다음 정점으로 삼고 backtracking해야 합니다. CFL-Match와 DAF의 경우 이부분에서 vertex를 core-forest-leaf 또는 core-leaf로 나눠서 매칭하는 전략을 쓰는데, 이 논문에서는 이와 같은 decomposition전략이 leaf가 적을 때 느려서 별로 좋지 않다고 주장합니다. 대신에, 다음과 같은 방법을 씁니다. DAG DP를 할 때, 미리 query에 대해서 NEC (Neighbor Equivalence Class) 라는 기법을 이용해서 리프 노드를 합칠 것입니다. NEC는 2013년 Turbo-Iso라는 알고리즘 (Postech의 한욱신 교수님 연구팀) 논문 중에 제시된 방법으로, label이 같고 이웃하는 vertex가 같은 leaf를 하나로 합쳐버린 다음 (즉, $u_3$에 리프 $u_4$ 와 $u_5$가 달려있는데 두 라벨이 같으면) 이를 기록해두는 것입니다. 이게 말이 되는 이유는 어차피 $u_4$가 매칭될 수 있는 노드라면 $u_5$도 항상 매칭 가능해서, 두개의 임베딩이 동시에 찾아지기 때문입니다 (둘다 리프이므로 다른 노드를 고려할 필요가 없습니다) 만약 리프 $u$가 존재하여, $\abs{NEC(u)}$의 개수를 고려할 때 아직 매칭되지 않은 $C_M(u)$의 노드가 충분히 있다면 이쪽으로 가서 매칭합니다. 그렇지 않다면, 리프를 우선적으로 매칭하고, 리프가 없으면, $\abs{C_M(u)}$가 작은 노드부터 매칭합니다. 참고로, DAF의 경우 두개의 adaptive matching order 중 하나를 사용합니다. 이때 두 가지 중 하나가 $C_M(u)$의 크기가 작은 노드부터 매칭하는 것입니다. Run time pruning : Dynamic Equivalence 백트래킹을 하는 중에도, 계속 Search space를 줄이고 싶습니다. 이를 위해서, Candidate Space를 잘 관찰하여 Equivalence Tree의 개념을 정립합니다. $C(u)$의 원소 $v_i, v_j$에 대해, $v_i, v_j$와 연결된 $C(u_c)$의 vertex 가 모든 $u$의 이웃 $u_c$ 에 대해 같으면, 두 노드를 Neighbor equivalent in $C(u)$라고 정의합니다. 이를 통해, Cell 이라는 개념을 정의하는데, cell $\pi(u, v)$는 $C(u)$에서 $v$와 equivalent한 $v_i$들의 집합으로 정의합니다. 이미지는 VEQ 원본 논문의 이미지인데, 말로 설명하면 조금 귀찮지만 개념 자체는 직관적입니다. Partial embedding $M$과, $C(u)$에서 equivalent한 노드 $v_i, v_j$가 있을때, $u \to v_i$를 매칭해 본 정보를 가지고 있다고 하겠습니다. 이때, $v_j$와 $v_i$는 그 특성이 매우 비슷한 노드이기 때문에, $u \to v_j$를 정말 모두 확인하는 것은 뭔가 기분이 매우 나쁩니다. 논문에서는 이를 위해, 마지막으로 subtree equivalence를 정의합니다. Partial embedding 을 탐색 트리처럼 쓰고 있다는 점에 주의해서 notation을 읽어야 합니다. $M \cup (u, v_i)$를 루트로 하는 서브트리에서, $(u’, v_i)$는 더이상 나타나서는 안 되는 conflict들입니다 ($v_i$는 이미 $u$와 매칭되었으므로) 이들을 $I_M(u, v_i)$라 하고, 이 서브트리에서 $v_i \not\in \pi(u’, v’)$인 모든 매핑 (즉, $v_i$와 equivalence관계를 갖지 않는 매핑) 들의 집합을 $O_M(u, v_i)$ 라 합니다. 이때, Negative cell $\pi^{-}(u, v_i)$를 다음과 같이 정의합니다. 만약 $v_i$에 대한 conflict가 한번이라도 있었다면, $\pi(u, v_i)$와 $\cap_{(u’, v_i) \in I_M(u, v_i)} \pi(u’, v_i)$의 intersection. 즉, $v_i$와 매칭되고 싶어한다는 이유로 conflict를 만드는 $u’$들에 대해, $v_i$를 따라다니면서 모든 곳에서 $v_i$와 equivalent한 노드의 집합. Conflict가 없었다면 $\pi(u, v_i)$로 그대로 가져갑니다. 또한, $\delta_{M}(u, v_i)$를 다음과 같이 정의합니다. \(\bigcup_{(u', v') \in O_M(u, v_i)} \pi(u', v')\) 직관적으로 이는, $v_i$와 equivalent하지 않은 모든 매핑들에 대해서, 그 equivalence class들을 모은 것입니다. 이를 이용하여, Equivalence set $\pi_M(u, v_i)$를 정의합니다. 한번이라도 이 서브트리에서 성공한 사례가 있는 경우, $\pi^{-}(u, v_i) - \delta_M(u, v_i)$를 씁니다. 모두 실패한 경우, $\pi^{-}(u, v_i)$를 씁니다. 이 equivalence class는, 진정한 subtree equivalence이기 때문에, $v_j \in \pi_M(u, v_i)$ 인 경우, $v_j$를 $v_i$대신 이용하는 모든 임베딩이 대칭적으로 존재합니다. 따라서, $u \to v_j$ 매칭을 아예 시도하지 않고 버릴 수 있습니다. Dynamic Equivalence 예시 아래 그림도 VEQ 논문의 그림인데, 일부만 해석해 보도록 하겠습니다. $\pi_M(u_2, v_3)$ 을 생각해 보겠습니다. (이 equivalence set을 완전히 아는 것은 $u_2 \to v_3$ 쪽의 서브트리를 모두 돌고 난 뒤입니다) 트리를 관찰해 보면, $v_3$ 와 매칭되고 싶어해서 conflict를 내는 노드 $u_5$ 가 보입니다. 따라서, $I_M(u_2, v_3) = \set{(u_5, v_3)}$ 입니다. Conflict가 발생한 적이 있으므로, $\pi^{-}(u_2, v_3)$ 을 계산할 때 $\pi(u_2, v_3)$ 와 $\pi(u_5, v_3)$의 intersection을 구합니다. 이는 figure 5를 보고 구하면 $\set{v_4}$고, 서브트리에서 성공해본 적이 없으므로 $\pi_M(u_2, v_3) = \pi^{-}(u_2, v_3) = \set{v_4}$ 입니다. 그러므로 $v_3 \equiv v_4$ 이고, $u_2 \to v_3$에서 성공해 본 적이 없으므로 $u_2 \to v_4$도 성공하는 임베딩이 없음을 알게 되어 탐색하지 않고 prune할수 있습니다. 이 $\pi_M(u, v)$가 subtree equivalence의 필요충분이라는 증명은 proceeding에 발표된 버전에서는 빠져 있는데, 이후에 증명하게 된다면 채워 넣겠습니다. 직관적으로는, 이후의 서브트리 매칭 시도에서 생기는 모든 conflict와 equivalence를 기억해서 반영하고 있기 때문에 증명은 technical하겠지만 그렇게 이상하지는 않은것 같습니다. 실험 (Performance Analysis) 이 논문의 저자들은 VEQ 알고리즘을 기존의 SOTA 알고리즘들과 비교하여 성능을 측정하는 실험을 실행했고, 절대적인 소요 시간을 많이 줄일 수 있었습니다. 특히, 재미있는 결과 몇가지만 소개합니다. 비교 대상인 알고리즘들은 같은 큰 틀을 공유하는 CFL-Match, DAF, GQL, RI와 Constraint programming 기반의 Glasgow (시간만 비교) 입니다. Matching order는 차치하고, 결국은 필터링을 빡세게 걸고 백트래킹하는게 알고리즘들의 틀입니다. 여기서, 필터링을 열심히 할수록 백트래킹할게 적은데, 백트래킹은 최악의 경우 지수 시간이 걸리지만 필터링은 어쨌든 다항시간에 할 수 있으므로, 필터링 시간이 크고 백트래킹 시간이 작다면 알고리즘의 성능이 데이터셋에 대해 좀더 stable합니다. 이 점에서 VEQ는 필터링을 extended DP로 강하게 하고, Dynamic pruning으로 백트래킹 시간을 많이 줄이기 때문에 최소 50%에서 최대 95% 정도의 시간을 필터링에 쓰고, 백트래킹은 정말 최소화합니다. 이것은, Extended DP를 했기 때문이기도 하지만, 필터링 결과 자체의 차이보다도 오히려 필터링 과정에서 얻는 Cell이라는 엄청나게 강한 정보를 이후에 이용할 수 있었던 점이 가장 중요해 보입니다. 즉, 다항시간에 할수있는 일들을 최대한 처리했기 때문에 가능했을 것입니다. 실제로, Dynamic Equivalence를 수행하여 날릴 수 있었던 search space가 많은 케이스에서 99% 가까이 나오기도 합니다. Thoughts Neighbor safety에서, 이 논문에서는 1-neighbor만을 고려하여 safety를 계산합니다. 더 많은, 예를들어 2-neighbor (거리가 2인 노드들까지) 까지 고려하면 더 강한 필터링이 가능할텐데, 그러지 않은 이유는 아마도 필터링에 소요하는 시간에 비해 필터링의 효용이 크지 않다고 보았기 때문일 것입니다. 그렇다면, label의 frequency가 높을 때 (즉 label frequency가 생각보다 더 중요할 때) 는 고려하는 neighbor의 수를 더 늘리는 방식처럼 뭔가 다이나믹하게 계산가능한 파라미터를 잡을수는 없을까요? Equivalence를 Hashing 등을 통해 잘 관리하면 더 빠르게 처리할 수 있을까요?</summary></entry><entry><title type="html">Subgraph Isomorphism : Introduction</title><link href="http://localhost:4000/cs-adventure/sub-iso-note/" rel="alternate" type="text/html" title="Subgraph Isomorphism : Introduction" /><published>2021-09-11T00:00:00+09:00</published><updated>2021-09-11T00:00:00+09:00</updated><id>http://localhost:4000/cs-adventure/sub-iso-note</id><content type="html" xml:base="http://localhost:4000/cs-adventure/sub-iso-note/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#subgraph-isomorphism-문제-소개&quot; id=&quot;markdown-toc-subgraph-isomorphism-문제-소개&quot;&gt;Subgraph Isomorphism 문제 소개&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#subgraph-isomorphism-algorithms&quot; id=&quot;markdown-toc-subgraph-isomorphism-algorithms&quot;&gt;Subgraph Isomorphism Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#backtracking-algorithms&quot; id=&quot;markdown-toc-backtracking-algorithms&quot;&gt;Backtracking Algorithms&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#filtering&quot; id=&quot;markdown-toc-filtering&quot;&gt;Filtering&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#matching-order&quot; id=&quot;markdown-toc-matching-order&quot;&gt;Matching Order&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#backtracking&quot; id=&quot;markdown-toc-backtracking&quot;&gt;Backtracking&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references--papers&quot; id=&quot;markdown-toc-references--papers&quot;&gt;References / Papers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;subgraph-isomorphism-문제-소개&quot;&gt;Subgraph Isomorphism 문제 소개&lt;/h2&gt;

&lt;p&gt;Subgraph Isomorphism이란, 쿼리 그래프 $q$와 데이터 그래프 $G$가 주어지는 상황에서, $G$가 $q$와 isomorphic한 subgraph를 갖는지 여부를 판단하는 문제입니다. 이 문제는 NP-Complete임이 증명되어 있습니다. NP-Complete를 증명하는 것은 우리의 논의에 그렇게 중요하지 않지만, 잠깐 생각해 보면, Clique Problem (Subgraph Isomorphism에서, $q$가 정점 $n$개짜리 완전그래프 $K_n$으로 한정되는 버전) 보다는 적어도 어려운 문제임을 알 수 있습니다. Clique 문제는 Karp가 NP-Complete라는 개념을 정의하고 증명했을 때 나온 21개의 오리지널한 NP-Complete 문제 중 하나로, General SAT로부터 환원되므로 NP-Complete입니다.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;우리는 Subgraph에 관한 문제를 접근하면서, 다음과 같이 Embedding을 정의합니다.&lt;br /&gt;
Vertex Labeled graph $G, q$가 주어졌을 때, 함수 $f : V_q \to V_G$가 존재하여, $q$에서 edge $(u_1, u_2)$에 대해 항상 $G$에서 edge $(v_1 = f(u_1), v_2 = f(u_2))$ 를 찾을 수 있을 때, 이를 Embedding 이라 합니다. 단, Labeled graph이므로 $q$에서 $u$의 label과 $G$에서 $f(u)$의 label이 항상 같아야 합니다. 앞으로 편의상 $u_1 \dots u_n$은 $q$의, $v_1 \dots v_n$은 $G$의 vertex를 의미하는 것으로 쓰겠습니다.&lt;/p&gt;

&lt;p&gt;비슷하지만 좀더 Application 스러운 문제 두 개인 Subgraph search와 matching은, 다음과 같이 정의됩니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Subgraph Search란, 데이터 그래프가 하나가 아니라 여러 개 $G_1, G_2, \dots G_n$의 집합이 주어지고, $q$의 embedding을 갖는 그래프들을 모두 찾는 문제입니다.&lt;/li&gt;
  &lt;li&gt;Subgraph Matching이란, 데이터 그래프가 하나 주어지고, 쿼리 그래프가 주어져서, 데이터 그래프에서 $q$의 embedding을 모두 (또는 좀더 현실적으로, 가능한한 많이) 찾는 문제입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉, subgraph matching을 푸는 알고리즘에게 embedding을 하나 찾고 return true 하도록 하면, subgraph isomorphism이 되고, 다시 이것을 여러 데이터 그래프에 대해 반복하면 subgraph search가 됩니다. 이 글에서는, 세 문제 모두를 대충 Subgraph Isomorphism이라고 퉁치고 맥락상 이해하기로 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;subgraph-isomorphism-algorithms&quot;&gt;Subgraph Isomorphism Algorithms&lt;/h2&gt;
&lt;p&gt;이런 어려운 문제에 대한 접근에는 크게 세 가지가 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;문제의 제약 있는 버전을 만들어서, 그 문제를 빠르게 풀고자 시도합니다. 주로 사용하는 접근으로는 &lt;strong&gt;Chromatic Number&lt;/strong&gt;가 $k$ 이하인 그래프, &lt;strong&gt;평면&lt;/strong&gt; 그래프, &lt;strong&gt;Sparse&lt;/strong&gt;한 그래프 등에 대해 시도합니다. 이 방향의 연구는 주로 알고리즘이 다항 시간 비슷하게 줄어들며 (NP-Complete한 문제의 일부긴 하지만, 추가적인 조건을 제약했으므로 이게 가능합니다) 수학적으로 엄밀하게 증명합니다.&lt;/li&gt;
  &lt;li&gt;Randomized 알고리즘이나 최적화 형태의 알고리즘을 만들어서, expected time complexity를 줄이고자 합니다.&lt;/li&gt;
  &lt;li&gt;일반적인 Case에 대해, 휴리스틱하게 빠른 알고리즘을 찾고, 이를 큰 데이터셋에 대해 실험을 통해 검증하는 방향이 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2020년 2학기에 인턴십을 진행하면서 주로 3번에 해당하는 쪽을 공부했는데, Sub-iso에서 2번은 어떤 식인지 잘 모르겠고 (본적 없습니다) 1번은 여러 재미있는 결과들이 있지만 아직 자세히 읽어보지는 못했습니다.&lt;/p&gt;

&lt;p&gt;이 문제의 3번 접근에는 다시 크게 세가지 접근이 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ullmann (1976) 으로부터 시작하는 Backtracking 기반의 알고리즘으로, 가장 자연스럽게 생각할 수 있는 백트래킹에 기반합니다.&lt;/li&gt;
  &lt;li&gt;Artificial Intelligence 쪽에서도 이 문제를 상당히 중요하게 보고 있어서, 이쪽의 접근도 있습니다. Graph 위에서 뭔가를 열심히 학습시키는 방법입니다.&lt;/li&gt;
  &lt;li&gt;Contraint Programming 이라는 신기한 방법론에 기반하는 접근이 있습니다. 저는 이쪽을 잘 모르지만, 이론적으로 상당히 재밌는 내용들이 많다고 들었습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2번은 주로 Graph mining 같은 방향으로 접근하여 약간 방향성이 다르기 때문에, 1번과 3번을 실질적으로 알고리즘적인 접근으로 볼 수 있습니다. 3번의 현재 SOTA는 Glasgow라는 프로그램이 있고, 1번의 경우 CFL-Match라는 알고리즘을 기점으로 CECI, DAF 등이 연구되었습니다.&lt;/p&gt;

&lt;h2 id=&quot;backtracking-algorithms&quot;&gt;Backtracking Algorithms&lt;/h2&gt;
&lt;p&gt;CFL-Match, CECI, DAF를 비롯하여 많은 알고리즘들이 크게 3단계로 이 문제를 해결합니다. Filtering - Matching order generation - Backtracking인데, 각각이 어떤 느낌인지 알아보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;filtering&quot;&gt;Filtering&lt;/h3&gt;
&lt;p&gt;Filtering이란, 도저히 매칭이 안되는 점들을 먼저 쳐내는 방법입니다. 이때 Candidate Vertex Set이라는 개념이 등장하는데, $q$의 정점 $u$에 대해 $u$가 매핑될 수 있는 $G$의 vertex들이라고 볼 수 있습니다. 예를 들어, Label이 다른 정점은 아예 고려할 필요가 없습니다. 조금 더 복잡한 예시로는, $q$에서 1번 정점으로부터 label이 $a$인 정점으로 가는 간선이 있는 상황을 생각해 보겠습니다. $G$의 정점 10번에 대해, 10번 정점의 neighbor들 중 label이 $a$인 정점이 하나도 없다면, $u_1$ 을 $v_{10}$으로 매칭하는 매핑은 존재할 수 없습니다. 이러한 정점들을 최대한 강하게 필터링해서 제거하면, 백트래킹할 대상이 줄어들 것입니다. 이때 Candidate vertex set은 $u_i$가 매핑될 수 있는 $v_j$ 들의 집합 $C_i$를 말하며, 알고리즘에 따라서는 이 과정을 좀더 잘 하는 방법을 제시하는 경우 자료구조의 이름이 달라지기도 하지만 대략적으로는 이렇습니다.&lt;/p&gt;

&lt;h3 id=&quot;matching-order&quot;&gt;Matching Order&lt;/h3&gt;
&lt;p&gt;문제의 특징 상, 어떤 순서로 정점들을 matching해 나가는지는 search space가 감소하는 속도를 좌우하는 매우 중요한 요소입니다. Backtracking을 하기 위해서는 이 matching order가 필요한데, 이후 백트래킹을 수행하는 순서 (정의상 $q_V$의 permutation) 를 matching order라고 부릅니다. 알고리즘마다 다른 matching order를 사용하게 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;backtracking&quot;&gt;Backtracking&lt;/h3&gt;
&lt;p&gt;백트래킹은 단순히 하면 되지만, 이 과정에서 다양한 최적화가 가능합니다. 먼저 백트래킹을 위해서는 extendable한 candidate를 잡아야 하는데…&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;현재의 partial embedding $M$에서 사용했던 점들은 다시 사용할 수 없고&lt;/li&gt;
  &lt;li&gt;지금 내가 $u$를 보고 있다면, $u$의 neighbor들 중 $M$에서 이미 매핑된 정점들에 대해, 그 정점들 모두와 연결이 가능해야 합니다. 즉, $u_3$이 $u_1$, $u_2$ 와 연결되어 있고, $u_1, u_2$를 각각 $v_a, v_b$와 연결되어 있으면, $u_3$은 적어도 $v_a, v_b$와 연결된 점들 중에 골라야 한다는 것입니다. 
이 두가지가 가장 기본이 됩니다. 여기서 추가로 DAF의 경우 Failing set과 같은 최적화 기법들을 제시하기도 했습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;references--papers&quot;&gt;References / Papers&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Sun, S., &amp;amp; Luo, Q. (2020). &lt;strong&gt;In-Memory Subgraph Matching: An In-depth Study&lt;/strong&gt;. Proceedings of the ACM SIGMOD International Conference on Management of Data, 1083–1098. https://doi.org/10.1145/3318464.3380581 : Subgraph Isomorphism 방법들을 비교하고, 이들을 모두 구현하여 통일된 프레임워크 위에서 실험한 논문입니다. 이 글은 거의 이 논문에 기반한 정리 포스팅인데, 논문의 메인인 실험 결과를 정리하지 않았기 때문에 그렇게 분류해놓지는 않았습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;이부분의 증명은 이 글의 Scope를 너무 많이 벗어납니다. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="cs-adventure" /><summary type="html">Contents Subgraph Isomorphism 문제 소개 Subgraph Isomorphism Algorithms Backtracking Algorithms Filtering Matching Order Backtracking References / Papers Subgraph Isomorphism 문제 소개 Subgraph Isomorphism이란, 쿼리 그래프 $q$와 데이터 그래프 $G$가 주어지는 상황에서, $G$가 $q$와 isomorphic한 subgraph를 갖는지 여부를 판단하는 문제입니다. 이 문제는 NP-Complete임이 증명되어 있습니다. NP-Complete를 증명하는 것은 우리의 논의에 그렇게 중요하지 않지만, 잠깐 생각해 보면, Clique Problem (Subgraph Isomorphism에서, $q$가 정점 $n$개짜리 완전그래프 $K_n$으로 한정되는 버전) 보다는 적어도 어려운 문제임을 알 수 있습니다. Clique 문제는 Karp가 NP-Complete라는 개념을 정의하고 증명했을 때 나온 21개의 오리지널한 NP-Complete 문제 중 하나로, General SAT로부터 환원되므로 NP-Complete입니다.1 우리는 Subgraph에 관한 문제를 접근하면서, 다음과 같이 Embedding을 정의합니다. Vertex Labeled graph $G, q$가 주어졌을 때, 함수 $f : V_q \to V_G$가 존재하여, $q$에서 edge $(u_1, u_2)$에 대해 항상 $G$에서 edge $(v_1 = f(u_1), v_2 = f(u_2))$ 를 찾을 수 있을 때, 이를 Embedding 이라 합니다. 단, Labeled graph이므로 $q$에서 $u$의 label과 $G$에서 $f(u)$의 label이 항상 같아야 합니다. 앞으로 편의상 $u_1 \dots u_n$은 $q$의, $v_1 \dots v_n$은 $G$의 vertex를 의미하는 것으로 쓰겠습니다. 비슷하지만 좀더 Application 스러운 문제 두 개인 Subgraph search와 matching은, 다음과 같이 정의됩니다. Subgraph Search란, 데이터 그래프가 하나가 아니라 여러 개 $G_1, G_2, \dots G_n$의 집합이 주어지고, $q$의 embedding을 갖는 그래프들을 모두 찾는 문제입니다. Subgraph Matching이란, 데이터 그래프가 하나 주어지고, 쿼리 그래프가 주어져서, 데이터 그래프에서 $q$의 embedding을 모두 (또는 좀더 현실적으로, 가능한한 많이) 찾는 문제입니다. 즉, subgraph matching을 푸는 알고리즘에게 embedding을 하나 찾고 return true 하도록 하면, subgraph isomorphism이 되고, 다시 이것을 여러 데이터 그래프에 대해 반복하면 subgraph search가 됩니다. 이 글에서는, 세 문제 모두를 대충 Subgraph Isomorphism이라고 퉁치고 맥락상 이해하기로 하겠습니다. Subgraph Isomorphism Algorithms 이런 어려운 문제에 대한 접근에는 크게 세 가지가 있습니다. 문제의 제약 있는 버전을 만들어서, 그 문제를 빠르게 풀고자 시도합니다. 주로 사용하는 접근으로는 Chromatic Number가 $k$ 이하인 그래프, 평면 그래프, Sparse한 그래프 등에 대해 시도합니다. 이 방향의 연구는 주로 알고리즘이 다항 시간 비슷하게 줄어들며 (NP-Complete한 문제의 일부긴 하지만, 추가적인 조건을 제약했으므로 이게 가능합니다) 수학적으로 엄밀하게 증명합니다. Randomized 알고리즘이나 최적화 형태의 알고리즘을 만들어서, expected time complexity를 줄이고자 합니다. 일반적인 Case에 대해, 휴리스틱하게 빠른 알고리즘을 찾고, 이를 큰 데이터셋에 대해 실험을 통해 검증하는 방향이 있습니다. 2020년 2학기에 인턴십을 진행하면서 주로 3번에 해당하는 쪽을 공부했는데, Sub-iso에서 2번은 어떤 식인지 잘 모르겠고 (본적 없습니다) 1번은 여러 재미있는 결과들이 있지만 아직 자세히 읽어보지는 못했습니다. 이 문제의 3번 접근에는 다시 크게 세가지 접근이 있습니다. Ullmann (1976) 으로부터 시작하는 Backtracking 기반의 알고리즘으로, 가장 자연스럽게 생각할 수 있는 백트래킹에 기반합니다. Artificial Intelligence 쪽에서도 이 문제를 상당히 중요하게 보고 있어서, 이쪽의 접근도 있습니다. Graph 위에서 뭔가를 열심히 학습시키는 방법입니다. Contraint Programming 이라는 신기한 방법론에 기반하는 접근이 있습니다. 저는 이쪽을 잘 모르지만, 이론적으로 상당히 재밌는 내용들이 많다고 들었습니다. 2번은 주로 Graph mining 같은 방향으로 접근하여 약간 방향성이 다르기 때문에, 1번과 3번을 실질적으로 알고리즘적인 접근으로 볼 수 있습니다. 3번의 현재 SOTA는 Glasgow라는 프로그램이 있고, 1번의 경우 CFL-Match라는 알고리즘을 기점으로 CECI, DAF 등이 연구되었습니다. Backtracking Algorithms CFL-Match, CECI, DAF를 비롯하여 많은 알고리즘들이 크게 3단계로 이 문제를 해결합니다. Filtering - Matching order generation - Backtracking인데, 각각이 어떤 느낌인지 알아보겠습니다. Filtering Filtering이란, 도저히 매칭이 안되는 점들을 먼저 쳐내는 방법입니다. 이때 Candidate Vertex Set이라는 개념이 등장하는데, $q$의 정점 $u$에 대해 $u$가 매핑될 수 있는 $G$의 vertex들이라고 볼 수 있습니다. 예를 들어, Label이 다른 정점은 아예 고려할 필요가 없습니다. 조금 더 복잡한 예시로는, $q$에서 1번 정점으로부터 label이 $a$인 정점으로 가는 간선이 있는 상황을 생각해 보겠습니다. $G$의 정점 10번에 대해, 10번 정점의 neighbor들 중 label이 $a$인 정점이 하나도 없다면, $u_1$ 을 $v_{10}$으로 매칭하는 매핑은 존재할 수 없습니다. 이러한 정점들을 최대한 강하게 필터링해서 제거하면, 백트래킹할 대상이 줄어들 것입니다. 이때 Candidate vertex set은 $u_i$가 매핑될 수 있는 $v_j$ 들의 집합 $C_i$를 말하며, 알고리즘에 따라서는 이 과정을 좀더 잘 하는 방법을 제시하는 경우 자료구조의 이름이 달라지기도 하지만 대략적으로는 이렇습니다. Matching Order 문제의 특징 상, 어떤 순서로 정점들을 matching해 나가는지는 search space가 감소하는 속도를 좌우하는 매우 중요한 요소입니다. Backtracking을 하기 위해서는 이 matching order가 필요한데, 이후 백트래킹을 수행하는 순서 (정의상 $q_V$의 permutation) 를 matching order라고 부릅니다. 알고리즘마다 다른 matching order를 사용하게 됩니다. Backtracking 백트래킹은 단순히 하면 되지만, 이 과정에서 다양한 최적화가 가능합니다. 먼저 백트래킹을 위해서는 extendable한 candidate를 잡아야 하는데… 현재의 partial embedding $M$에서 사용했던 점들은 다시 사용할 수 없고 지금 내가 $u$를 보고 있다면, $u$의 neighbor들 중 $M$에서 이미 매핑된 정점들에 대해, 그 정점들 모두와 연결이 가능해야 합니다. 즉, $u_3$이 $u_1$, $u_2$ 와 연결되어 있고, $u_1, u_2$를 각각 $v_a, v_b$와 연결되어 있으면, $u_3$은 적어도 $v_a, v_b$와 연결된 점들 중에 골라야 한다는 것입니다. 이 두가지가 가장 기본이 됩니다. 여기서 추가로 DAF의 경우 Failing set과 같은 최적화 기법들을 제시하기도 했습니다. References / Papers Sun, S., &amp;amp; Luo, Q. (2020). In-Memory Subgraph Matching: An In-depth Study. Proceedings of the ACM SIGMOD International Conference on Management of Data, 1083–1098. https://doi.org/10.1145/3318464.3380581 : Subgraph Isomorphism 방법들을 비교하고, 이들을 모두 구현하여 통일된 프레임워크 위에서 실험한 논문입니다. 이 글은 거의 이 논문에 기반한 정리 포스팅인데, 논문의 메인인 실험 결과를 정리하지 않았기 때문에 그렇게 분류해놓지는 않았습니다. 이부분의 증명은 이 글의 Scope를 너무 많이 벗어납니다. &amp;#8617;</summary></entry><entry><title type="html">논문읽기 : DELTACON</title><link href="http://localhost:4000/cs-adventure/deltacon/" rel="alternate" type="text/html" title="논문읽기 : DELTACON" /><published>2021-09-10T00:00:00+09:00</published><updated>2021-09-10T00:00:00+09:00</updated><id>http://localhost:4000/cs-adventure/deltacon</id><content type="html" xml:base="http://localhost:4000/cs-adventure/deltacon/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#key-ideas&quot; id=&quot;markdown-toc-key-ideas&quot;&gt;Key Ideas&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#concepts&quot; id=&quot;markdown-toc-concepts&quot;&gt;Concepts&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#similarity-measure-properties&quot; id=&quot;markdown-toc-similarity-measure-properties&quot;&gt;Similarity measure properties&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#deltacon-algorithm&quot; id=&quot;markdown-toc-deltacon-algorithm&quot;&gt;DELTACON Algorithm&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#scalability&quot; id=&quot;markdown-toc-scalability&quot;&gt;Scalability&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thoughts&quot; id=&quot;markdown-toc-thoughts&quot;&gt;Thoughts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;Koutra, D., Vogelstein, J. T., &amp;amp; Faloutsos, C. (2013). DeltaCon : A Principled Massive-Graph Similarity Function. Proceedings of the 2013 SIAM International Conference on Data Mining, 10(3), 162–170. https://doi.org/10.1137/1.9781611972832.18&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;이번에 정리할 논문은 &lt;strong&gt;DELTACON&lt;/strong&gt; 이라는 Graph similarity metric을 제시한, DELTACON: A Principled Massive-Graph Similarity Function으로, 2013년 SIAM International Conference on Data Mining에 발표된 논문입니다. (SIAM과 IEEE에서 진행하는 똑같은 이름의 Conference가 있어서, 이쪽을 보통 SDM으로 약칭합니다). 이 논문에서는 그래프 유사도가 만족해야 할 기본적인 기준들을 제시하고, 그 기준에 맞는 실제 유사도 메트릭을 제시하였습니다.&lt;/p&gt;

&lt;p&gt;두 그래프 $G_1 = (V_1, E_1), G_2 = (V_2, E_2)$ 가 주어졌을 때, 우리는 두 그래프의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;유사도&lt;/code&gt; 를 측정하는 어떤 좋은 메트릭을 갖고 싶습니다. 예를 들어, 큰 그래프 $G$가 시간의 흐름에 따라 변화한다면 - 즉, $G_1, \dots G_n$ 에 대해서, $d(G_i, G_{i-1})$ 이 최대인 시점 $i$를 확인하면 anomally를 알 수 있을 것입니다. 이 논문에서는 Node correspondence까지 주어진 상황에서의 그래프 유사도에 대해서만 다룹니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;key-ideas&quot;&gt;Key Ideas&lt;/h1&gt;
&lt;h2 id=&quot;concepts&quot;&gt;Concepts&lt;/h2&gt;
&lt;p&gt;뭔가 노드 간의 연결관계를 수치화해서 알고 있다면, 이를 비교할 수 있을 것 같습니다. 예를 들어, Random walk with Restart 같은 방법을 이용 (이 방법에 대한 설명은 Advanced-algorithm 쪽으로 제가 포스팅한 적이 있습니다. &lt;a href=&quot;/advanced-algorithms/random-walk-on-graphs/&quot;&gt;링크&lt;/a&gt;) 하여, 노드간의 연결정도를 행렬로 만들어 놨다면 이 행렬이 그래프의 어떤 구조를 가지고 있다고 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 논문에서는, RwR은 아니고 이보다 좀더 최신이며 여러 좋은 성질을 갖는 Fast Belief Propagation이라는 방법을 사용합니다. 이 방법을 사용할 때, 노드 간의 연결성을 포함하는 $n \times n$ 행렬은 다음과 같이 계산됩니다. 
\(S = [s_{ij}] = \left(I + \epsilon^2 D - \epsilon A\right)^{-1}\)
여기서, $A$는 그래프의 인접행렬을, $D$는 노드 $i$의 degree를 $d_{ii}$로 하는 대각행렬을 사용합니다.&lt;/p&gt;

&lt;h2 id=&quot;similarity-measure-properties&quot;&gt;Similarity measure properties&lt;/h2&gt;
&lt;p&gt;이 논문에서는 다음과 같은 몇가지 성질들을 &lt;strong&gt;Graph Similarity Measure&lt;/strong&gt;가 가져야 할 성질들이라고 주장합니다. 상당수가 우리의 직관에 기반하였기 때문에 자연스럽게 이해할 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Identity&lt;/strong&gt; : $sim(G, G) = 1$. 매우 자연스럽습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Symmetry&lt;/strong&gt; : $sim(G_1, G_2) = sim(G_2, G_1)$. 역시 매우 자연스럽습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zero Property&lt;/strong&gt; : Complete graph $K_n$ 과 Vertex $n$개에 edge는 하나도 없는 zero graph $Z_n$을 생각해 보겠습니다. 이때, $d(K_n, Z_n) \to 0$ as $n \to \infty$ 를 원합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Edge Importance&lt;/strong&gt; : Edge가 달라지는 변화들 중, connected component의 개수가 바뀌면 특히 더 큰 차이로 간주합니다. 즉, $K_n$ 과 $K_n$을 edge 하나로 이어놓은 그래프에서 bridge는 다른 edge들보다 더 중요합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Weight Awareness&lt;/strong&gt; : Weighted graph에서, weight이 큰 edge에서 일어나는 변화는 더 중요합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Submodularity&lt;/strong&gt; : 같은 크기의 그래프에서, edge 하나의 중요도는 dense graph에서가 sparse graph에서보다 덜 중요합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Focus Awareness&lt;/strong&gt; : 그래프에서 edge들에 변화 (추가 또는 제거) 가 이루어질 때, 한 점을 노리고 한쪽에 집중된 변화는 랜덤한 변화보다 더 중요합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deltacon-algorithm&quot;&gt;DELTACON Algorithm&lt;/h2&gt;
&lt;p&gt;DELTACON은 앞서 제시한 행렬 $S$를 이용, 다음과 같은 distance를 계산합니다. 
\(d(G_1, G_2) = \sqrt{\sum_{i = 1}^{n} \sum_{j = 1}^{n} \left(\sqrt{S_1(i, j)} - \sqrt{S_2(i, j)}\right)^2}\)
행렬간의 거리가 굉장히 특이하게 정의되는데, 이를 Jefries-Matusita distance 라고 부른다고 합니다. 루트의 차를 제곱하는 신기한 방식으로 동작하는데, 일반적인 Euclidean distance와는 달리 이 distance를 사용할 때 위 &lt;strong&gt;성질들&lt;/strong&gt; 을 잘 만족합니다. 이 부분은 이 논문에서 수학적으로 엄밀하게 논증되지는 않았고, 데이터 그래프에 대해 실험적으로 검증되었습니다.&lt;/p&gt;

&lt;p&gt;우리는 그래프 유사도를 $[0, 1]$ 에 집어넣고 싶기 때문에, $sim(G_1, G_2) = \frac{1}{1 + d(G_1, G_2)}$ 를 사용합니다.&lt;/p&gt;

&lt;p&gt;이 sim 함수를 DELTACON이라고 부릅니다.&lt;/p&gt;

&lt;h2 id=&quot;scalability&quot;&gt;Scalability&lt;/h2&gt;
&lt;p&gt;Anomally detection 등에 쓰인다는 것을 통해 알 수 있듯이, 그래프 유사도는 많은 수의 그래프를 대상으로 해야 할 수도 있기 때문에, 가능한 빨라야 합니다.&lt;/p&gt;

&lt;p&gt;Deltacon 알고리즘에서 가장 오래 걸리는 부분은 $S$행렬의 계산입니다. $S$행렬은 $S = [s_{ij}] = \left(I + \epsilon^2 D - \epsilon A\right)^{-1}$ 와 같이 역행렬로 정의되는데, 일반적인 matrix가 아니라 특수한 graph structure가 있기 때문에 FaBP 알고리즘을 이용하여 $O(n^2)$ 시간에 계산할 수 있다고 합니다. 이후의 Matusita distance는 당연히 $O(n^2)$에 계산 가능하므로, 이 알고리즘은 $O(n^2)$ 입니다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 DELTACON의 좀더 빠르게 작동하는 approximation 버전을 제시하고 있습니다. $n^2$보다 빠르게 하기 위해서는, Matusita distance 계산이 일단 $O(n^2)$ 시간은 무조건 걸리기 때문에 행렬 자체를 줄여야 합니다. 이를 위해, affinity를 계산하기는 하는데 노드 $i$에 대해 모든 노드 $j$의 affinity가 아닌, 노드를 적당히 묶어 $g$개의 그룹으로 만들어서 $i$에서 $j$번 그룹으로의 affinity를 계산합니다. 이는 즉, $S$행렬에서 임의로 열들을 $g$개의 group으로 묶어서 더함으로써 $n \times g$행렬을 묶는다는 것입니다. $g$를 충분히 작게 하고, 구현을 잘 하면 이 알고리즘을 edge 개수에 대해 linear하게 돌게 할 수 있다고 합니다.&lt;/p&gt;

&lt;p&gt;이때, 이렇게 approximate한 similarity는 항상 실제 similarity보다 큰 값을 갖습니다. (증명은 부록에만 수록되어 있으며, 그렇게 어렵지는 않습니다. 증명이 공개된 링크를 첨부합니다. &lt;a href=&quot;https://web.eecs.umich.edu/~dkoutra/papers/DeltaCon_KoutraVF_withAppendix.pdf&quot;&gt;링크&lt;/a&gt;)&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;DELTACON은 무엇보다 Graph Similarity Measure가 가져야 할 좋은 성질들을 (정성적으로나마) 제시하였고, 이 성질들을 만족하는 실제 similarity measure를 찾아냈으며, 실험적으로 이를 검증하였다는 의의가 있습니다. 특히 다른 Similarity measure (Graph edit distance, spectral methods 등) 들은 이러한 그래프에 대한 직관적인 성질들이 전혀 고려되지 않았는데, 이런 유사도들에 비해 DELTACON이 얼마나 제시한 조건들을 잘 맞추는지를 상당히 extensive한 실험을 통해 검증하였습니다. 특히 Graph edit distance 등 계산 시간이 굉장히 오래 걸리는 알고리즘들에 비해, exact도 quadratic이고 이를 edge 개수에 선형이 되게 더 개선했기 때문에 다양한 활용이 가능할 것 같습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Graph의 노드 대신 edge에 label이 주어진다면, 이를 자연스럽게 확장할 수 있을까요?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;실험적 검증을 넘어서서, 성질들을 수식으로 표현하고 논증하는 방법은 없을까요?
    &lt;ul&gt;
      &lt;li&gt;부록에는 Edge importance 성질과 zero property에 대해서는 증명하고 있으며, 나머지 성질들에 대해서는 &lt;strong&gt;interesting future work&lt;/strong&gt; 라고 남겨두었습니다.&lt;/li&gt;
      &lt;li&gt;Focus Awareness와 같은 성질들이 문제인데.. 잠깐 생각해보면, edge 하나가 변화할 때, 각 점 $i$에 대해 새로 생긴/제거된 edge까지의 거리를 잴 수 있습니다. 이 거리를 $x_i$라고 하면, 변화 $m$번에 대해 행렬 $x_{m, i}$를 생각할 수 있겠습니다. Edge가 한쪽을 타겟팅한다는 것은, $x_{m, i}$의 각 열 - 즉, $m$번의 변화가 이 vertex로부터 얼마의 거리에서 일어나는지를 모은 벡터 - 의 표준편차 같은 통계적인 성질들을 이용하여 측정할 수 있을 것 같기도 합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Edge 하나가 변화하면서, 변화 전 그래프 $G$와 변화 후 그래프 $G’$간의 deltacon similarity 또는 그 근사값을 측정하는 더 빠른 방법은 없을까요? 바뀌는 edge가 1개인데 $n^2$ 이나 $n$ 시간을 지불하기는 좀 아깝습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Zero Property에서, $d(K_n, G_n)$ 이 항상 0이 아니라 0으로 수렴한다는 것이 약간 오묘합니다. 전체적으로 그래프 유사도가 크기에 많은 영향을 받는 것 같습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;FaBP가 왜 $O(n^2)$ 에 작동하는지는 아직 공부하지 못했습니다. 전반적으로 후반부의 시간 복잡도 증명이 약간 &lt;strong&gt;잘 구현하면 된다&lt;/strong&gt; 는 식으로 쓰여 있고, 엄밀하게 증명되어 있지 않다는 점은 조금 아쉬웠는데, &lt;a href=&quot;https://github.com/ZhenguoChen/DeltaCon&quot;&gt;Github Repo&lt;/a&gt; 에 꽤 읽기 쉬운 코드가 있어서 그럭저럭 납득할 수 있었습니다. Sparse matrix의 성질을 잘 사용하는 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="cs-adventure" /><category term="graph theory" /><summary type="html">Contents</summary></entry><entry><title type="html">Introduction to Optimization / Gradient Descent</title><link href="http://localhost:4000/deep-learning-study/opt-and-gd/" rel="alternate" type="text/html" title="Introduction to Optimization / Gradient Descent" /><published>2021-09-03T00:00:00+09:00</published><updated>2021-09-03T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/opt-and-gd</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/opt-and-gd/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#intro-to-optimization&quot; id=&quot;markdown-toc-intro-to-optimization&quot;&gt;Intro to Optimization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gradient-descent&quot; id=&quot;markdown-toc-gradient-descent&quot;&gt;Gradient Descent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 1강 (9월 2일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;intro-to-optimization&quot;&gt;Intro to Optimization&lt;/h2&gt;

&lt;p&gt;우리는 다음과 같은 최적화 문제를 생각한다.&lt;/p&gt;

&lt;p&gt;최적화 문제란, 어떤 Decision variable $x$를 조절하여 Objective function
$f$를 최소화 / 최대화 하는 문제를 말한다. 이때, equality 또는 inequality
constraint (제약조건) 들이 주어질 수 있다. 즉 다음과 같은 형태의 문제들.
\(\underset{x \in \R^p}{\minimize} \ f(x)  \ \subto \  h(x) = 0,\ g(x) \leq 0\)&lt;/p&gt;

&lt;p&gt;어차피 최소화와 최대화는 부호를 바꾸면 동치이므로, 앞으로는 최소화
문제만 생각한다.&lt;/p&gt;

&lt;p&gt;모든 제약 조건을 만족하는 점을 &lt;strong&gt;Feasible point&lt;/strong&gt;라 한다. Feasible
point가 아예 없는 경우 &lt;strong&gt;infeasible&lt;/strong&gt;하다.&lt;/p&gt;

&lt;p&gt;최적화 문제를 Constraint 유무에 따라 Unconstrained / Constrained로
나눈다.&lt;/p&gt;

&lt;p&gt;최적화 문제의 답은 Optimal value $p^\star$ 와 solution $x^\star$를 찾는 것이다.
즉…
\(p^* = \inf \Setcond{f(x)}{x \in \R^n, x \text{ feasible }}, \quad f(x^*) = p^*\)
ML 세팅에서는, $0 \leq p^* &amp;lt; \infty$ 인 경우를 주로 생각한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;예시&lt;/strong&gt; : Curve-Fitting, 즉 입력 데이터 $x_1 \dots x_n$ 과 그 label
$y_1 \dots y_n$에 대해, 입력값과 label의 관계를 찾는 문제. 대표적으로, Least square 문제를 생각할 수 있다. 주어진 입력과 결과를
가장 가깝게 근사하는 일차함수 찾기.&lt;/p&gt;

&lt;p&gt;최적화 문제에서는 극소 (Local minima) 와 최소 (Global minima) 를
생각해야 한다. 일반적으로, non-convex 함수의 global minima를 찾는 것은
어렵다.&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h2&gt;

&lt;p&gt;미분가능한 함수 $f$에 대해, 가장 간단한 unconstrained optimization
problem을 해결하고자 한다. \(\underset{x \in \R^p}{\minimize} \ f(x)\)
ML 세팅에서는 almost everywhere differentiable이면 대충 미분가능하다고
말하는 경우 많음.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm (Gradient Descent)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha_k &amp;gt; 0$ 에 대해
다음을 반복한다. \(x^{k+1} = x^k - \alpha_k \nabla{f(x^k)}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;대략의 아이디어&lt;/strong&gt; :
$x^k$ 근처에서 $f$를 테일러 전개하면,
\(f(x) = f(x^k) + \nabla f (x^k)^T (x - x^k) + \order{\norm{x - x^k}^2}\)
즉, $x = x^{k+1} = x^k - \alpha_k \nabla{f(x^k)}$ 대입하면,
\(f(x^{k+1}) = f(x^k) - \alpha_k \norm{\nabla{f(x^k)}}^2 + \order{\alpha_k^2}\)
적당히 $\alpha_k$를 충분히 작게 잡으면, $f(x^{k+1})$ 이 $f(x^k)$보다
작게 할 수 있을 것 같다.&lt;/p&gt;

&lt;p&gt;일반적으로, Gradient Descent는 Global 한 최적해를 보장하지 않는다.
Local한 최적해를 찾아간다는 것도 일반적인 조건에서는 안 되고… 대신에,
조건이 충분히 좋으면 거의 비슷한 명제, $\nabla f(x^k) \to 0$ 을 보일 수
있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;정리 (Gradient Descent의 수렴성)&lt;/strong&gt;&lt;br /&gt;
$f : \R^n \to \R$ 이 미분가능하고, $\nabla f$ 가 $L$-Lipschitz 연속이며,
$f$가 $-\infty$가 아닌 최소값을 가질 때, Gradient descent
\(x^{k+1} = x^k - \alpha \nabla{f(x^k)}\) 은,
$\alpha \in \left(0, \frac{2}{L}\right)$에 대해, $\nabla f(x^k) \to 0$
을 보장한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;
$L$-Lipschitz 조건이 필요한 이유는, $\nabla f$ 가 적당히 smooth 해야
테일러 전개의 근사가 잘 맞기 때문.&lt;/p&gt;

&lt;p&gt;이 생각을 보조정리로 활용한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lemma (Lipschitz Gradient Lemma)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$f : \R^n \to R$ 이 미분가능하고, $\nabla f$ 가 $L$-Lipschitz 연속이면, 다음이 성립한다.
\(f(x + \delta) \leq f(x) + \nabla f(x)^T \delta + \frac{L}{2}\norm{\delta}^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lemma의 증명(살짝 Rough하게)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$g(t) = f(x + t\delta)$ 로 두면, $g’(t) = \nabla f(x + t\delta)^T \delta$ 가 된다. 이때 $g’$는 직접
계산해 보면 $L\norm{\delta}^2$-Lipschitz 임을 알 수 있다.&lt;/li&gt;
  &lt;li&gt;이제, $f(x + \delta) = g(1)$ 은, 다음과 같이 계산한다.
\(f(x + \delta) = g(1) = g(0) + \int_{0}^{1} g'(t) \dd{t} \leq f(x) + \int_{0}^{1} (g'(0) + L\norm{\delta}^2 t) \dd{t} = f(x) + \nabla f(x)^T \delta + \frac{L}{2}\norm{\delta}^2\)&lt;/li&gt;
  &lt;li&gt;따라서 주어진 부등식이 성립한다. ◻&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;수학적으로 깔끔하게 증명하기 위해, 보조정리를 하나 더 쓰자.&lt;br /&gt;
&lt;strong&gt;Lemma (Summability Lemma)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Non-negative sequence $V_i$, $S_i$ 가 $V_{k+1} \leq V_k - S_k$ 를 만족할 때, $S_k \to 0$ 이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lemma의 증명&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$V_{k+1} + \sum_{i = 0}^{k} S_i \leq V_0$에서, $k \to \infty$ 를 취하면, $\sum_{i = 0}^{\infty} S_i \leq V_0 &amp;lt; \infty$ 이다. 급수가 수렴할 때, 일반항이 0으로 수렴함이 알려져 있으므로, 주어진 명제가 성립한다. ◻&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 마지막으로 앞선 정리 - Gradient Descent의 수렴성 비슷한 정리 - 를 증명한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lipchitz Gradient Lemma에 의해, $f(x^{k+1}) \leq f(x^k) - \alpha\left(1 - \frac{\alpha L}{2}\right)\norm{\nabla(x^k)}^2$ 이다.&lt;/li&gt;
  &lt;li&gt;또한, $V_k = f(x^k) - f(x^\star)$, $S_k = \alpha\left(1 - \frac{\alpha L}{2}\right)\norm{\nabla(x^k)}^2$ 라 하면, 주어진 수열들이 음수가 아니며 Summability Lemma의 조건을 만족함을 안다. 따라서, $S_k \to 0$, 즉 $\norm{\nabla(x^k)}^2 \to 0$ 이므로 $\nabla f(x^k) \to 0$ 이다. ◻&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">8월 3-4주차 Weekly PS</title><link href="http://localhost:4000/ps-weekly/ps-weekly-21Aug4/" rel="alternate" type="text/html" title="8월 3-4주차 Weekly PS" /><published>2021-08-31T00:00:00+09:00</published><updated>2021-08-31T00:00:00+09:00</updated><id>http://localhost:4000/ps-weekly/ps-weekly-21Aug4</id><content type="html" xml:base="http://localhost:4000/ps-weekly/ps-weekly-21Aug4/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#recent-updates&quot; id=&quot;markdown-toc-recent-updates&quot;&gt;Recent Updates&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rounds&quot; id=&quot;markdown-toc-rounds&quot;&gt;Rounds&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#facebook-hackercup-qualification-round&quot; id=&quot;markdown-toc-facebook-hackercup-qualification-round&quot;&gt;Facebook HackerCup, Qualification Round&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#problems&quot; id=&quot;markdown-toc-problems&quot;&gt;Problems&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#boj-1086-박성원&quot; id=&quot;markdown-toc-boj-1086-박성원&quot;&gt;BOJ 1086 박성원&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#boj-1533-길의-개수&quot; id=&quot;markdown-toc-boj-1533-길의-개수&quot;&gt;BOJ 1533 길의 개수&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2009-baltic-olympiad-of-informatics-p2-boj-3356-라디오-전송&quot; id=&quot;markdown-toc-2009-baltic-olympiad-of-informatics-p2-boj-3356-라디오-전송&quot;&gt;2009 Baltic Olympiad of Informatics P2, BOJ 3356 라디오 전송&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2013-한국정보올림피아드-지역본선-고등부-5번-boj-7575-바이러스&quot; id=&quot;markdown-toc-2013-한국정보올림피아드-지역본선-고등부-5번-boj-7575-바이러스&quot;&gt;2013 한국정보올림피아드 지역본선 고등부 5번, BOJ 7575 바이러스&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2017-연세대학교-프로그래밍-경진대회-boj-14574-헤븐스-키친&quot; id=&quot;markdown-toc-2017-연세대학교-프로그래밍-경진대회-boj-14574-헤븐스-키친&quot;&gt;2017 연세대학교 프로그래밍 경진대회, BOJ 14574 헤븐스 키친&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2016-nordic-collegiate-programming-contest-boj-13355-bless-you-autocorrect&quot; id=&quot;markdown-toc-2016-nordic-collegiate-programming-contest-boj-13355-bless-you-autocorrect&quot;&gt;2016 Nordic Collegiate Programming Contest, BOJ 13355 Bless You Autocorrect&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#2017-central-european-olympiad-in-informatics-boj-15246-one-way-streets&quot; id=&quot;markdown-toc-2017-central-european-olympiad-in-informatics-boj-15246-one-way-streets&quot;&gt;2017 Central European Olympiad in Informatics, BOJ 15246 One Way Streets&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;August 16 - August 31, 2021&lt;/p&gt;

&lt;p&gt;이 글에 구현코드 링크가 없더라도 &lt;a href=&quot;https://github.com/gratus907/Gratus_PS&quot;&gt;PS 레포 링크&lt;/a&gt; 에 가서 대회 단위로 들어가면 보통 올려놓은 코드를 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;BOJ의 문제 중 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[출처]&lt;/code&gt; 에 대회명이 적혀있지 않으면 제 레포에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BOJ Original&lt;/code&gt;에 있습니다.&lt;/p&gt;

&lt;p&gt;읽는 사람이 문제를 읽고 조금 생각해봤다고 가정하고, 대략적인 아이디어만 간단히 적을 생각입니다 ㅎㅎ&lt;/p&gt;

&lt;h2 id=&quot;recent-updates&quot;&gt;Recent Updates&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Hackercup Qual round에 참여했습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rounds&quot;&gt;Rounds&lt;/h2&gt;

&lt;h3 id=&quot;facebook-hackercup-qualification-round&quot;&gt;Facebook HackerCup, Qualification Round&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Qual round라서 별로 할말은 없는듯 합니다. C2는 재밌지만 구현을 포기했고, C1까지는 재밌게 풀었습니다.&lt;/li&gt;
  &lt;li&gt;FHC는 정말 &lt;strong&gt;해괴한&lt;/strong&gt; 채점 방식을 가지고 있습니다. ㅋㅋ…&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;problems&quot;&gt;Problems&lt;/h2&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;boj-1086-박성원&quot;&gt;BOJ 1086 박성원&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;난이도 Platinum V&lt;/li&gt;
  &lt;li&gt;Bitmask DP를 하면 됩니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dp[BIT][REM]&lt;/code&gt; 을, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;BIT&lt;/code&gt; 에 해당하는 비트마스크를 붙여 나머지 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;REM&lt;/code&gt;을 만드는 경우의 수로 정의하고, 아직 쓰지 않은 원소들을 DP로 잘 관리합니다.&lt;/li&gt;
  &lt;li&gt;자세한 것은 코드 참고.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;boj-1533-길의-개수&quot;&gt;BOJ 1533 길의 개수&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;난이도 Platinum IV&lt;/li&gt;
  &lt;li&gt;가중치 없는 그래프의 인접행렬 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt;에 대해, $A^n$을 계산하면, 그 $i, j$ 번째 칸은 $i \to j$ 로 $n$개의 간선을 사용해서 도달하는 방법의 경우의 수에 해당한다는 사실이 잘 알려져 있습니다.&lt;/li&gt;
  &lt;li&gt;가중치가 5 이하이므로, 정점을 복사하는 트릭을 사용합니다. 만약 1번 정점에서 2번 정점으로 3의 시간이 걸린다면, $(1, 0)$ 에서 $(2, 0)$ 으로 그어주는 것이 아니라, $(1, 0)$ 에서 $(2, 2)$ 로, $(2, 2) \to (2, 1) \to (2, 0)$ 으로 가게 해서 3개의 간선을 거치도록 강제합니다.&lt;/li&gt;
  &lt;li&gt;이제 위 사실을 사용할 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;2009-baltic-olympiad-of-informatics-p2-boj-3356-라디오-전송&quot;&gt;2009 Baltic Olympiad of Informatics P2, BOJ 3356 라디오 전송&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;난이도 Platinum IV&lt;/li&gt;
  &lt;li&gt;문제의 정의를 잘 읽어보면, KMP 알고리즘의 실패함수를 이용하여 $n - p[n]$ 이 답임을 알 수 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;2013-한국정보올림피아드-지역본선-고등부-5번-boj-7575-바이러스&quot;&gt;2013 한국정보올림피아드 지역본선 고등부 5번, BOJ 7575 바이러스&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;난이도 Platinum V&lt;/li&gt;
  &lt;li&gt;$N$개의 문자열 각각에 대해, 길이가 $K$인 모든 부분 문자열과 그 역 문자열을 저장할 수 있다면&lt;/li&gt;
  &lt;li&gt;이들을 비교해서 쉽게 풀 수 있을 것입니다.&lt;/li&gt;
  &lt;li&gt;시간 복잡도상 이를 직접 비교할 수는 없지만, 해시값을 비교할 수는 있습니다.&lt;/li&gt;
  &lt;li&gt;매우 느리지만 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set_intersection&lt;/code&gt;을 쓰면 구현이 매우 쉽고, 이 문제를 통과하기에는 충분합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2017-연세대학교-프로그래밍-경진대회-boj-14574-헤븐스-키친&quot;&gt;2017 연세대학교 프로그래밍 경진대회, BOJ 14574 헤븐스 키친&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;난이도 Platinum V&lt;/li&gt;
  &lt;li&gt;대결에서 승리한 쪽이 승천해버리기 때문에 한 노드를 두 번 포함할 수 없습니다.&lt;/li&gt;
  &lt;li&gt;즉… 대진표가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Spanning tree&lt;/code&gt;를 이루어야겠습니다.&lt;/li&gt;
  &lt;li&gt;주어진 점수 함수로 complete graph를 만들고, 그 maximum spanning tree를 쓰고 싶습니다.&lt;/li&gt;
  &lt;li&gt;그런데, 이 트리로 올바른 대진표를 만들 수 있을까요?&lt;/li&gt;
  &lt;li&gt;네. DFS를 따라 돌면서, 리프 노드와 리프가 아닌 노드 간의 경기에 대해서는 리프 노드가 승리하고 승천해야 합니다. (리프가 아닌 노드는 나중에 또 써야 하므로). 이제, 새롭게 리프가 된 노드가 있다면 이 노드는 자기 parent 노드와의 대결에서 승리해서 승천해도 됩니다.&lt;/li&gt;
  &lt;li&gt;DFS를 이용하면 쉽게 구현 가능합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2016-nordic-collegiate-programming-contest-boj-13355-bless-you-autocorrect&quot;&gt;2016 Nordic Collegiate Programming Contest, BOJ 13355 Bless You Autocorrect&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;난이도 Platinum I&lt;/li&gt;
  &lt;li&gt;솔직히 이정도로 어려운지는 잘 모르겠습니다.&lt;/li&gt;
  &lt;li&gt;Trie를 골자로 한 그래프를 만듭니다. 단, autocomplete 기능을 이용할 수 있으므로 문제의 정의에 합당하게 TAB키를 길이가 1인 간선으로 표현해주고, BACKSPACE키도 길이가 1인 간선으로 표현해 줍니다.&lt;/li&gt;
  &lt;li&gt;이렇게 만든 그래프 위에서 BFS를 돌려서, 모든 노드로 갈 수 있는 최단 경로의 길이를 미리 계산합니다.&lt;/li&gt;
  &lt;li&gt;이제, query string이 주어지면, 이 query string의 어디까지를 trie 위에서 찾을 수 있는지 보고, 그 최단 경로를 따 온 다음, 나머지는 일일히 타이핑해주면 끝입니다.&lt;/li&gt;
  &lt;li&gt;구현량이 많지만 각각을 따로 구현해서 합칠 수 있으므로 별로 어렵지는 않습니다. 저는 구현의 편의를 위해 트라이와 그래프를 따로따로 만들었지만, 구현을 조심해서 한다면 트라이를 따로 만들지 않고 바로 적절히 그래프를 (트라이를 뼈대 삼아) 구현하면 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2017-central-european-olympiad-in-informatics-boj-15246-one-way-streets&quot;&gt;2017 Central European Olympiad in Informatics, BOJ 15246 One Way Streets&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;난이도 Platinum II&lt;/li&gt;
  &lt;li&gt;IOI를 제외하고 가장 어려운 OI중 하나인 CEOI의 문제입니다. 솔직히 저는 P2보다 훨씬 어렵다고 생각합니다.&lt;/li&gt;
  &lt;li&gt;별도로 포스팅할 예정입니다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="ps-weekly" /><summary type="html">Contents</summary></entry><entry><title type="html">2021 2학기 시작</title><link href="http://localhost:4000/retrospects-and-plans/starting-2021-fall/" rel="alternate" type="text/html" title="2021 2학기 시작" /><published>2021-08-31T00:00:00+09:00</published><updated>2021-08-31T00:00:00+09:00</updated><id>http://localhost:4000/retrospects-and-plans/starting-2021-fall</id><content type="html" xml:base="http://localhost:4000/retrospects-and-plans/starting-2021-fall/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#컴공-전공과목&quot; id=&quot;markdown-toc-컴공-전공과목&quot;&gt;컴공 전공과목&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#수학-전공과목&quot; id=&quot;markdown-toc-수학-전공과목&quot;&gt;수학 전공과목&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#기타-공부&quot; id=&quot;markdown-toc-기타-공부&quot;&gt;기타 공부&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#problem-solving--competitive-programming&quot; id=&quot;markdown-toc-problem-solving--competitive-programming&quot;&gt;Problem Solving / Competitive Programming&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#수리과학부-졸업논문&quot; id=&quot;markdown-toc-수리과학부-졸업논문&quot;&gt;수리과학부 졸업논문&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#gsim-project&quot; id=&quot;markdown-toc-gsim-project&quot;&gt;GSIM project&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#posting&quot; id=&quot;markdown-toc-posting&quot;&gt;Posting&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;다음 학기 목표.&lt;/p&gt;

&lt;h2 id=&quot;컴공-전공과목&quot;&gt;컴공 전공과목&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;계산 이론 : 이름은 계산이론이지만 실제로는 고급 알고리즘 느낌의 수업입니다.
    &lt;ul&gt;
      &lt;li&gt;진학을 희망하는 분야의 수업이기도 하고, 재밌게 들을 수 있을 것 같습니다.&lt;/li&gt;
      &lt;li&gt;String 알고리즘 쪽을 많이 배우는것 같던데, 이쪽은 거의 몰라서 새로운 내용도 많습니다.&lt;/li&gt;
      &lt;li&gt;수업에서 배운 내용들을 (아마도) 고급 알고리즘 정리 포스팅 쪽에 계속 노트정리처럼 올릴듯 합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;창의적 통합 설계 : 산학연계 프로젝트 과목입니다.
    &lt;ul&gt;
      &lt;li&gt;좋은 회사의 프로젝트를 따는 것이 과목의 거의 모든 것을 결정한다는 소문을 들었습니다.&lt;/li&gt;
      &lt;li&gt;어차피 모든 프로젝트가 ML일테니 ML 해본다고 생각하고 있습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;수학-전공과목&quot;&gt;수학 전공과목&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;현대대수학 II : 어쨌든 수학 근본과목.
    &lt;ul&gt;
      &lt;li&gt;Galois Theory 등을 배웁니다. 방학때 대충 한번 보긴 했지만, 사실 잘 모르겠네요&lt;/li&gt;
      &lt;li&gt;나름 학점 챙겨야 하니까, 연습문제 다 풀면서 좀 열심히 공부할것 같습니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;심층신경망의 수학적 기초 : 새로 생긴 수학과 ML 과목.
    &lt;ul&gt;
      &lt;li&gt;작년 2학기 최적화이론 강의하셨던 교수님께서 강의하십니다.&lt;/li&gt;
      &lt;li&gt;최적화이론에 대해 굉장히 좋은 기억이 있고, 정말 많이 배울수 있었던것 같아서 ML도 그런 느낌으로 배워볼 생각으로 신청했습니다.&lt;/li&gt;
      &lt;li&gt;소개원실-최적화와 창통설-심수개를 보며 데자뷰가 좀 있는데, 그런 일은 없었으면 합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;해석학특강 (심층학습의 수치해석) : (미정)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;기타-공부&quot;&gt;기타 공부&lt;/h2&gt;

&lt;h3 id=&quot;problem-solving--competitive-programming&quot;&gt;Problem Solving / Competitive Programming&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;SNUPC 2021 Div2 수상하기. SNUPC는 앞으로 대학원때도 심심할때마다 PS로 기분전환하는 좋은 기회가 되어줄 예정이라 부담없이 Div2에서 3등상 정도 (작년이랑 비슷하게) 목표하고 있습니다.&lt;/li&gt;
  &lt;li&gt;ICPC 2021 좋은 팀원들 구해서 재밌게 즐기기. Little Piplup 이후 팀연습을 즐길수있는 좋은 팀원에 목말라 있습니다. :(&lt;/li&gt;
  &lt;li&gt;Codeforces 2200+, Atcoder 2000+ 찍기.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;수리과학부-졸업논문&quot;&gt;수리과학부 졸업논문&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;주제는 Image Segmentation 관련. Convolutionary Neural Network를 시작으로 다양하게 공부할게 많습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gsim-project&quot;&gt;GSIM project&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;친구들이랑 같이 진행하고 있는 일종의 아카데믹한 프로젝트.&lt;/li&gt;
  &lt;li&gt;관련 내용은 언젠가 포스팅할 예정입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;posting&quot;&gt;Posting&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;적어도 1주일에 하나정도씩은 개인 공부한거에 대해 (학교 수업 노트정리 빼고) 여기에 적어보기.&lt;/li&gt;
  &lt;li&gt;구체적으로는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CS-Adventure&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Advanced-Algorithms&lt;/code&gt; 쪽 포스팅 + 어쩌면 수학? 정도…&lt;/li&gt;
  &lt;li&gt;시험기간 빼고 10개 정도를 생각하고 있습니다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="retrospects-and-plans" /><summary type="html">Contents</summary></entry><entry><title type="html">VI. Binary Search Tree &amp;amp; Union Find</title><link href="http://localhost:4000/ds-alg-note/06-bst-unionfind/" rel="alternate" type="text/html" title="VI. Binary Search Tree &amp;amp; Union Find" /><published>2021-08-25T00:00:00+09:00</published><updated>2021-08-25T00:00:00+09:00</updated><id>http://localhost:4000/ds-alg-note/06-bst-unionfind</id><content type="html" xml:base="http://localhost:4000/ds-alg-note/06-bst-unionfind/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#binary-search-tree&quot; id=&quot;markdown-toc-binary-search-tree&quot;&gt;Binary Search Tree&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#stl-set-map&quot; id=&quot;markdown-toc-stl-set-map&quot;&gt;STL set, map&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#disjoint-set&quot; id=&quot;markdown-toc-disjoint-set&quot;&gt;Disjoint Set&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#naive-approach&quot; id=&quot;markdown-toc-naive-approach&quot;&gt;Naive Approach&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#using-trees&quot; id=&quot;markdown-toc-using-trees&quot;&gt;Using Trees&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#optimizations&quot; id=&quot;markdown-toc-optimizations&quot;&gt;Optimizations&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#time-complexity&quot; id=&quot;markdown-toc-time-complexity&quot;&gt;Time Complexity&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#additional-topics--problems&quot; id=&quot;markdown-toc-additional-topics--problems&quot;&gt;Additional Topics / Problems&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#programming-practice&quot; id=&quot;markdown-toc-programming-practice&quot;&gt;Programming Practice&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;binary-search-tree&quot;&gt;Binary Search Tree&lt;/h2&gt;

&lt;p&gt;Binary Search Tree란, 다음과 같은 성질을 만족하는 트리를 말합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;이진 트리입니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;항상 왼쪽 서브트리의 값은 자기 자신보다 작고, 오른쪽 서브트리의 값은
자기 자신보다 큽니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Binary Search Tree는 우리의 맥락에서 약간 벗어나 있으나 자료구조와
알고리즘 시간에 매우 중요하게 다룹니다. 익혀두는 것을 추천하지만, 우리가
앞으로 쓸 일은 아마도 없을 것입니다. 간단하게만 짚고 넘어가도록
하겠습니다.&lt;/p&gt;

&lt;p&gt;(i) &lt;strong&gt;삽입&lt;/strong&gt; : 삽입은 기본적으로, 루트에서부터 출발해서, 삽입할 자리를
    찾아가는 식으로 합니다. 대소관계에 따라 왼쪽으로 타고 내려갈지,
    오른쪽으로 타고 내려갈지를 정한 다음, 내려가야 할 자리가 비었으면 그
    자리에 집어넣습니다.&lt;/p&gt;

&lt;p&gt;(ii) &lt;strong&gt;삭제&lt;/strong&gt; : 삭제는 다음과 같이 수행합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;삭제할 값 $x$를 트리에서 찾습니다. (삽입에서 찾는 방법과
 비슷합니다.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이 노드를, $x$의 오른쪽 서브트리에서 가장 작은 값이 있는 노드와
 교환합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이제 그 자리에 교환되어 들어간 노드를 삭제합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;왼쪽 자식 노드가 있다면 그 노드는 가장 작은 겂이 있는 노드가
 아니므로 불가능하고, 따라서 노드의 자식이 2개일 수는 없습니다.
 자식이 1개라면, 삭제된 노드 자리로 끌어올립니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;자식이 없다면 그냥 넘어가도 됩니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;결국, 두 연산 모두 &lt;strong&gt;검색&lt;/strong&gt; 연산을 이용하여 이루어집니다.&lt;br /&gt;
이제, 시간 복잡도를 생각해 봅시다. 삽입 연산의 경우 검색 연산과 거의
동일하므로, 트리의 높이 $h$에 대해 $O(h)$ 시간이 들게 됩니다. 삭제의
경우, 검색 + 오른쪽 서브트리의 가장 작은 값 찾기의 두 번인데, 둘 모두
사실상 검색과 비슷한 연산이므로 $O(h)$ 시간입니다. 결국 삽입과 삭제 모두
$O(h)$ 시간이 드는 연산입니다. 그런데, 이진 트리의 경우 최악의 상황에서
$h$가 $n$까지 커질 수 있습니다. (한 줄로 쭉 늘어서 있는 경우)&lt;br /&gt;
우리는 별로 자세히 다루지는 않겠지만, 이러한 문제를 해결하기 위한 방법을
잠깐만 생각해 봅시다. Quick select때랑 약간 비슷한데, “약간의 시간을
지불해서”, “너무 나쁜 상황이 벌어지지 않게” 만들면 됩니다. 이것을
Balanced Binary Search Tree (BBST) 라고 부르고, 이를 구현하는 다양한
방법이 있습니다. 자세한 내용은 알고리즘 수업에서 다룹니다. 추가 자료를
Additional ii에 일부 제시해 두었습니다.&lt;/p&gt;

&lt;h3 id=&quot;stl-set-map&quot;&gt;STL set, map&lt;/h3&gt;

&lt;p&gt;C++의 라이브러리에는 매우 편한 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set&lt;/code&gt; 과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;map&lt;/code&gt;이 있습니다. 이 set과 map은
Balanced Binary Search Tree의 일종인 Red-Black Tree로 구현되어 있기
때문에, BBST를 실제로 구현해서 쓸 일은 보통 없습니다. 이 라이브러리의
사용법을 반드시 익히길 권합니다.&lt;br /&gt;
&lt;a href=&quot;http://boj.kr/f4fa91dacdf9424a9a0b2e0ab3f140d9&quot;&gt;예시 코드 보기 : BOJ 14425 문자열
집합&lt;/a&gt;&lt;br /&gt;
set, map, multiset, multimap은 활용도가 매우 높습니다. 참고로, priority
queue로 할 수 있는 모든 연산은 multiset으로 똑같이 할 수 있고, 시간
복잡도도 $\order{\log n}$으로 같습니다. 그렇다고 해서 두 코드의 수행
시간이 같거나 비슷할 것으로 기대해서는 안 됩니다. 항상, 시간 복잡도는
&lt;strong&gt;중요하지만&lt;/strong&gt;, 그렇다고 해서 &lt;strong&gt;전부는 아닙니다&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;disjoint-set&quot;&gt;Disjoint Set&lt;/h2&gt;

&lt;p&gt;이번 section에서 우리의 목표는, 다음과 같은 두 기능을 갖는 자료구조를
만드는 것입니다.&lt;/p&gt;

&lt;p&gt;(i) Union(a, b) : a가 들어 있는 집합과 b가 들어 있는 집합을 합치는 연산.&lt;/p&gt;

&lt;p&gt;(ii) Find(x) : x가 들어 있는 집합의 번호를 확인한다. 즉, Find(x) 와
     Find(y) 를 통해 두 원소가 같은 집합에 소속되어 있는지 확인하는
     작업이 목표.&lt;/p&gt;

&lt;p&gt;예를 들어, 1부터 5까지의 숫자가 있다고 할 때, Union(1, 2), Union(3, 4)
를 하고 나면 $\Set{1, 2}, \Set{3, 4}, \Set{5}$ 가 됩니다. 이때 Find(3)
과 Find(4)는 같아야 하고, Find(1)과는 달라야 합니다. 또한, Union(1, 4)
나 Union(2, 3) 등은 모두 $\Set{1, 2, 3, 4}, \Set{5}$ 로 만드는 과정을
수행해야 합니다.&lt;/p&gt;

&lt;h3 id=&quot;naive-approach&quot;&gt;Naive Approach&lt;/h3&gt;

&lt;p&gt;쉬운 방법으로, Linked List를 사용하는 방법을 예로 들 수 있습니다.
$n$개의 숫자가 있고, 이들에 적당히 operation을 수행하려고 한다고 합시다.
각각의 원소가 $p$, $q$개인 집합을 합치는 데 드는 시간은 구현에 따라
다르지만, 효율성을 위해 작은 리스트를 큰 리스트에 합치는 식으로 작업하면
$O(\min(p, q))$ 이지만 이는 최대 $n/2$ 까지이고, 결국 한번의 Union에
$O(n)$이 걸릴 수 있습니다. 또한, Find의 경우 모든 element를 뒤지면서 이
리스트에 소속되어 있는지 찾는 방법밖에 없으므로 $O(n)$이 걸리게 됩니다.
물론, 추가적인 메모리를 쓰면, 매번 각 원소가 자신이 소속된 리스트의
헤드를 가리키는 포인터를 관리하는 등 방법을 쓸 수는 있지만, 이것도
Union은 빨리 할 수 없습니다.&lt;/p&gt;

&lt;h3 id=&quot;using-trees&quot;&gt;Using Trees&lt;/h3&gt;

&lt;p&gt;생각을 달리하여, 다음과 같이 생각해 봅시다. 각 집합은 하나의 트리로
나타낼 것이고, 각 원소마다 자신의 부모 노드의 번호만 적어 놓습니다. 즉,
각 원소에 대해 par(x)를 항상 관리한다고 생각하겠습니다. 이때, Find(x)는
약간 생각을 바꿔서, 자신이 소속된 트리의 루트 노드를 찾는 연산이라고
생각합니다. (부모가 없는 루트 노드의 부모는 자기 자신)&lt;br /&gt;
그렇다면, Union을 할 때 굳이 모든 노드의 par을 바꿔야 할까요? 트리 A와
트리 B를 합치려고 한다면, A의 루트를 B의 루트 밑에 달아 주기만 하면 (즉,
par[root of A] = root of B) 한 번에 트리 A 전체를 트리 B에 달아 놓은
형태가 됩니다. 두 트리 (집합)의 Union이 끝났습니다!&lt;br /&gt;
이 방법을 생각해 보면, Union(x, y) 연산의 시간 복잡도는 결국 Find(x)와
Find(y)에 의해 결정됩니다. Find(x)하여, 그 찾은 루트를 Find(y)에 달아
주는 연산이 $\order{1}$이기 때문입니다. 그런데, Find 연산은 그 트리의
높이에 의해 결정되고, 최악의 경우 트리가 루트 밑으로 한 줄로 쭉 달릴 수
있으므로 $O(h) = O(n)$ 입니다. 그러면 별로 빨라진 것이 없습니다.&lt;/p&gt;

&lt;h3 id=&quot;optimizations&quot;&gt;Optimizations&lt;/h3&gt;

&lt;p&gt;위와 같은 처참한 상황을 막기 위해, 우리는 크게 세 가지를 생각합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Union by Rank : 각 트리마다, 항상 트리의 높이&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;를 따로 관리합니다.
이때, Union 연산에서 트리를 매달 때, 반드시 높이가 낮은 트리를
높이가 높은 트리에 매달도록 강제합니다. 이렇게 하면, 트리의 높이가
절대 $\log n$ 이상으로 커지지 않음을 보일 수 있습니다.
(Additional 3)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Union by Size : 각 트리마다, 트리의 크기 (노드의 개수) 를 관리하고,
작은 트리를 큰 트리에 붙이도록 강제합니다. 역시 Union by Rank와
마찬가지로, 트리의 높이가 절대 $\log n$ 이상으로 커지지 않음을 보일
수 있습니다. (Additional 4)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Path Compression : 매번 Find 연산을 하다 보면, $x$가 포함된 트리의
루트를 알게 됩니다. 이때, Heuristic적인 생각으로, 내가 3-4-1-5-2-6의
과정으로 3에서부터 parent를 타고 올라가 6에 도달했다면, 이 트리를
모두 뜯어버리고 3, 4, 1, 5, 2를 전부 6에 그대로 매달아도 됩니다. 이
연산은 트리의 높이를 줄여 줄 것 같습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;실제 구현에서 사용하는 방법은 [Union by Rank or Size] + [Path
Compression] 입니다. 이하, [Union Rule]과 [Path Comp] 라고
줄이겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;time-complexity&quot;&gt;Time Complexity&lt;/h3&gt;

&lt;p&gt;Additional 3과 4에서 다룬 바와 같이, [Union Rule] 은 한번 연산에 대략
$\order{\log n}$ 정도가 걸림을 보장합니다. Union Rule 없이 Path Comp
만으로는, 첫 몇번의 Path comp는 별로 효율적이지 못하지만 나중의 case들이
효율적이기 때문에, 상당히 좋은 Bound를 찾을 수 있습니다.&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 두 가지를
모두 사용하는, 효율적인 구현의 경우, Find 연산이 평균적으로 대단히
빠르게 수행됩니다. 이때, 이 시간 복잡도를 $\alpha(n)$ 이라는 함수로
씁니다. 이 함수는 Inverse Ackermann 함수라는 것인데, 우리가 상상할 수
있는 대부분의 함수보다 작은 값을 갖습니다. 인간이 가지고 있는 메모리를
모두 합쳐도, 그 안에 들어가는 $n$의 값에 대해 $\alpha(n) &amp;lt; 5$이기 때문에
우리는 이 함수를 사실상 상수라고 생각해도 큰 문제는 없습니다.&lt;/p&gt;

&lt;h2 id=&quot;additional-topics--problems&quot;&gt;Additional Topics / Problems&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Balanced Binary Search Tree의 예시로, AVL-Tree, Red-Black-Tree,
B-Tree와 그 특수한 형태인 2-3-4 Tree가 있습니다. 이 자료구조들은
크게 검색과 검색 기반 연산 (삽입, 삭제, 검색)을 $\order{\log n}$ 에
수행합니다. 그 밖에도, 일반적인 이런 트리로는 절대 수행할 수 없어
보이는 기괴한 연산을 제공하는 자료구조들이 존재합니다.&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; 우리는
다루지 않을 예정이고 사실 저도 코딩할 줄 모르지만 ‘루트를 바꾸는
연산’을 Amortized $\order{\log n}$에 해 준다거나 하는... 뭐 그런
것도 있다고 합니다 (?)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Union by rank만 사용하였을 때, 트리의 높이가 $O(\log n)$ 이상으로
증가하지 않는다는 사실을 납득하세요. 트리의 높이가 합치려는 트리의
높이 $h_1, h_2$보다 1만큼 증가하기 위해서는, 양쪽의 높이가 같아야
하며, 그러기 위해서는 그 트리의 노드 수는 적어도 $2h_1$개가 되어야
합니다. 귀납법을 통해, 높이가 $h$인 트리가 되려면 $2^h$개 정도의
노드가 필요함을 보이세요.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Union by size에 대해서, 위 문제와 같은 내용을 보이세요.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;2, 3에서 제시된 아이디어의 핵심을 요약하면, ‘매번 큰 쪽에 작은 쪽을 붙이도록 강제하면, 한번 합치는 연산을 할 때 결과물의 크기는 적어도 작은 쪽의 2배가 된다’ 라는 것입니다. 이 원칙은 당연해 보이지만, Tree DP 등에서 복잡도를 줄이는 핵심적인 트릭 중 하나입니다. 간단한 제약을 통해 $O(n^2)$ 시간 알고리즘을 $O(n \log n)$ 또는 $O(n \log^2 n)$ 으로 줄일 수 있기 때문입니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Wikipedia에는 Union Rule + Path Comp를 수행할 때, 시간 복잡도가
$O(\log^* n)$ 임을 보이는 증명이 있습니다. $\log^* n$ 이라는 함수는,
대략 $\log \log \log \dots \log n$의 값이 1보다 작아지기 위해 필요한
$\log$의 개수입니다. 이 함수도 당연히 매우 느리게 증가하기 때문에,
실용적으로는 5 이하의 값을 가진다고 가정해도 됩니다. CLRS 책의
chapter 21에는 Inverse ackermann 함수에 관한 증명이 수록되어
있습니다. 관심이 있다면 참고하세요. 우리가 다루기에는 필요 이상으로
복잡하고, 별로 중요하지 않습니다. 다만 두 증명 모두 상당히
Elegant합니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;($\star$) Union Find을 그래프의 용어로 쓰면, 노드들을 잇는 연산과 두
노드가 서로 연결되어 있는지 묻는 연산이라고 생각할 수 있습니다. 이를
Incremental connectivity라고 부릅니다. 반대로, 간선이 처음에는
연결되어 있고, 삭제되는 경우의 문제를 해결할 수 있을까요? 즉,
union-find의 union 대신 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;disconnect(u, v)&lt;/code&gt; 연산을 빠르게 구현할 수
있을까요? 이 문제는 incremental보다 훨씬 어렵습니다. 처음에 연결된
상태가 Tree인 경우, 1981년에 Evan과 Shiloach가 $O(n \log n)$
알고리즘을, 1997년에 Alstrup 등이 $O(n + m)$ 에 가능함을 보였습니다.
Planar graph에 대해서 선형 시간 알고리즘이 제시된 것은 2015년의
일입니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;($\star\star$) 이제, 두 문제를 합쳐 봅시다. connect와
disconnect연산을 모두 지원할 수 있을까요? 이 문제는 그래프가 모든
상황에서 Forest (서로 연결되지 않은 트리들) 임이 보장되는 경우 $O(n \log n)$ 에, 일반
그래프에서도 쿼리당 poly-logarithmic 시간에 풀 수 있음이 알려져
있습니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;programming-practice&quot;&gt;Programming Practice&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;C++의 STL multiset 등을 사용하여, BOJ 7662번을 해결해 보세요.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;처음으로 STL에서 아예 지원하지 않는 자료구조를 구현해 보게
되었습니다. Disjoint set 자료구조를 구현해 보고, 구현체를 BOJ
1717번에 제출해서 확인해 보세요. C++로 구현한 올바른 구현체는 100ms
미만으로 동작합니다. 만약 생각보다 시간이 오래 걸린다면, 다른 사람의
빠른 구현을 참고해서 어떤 부분을 개선할 수 있을지 알아보세요.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;엄밀하게는 높이와는 약간 다른데, 대충 높이라고 생각해도
논리진행에는 문제가 없습니다 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;상당히 복잡하고 별로 중요하지 않으므로 생략합니다 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;자료구조의 세계도 끝이 없습니다 :) &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="ds-alg-note" /><summary type="html">Contents Binary Search Tree STL set, map Disjoint Set Naive Approach Using Trees Optimizations Time Complexity Additional Topics / Problems Programming Practice Binary Search Tree Binary Search Tree란, 다음과 같은 성질을 만족하는 트리를 말합니다. 이진 트리입니다. 항상 왼쪽 서브트리의 값은 자기 자신보다 작고, 오른쪽 서브트리의 값은 자기 자신보다 큽니다. Binary Search Tree는 우리의 맥락에서 약간 벗어나 있으나 자료구조와 알고리즘 시간에 매우 중요하게 다룹니다. 익혀두는 것을 추천하지만, 우리가 앞으로 쓸 일은 아마도 없을 것입니다. 간단하게만 짚고 넘어가도록 하겠습니다. (i) 삽입 : 삽입은 기본적으로, 루트에서부터 출발해서, 삽입할 자리를 찾아가는 식으로 합니다. 대소관계에 따라 왼쪽으로 타고 내려갈지, 오른쪽으로 타고 내려갈지를 정한 다음, 내려가야 할 자리가 비었으면 그 자리에 집어넣습니다. (ii) 삭제 : 삭제는 다음과 같이 수행합니다. 삭제할 값 $x$를 트리에서 찾습니다. (삽입에서 찾는 방법과 비슷합니다.) 이 노드를, $x$의 오른쪽 서브트리에서 가장 작은 값이 있는 노드와 교환합니다. 이제 그 자리에 교환되어 들어간 노드를 삭제합니다. 왼쪽 자식 노드가 있다면 그 노드는 가장 작은 겂이 있는 노드가 아니므로 불가능하고, 따라서 노드의 자식이 2개일 수는 없습니다. 자식이 1개라면, 삭제된 노드 자리로 끌어올립니다. 자식이 없다면 그냥 넘어가도 됩니다. 결국, 두 연산 모두 검색 연산을 이용하여 이루어집니다. 이제, 시간 복잡도를 생각해 봅시다. 삽입 연산의 경우 검색 연산과 거의 동일하므로, 트리의 높이 $h$에 대해 $O(h)$ 시간이 들게 됩니다. 삭제의 경우, 검색 + 오른쪽 서브트리의 가장 작은 값 찾기의 두 번인데, 둘 모두 사실상 검색과 비슷한 연산이므로 $O(h)$ 시간입니다. 결국 삽입과 삭제 모두 $O(h)$ 시간이 드는 연산입니다. 그런데, 이진 트리의 경우 최악의 상황에서 $h$가 $n$까지 커질 수 있습니다. (한 줄로 쭉 늘어서 있는 경우) 우리는 별로 자세히 다루지는 않겠지만, 이러한 문제를 해결하기 위한 방법을 잠깐만 생각해 봅시다. Quick select때랑 약간 비슷한데, “약간의 시간을 지불해서”, “너무 나쁜 상황이 벌어지지 않게” 만들면 됩니다. 이것을 Balanced Binary Search Tree (BBST) 라고 부르고, 이를 구현하는 다양한 방법이 있습니다. 자세한 내용은 알고리즘 수업에서 다룹니다. 추가 자료를 Additional ii에 일부 제시해 두었습니다. STL set, map C++의 라이브러리에는 매우 편한 set 과 map이 있습니다. 이 set과 map은 Balanced Binary Search Tree의 일종인 Red-Black Tree로 구현되어 있기 때문에, BBST를 실제로 구현해서 쓸 일은 보통 없습니다. 이 라이브러리의 사용법을 반드시 익히길 권합니다. 예시 코드 보기 : BOJ 14425 문자열 집합 set, map, multiset, multimap은 활용도가 매우 높습니다. 참고로, priority queue로 할 수 있는 모든 연산은 multiset으로 똑같이 할 수 있고, 시간 복잡도도 $\order{\log n}$으로 같습니다. 그렇다고 해서 두 코드의 수행 시간이 같거나 비슷할 것으로 기대해서는 안 됩니다. 항상, 시간 복잡도는 중요하지만, 그렇다고 해서 전부는 아닙니다. Disjoint Set 이번 section에서 우리의 목표는, 다음과 같은 두 기능을 갖는 자료구조를 만드는 것입니다. (i) Union(a, b) : a가 들어 있는 집합과 b가 들어 있는 집합을 합치는 연산. (ii) Find(x) : x가 들어 있는 집합의 번호를 확인한다. 즉, Find(x) 와 Find(y) 를 통해 두 원소가 같은 집합에 소속되어 있는지 확인하는 작업이 목표. 예를 들어, 1부터 5까지의 숫자가 있다고 할 때, Union(1, 2), Union(3, 4) 를 하고 나면 $\Set{1, 2}, \Set{3, 4}, \Set{5}$ 가 됩니다. 이때 Find(3) 과 Find(4)는 같아야 하고, Find(1)과는 달라야 합니다. 또한, Union(1, 4) 나 Union(2, 3) 등은 모두 $\Set{1, 2, 3, 4}, \Set{5}$ 로 만드는 과정을 수행해야 합니다. Naive Approach 쉬운 방법으로, Linked List를 사용하는 방법을 예로 들 수 있습니다. $n$개의 숫자가 있고, 이들에 적당히 operation을 수행하려고 한다고 합시다. 각각의 원소가 $p$, $q$개인 집합을 합치는 데 드는 시간은 구현에 따라 다르지만, 효율성을 위해 작은 리스트를 큰 리스트에 합치는 식으로 작업하면 $O(\min(p, q))$ 이지만 이는 최대 $n/2$ 까지이고, 결국 한번의 Union에 $O(n)$이 걸릴 수 있습니다. 또한, Find의 경우 모든 element를 뒤지면서 이 리스트에 소속되어 있는지 찾는 방법밖에 없으므로 $O(n)$이 걸리게 됩니다. 물론, 추가적인 메모리를 쓰면, 매번 각 원소가 자신이 소속된 리스트의 헤드를 가리키는 포인터를 관리하는 등 방법을 쓸 수는 있지만, 이것도 Union은 빨리 할 수 없습니다. Using Trees 생각을 달리하여, 다음과 같이 생각해 봅시다. 각 집합은 하나의 트리로 나타낼 것이고, 각 원소마다 자신의 부모 노드의 번호만 적어 놓습니다. 즉, 각 원소에 대해 par(x)를 항상 관리한다고 생각하겠습니다. 이때, Find(x)는 약간 생각을 바꿔서, 자신이 소속된 트리의 루트 노드를 찾는 연산이라고 생각합니다. (부모가 없는 루트 노드의 부모는 자기 자신) 그렇다면, Union을 할 때 굳이 모든 노드의 par을 바꿔야 할까요? 트리 A와 트리 B를 합치려고 한다면, A의 루트를 B의 루트 밑에 달아 주기만 하면 (즉, par[root of A] = root of B) 한 번에 트리 A 전체를 트리 B에 달아 놓은 형태가 됩니다. 두 트리 (집합)의 Union이 끝났습니다! 이 방법을 생각해 보면, Union(x, y) 연산의 시간 복잡도는 결국 Find(x)와 Find(y)에 의해 결정됩니다. Find(x)하여, 그 찾은 루트를 Find(y)에 달아 주는 연산이 $\order{1}$이기 때문입니다. 그런데, Find 연산은 그 트리의 높이에 의해 결정되고, 최악의 경우 트리가 루트 밑으로 한 줄로 쭉 달릴 수 있으므로 $O(h) = O(n)$ 입니다. 그러면 별로 빨라진 것이 없습니다. Optimizations 위와 같은 처참한 상황을 막기 위해, 우리는 크게 세 가지를 생각합니다. Union by Rank : 각 트리마다, 항상 트리의 높이1를 따로 관리합니다. 이때, Union 연산에서 트리를 매달 때, 반드시 높이가 낮은 트리를 높이가 높은 트리에 매달도록 강제합니다. 이렇게 하면, 트리의 높이가 절대 $\log n$ 이상으로 커지지 않음을 보일 수 있습니다. (Additional 3) Union by Size : 각 트리마다, 트리의 크기 (노드의 개수) 를 관리하고, 작은 트리를 큰 트리에 붙이도록 강제합니다. 역시 Union by Rank와 마찬가지로, 트리의 높이가 절대 $\log n$ 이상으로 커지지 않음을 보일 수 있습니다. (Additional 4) Path Compression : 매번 Find 연산을 하다 보면, $x$가 포함된 트리의 루트를 알게 됩니다. 이때, Heuristic적인 생각으로, 내가 3-4-1-5-2-6의 과정으로 3에서부터 parent를 타고 올라가 6에 도달했다면, 이 트리를 모두 뜯어버리고 3, 4, 1, 5, 2를 전부 6에 그대로 매달아도 됩니다. 이 연산은 트리의 높이를 줄여 줄 것 같습니다. 실제 구현에서 사용하는 방법은 [Union by Rank or Size] + [Path Compression] 입니다. 이하, [Union Rule]과 [Path Comp] 라고 줄이겠습니다. Time Complexity Additional 3과 4에서 다룬 바와 같이, [Union Rule] 은 한번 연산에 대략 $\order{\log n}$ 정도가 걸림을 보장합니다. Union Rule 없이 Path Comp 만으로는, 첫 몇번의 Path comp는 별로 효율적이지 못하지만 나중의 case들이 효율적이기 때문에, 상당히 좋은 Bound를 찾을 수 있습니다.2 두 가지를 모두 사용하는, 효율적인 구현의 경우, Find 연산이 평균적으로 대단히 빠르게 수행됩니다. 이때, 이 시간 복잡도를 $\alpha(n)$ 이라는 함수로 씁니다. 이 함수는 Inverse Ackermann 함수라는 것인데, 우리가 상상할 수 있는 대부분의 함수보다 작은 값을 갖습니다. 인간이 가지고 있는 메모리를 모두 합쳐도, 그 안에 들어가는 $n$의 값에 대해 $\alpha(n) &amp;lt; 5$이기 때문에 우리는 이 함수를 사실상 상수라고 생각해도 큰 문제는 없습니다. Additional Topics / Problems Balanced Binary Search Tree의 예시로, AVL-Tree, Red-Black-Tree, B-Tree와 그 특수한 형태인 2-3-4 Tree가 있습니다. 이 자료구조들은 크게 검색과 검색 기반 연산 (삽입, 삭제, 검색)을 $\order{\log n}$ 에 수행합니다. 그 밖에도, 일반적인 이런 트리로는 절대 수행할 수 없어 보이는 기괴한 연산을 제공하는 자료구조들이 존재합니다.3 우리는 다루지 않을 예정이고 사실 저도 코딩할 줄 모르지만 ‘루트를 바꾸는 연산’을 Amortized $\order{\log n}$에 해 준다거나 하는... 뭐 그런 것도 있다고 합니다 (?) Union by rank만 사용하였을 때, 트리의 높이가 $O(\log n)$ 이상으로 증가하지 않는다는 사실을 납득하세요. 트리의 높이가 합치려는 트리의 높이 $h_1, h_2$보다 1만큼 증가하기 위해서는, 양쪽의 높이가 같아야 하며, 그러기 위해서는 그 트리의 노드 수는 적어도 $2h_1$개가 되어야 합니다. 귀납법을 통해, 높이가 $h$인 트리가 되려면 $2^h$개 정도의 노드가 필요함을 보이세요. Union by size에 대해서, 위 문제와 같은 내용을 보이세요. 2, 3에서 제시된 아이디어의 핵심을 요약하면, ‘매번 큰 쪽에 작은 쪽을 붙이도록 강제하면, 한번 합치는 연산을 할 때 결과물의 크기는 적어도 작은 쪽의 2배가 된다’ 라는 것입니다. 이 원칙은 당연해 보이지만, Tree DP 등에서 복잡도를 줄이는 핵심적인 트릭 중 하나입니다. 간단한 제약을 통해 $O(n^2)$ 시간 알고리즘을 $O(n \log n)$ 또는 $O(n \log^2 n)$ 으로 줄일 수 있기 때문입니다. Wikipedia에는 Union Rule + Path Comp를 수행할 때, 시간 복잡도가 $O(\log^* n)$ 임을 보이는 증명이 있습니다. $\log^* n$ 이라는 함수는, 대략 $\log \log \log \dots \log n$의 값이 1보다 작아지기 위해 필요한 $\log$의 개수입니다. 이 함수도 당연히 매우 느리게 증가하기 때문에, 실용적으로는 5 이하의 값을 가진다고 가정해도 됩니다. CLRS 책의 chapter 21에는 Inverse ackermann 함수에 관한 증명이 수록되어 있습니다. 관심이 있다면 참고하세요. 우리가 다루기에는 필요 이상으로 복잡하고, 별로 중요하지 않습니다. 다만 두 증명 모두 상당히 Elegant합니다. ($\star$) Union Find을 그래프의 용어로 쓰면, 노드들을 잇는 연산과 두 노드가 서로 연결되어 있는지 묻는 연산이라고 생각할 수 있습니다. 이를 Incremental connectivity라고 부릅니다. 반대로, 간선이 처음에는 연결되어 있고, 삭제되는 경우의 문제를 해결할 수 있을까요? 즉, union-find의 union 대신 disconnect(u, v) 연산을 빠르게 구현할 수 있을까요? 이 문제는 incremental보다 훨씬 어렵습니다. 처음에 연결된 상태가 Tree인 경우, 1981년에 Evan과 Shiloach가 $O(n \log n)$ 알고리즘을, 1997년에 Alstrup 등이 $O(n + m)$ 에 가능함을 보였습니다. Planar graph에 대해서 선형 시간 알고리즘이 제시된 것은 2015년의 일입니다. ($\star\star$) 이제, 두 문제를 합쳐 봅시다. connect와 disconnect연산을 모두 지원할 수 있을까요? 이 문제는 그래프가 모든 상황에서 Forest (서로 연결되지 않은 트리들) 임이 보장되는 경우 $O(n \log n)$ 에, 일반 그래프에서도 쿼리당 poly-logarithmic 시간에 풀 수 있음이 알려져 있습니다. Programming Practice C++의 STL multiset 등을 사용하여, BOJ 7662번을 해결해 보세요. 처음으로 STL에서 아예 지원하지 않는 자료구조를 구현해 보게 되었습니다. Disjoint set 자료구조를 구현해 보고, 구현체를 BOJ 1717번에 제출해서 확인해 보세요. C++로 구현한 올바른 구현체는 100ms 미만으로 동작합니다. 만약 생각보다 시간이 오래 걸린다면, 다른 사람의 빠른 구현을 참고해서 어떤 부분을 개선할 수 있을지 알아보세요. 엄밀하게는 높이와는 약간 다른데, 대충 높이라고 생각해도 논리진행에는 문제가 없습니다 &amp;#8617; 상당히 복잡하고 별로 중요하지 않으므로 생략합니다 &amp;#8617; 자료구조의 세계도 끝이 없습니다 :) &amp;#8617;</summary></entry><entry><title type="html">VIII. Dynamic Programming &amp;amp; Divide and Conquer (1)</title><link href="http://localhost:4000/ds-alg-note/08-dp-dnc-1/" rel="alternate" type="text/html" title="VIII. Dynamic Programming &amp;amp; Divide and Conquer (1)" /><published>2021-08-25T00:00:00+09:00</published><updated>2021-08-25T00:00:00+09:00</updated><id>http://localhost:4000/ds-alg-note/08-dp-dnc-1</id><content type="html" xml:base="http://localhost:4000/ds-alg-note/08-dp-dnc-1/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#divide-and-conquer&quot; id=&quot;markdown-toc-divide-and-conquer&quot;&gt;Divide and Conquer&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#merge-sort&quot; id=&quot;markdown-toc-merge-sort&quot;&gt;Merge Sort&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#빠른-거듭-제곱&quot; id=&quot;markdown-toc-빠른-거듭-제곱&quot;&gt;빠른 거듭 제곱&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dynamic-programming&quot; id=&quot;markdown-toc-dynamic-programming&quot;&gt;Dynamic Programming&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#memoization--top-down-dp&quot; id=&quot;markdown-toc-memoization--top-down-dp&quot;&gt;Memoization : Top Down DP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bottom-up-dp&quot; id=&quot;markdown-toc-bottom-up-dp&quot;&gt;Bottom Up DP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dp-예시--2차원-경로-문제&quot; id=&quot;markdown-toc-dp-예시--2차원-경로-문제&quot;&gt;DP 예시 : 2차원 경로 문제&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#additional-topics--problems&quot; id=&quot;markdown-toc-additional-topics--problems&quot;&gt;Additional Topics / Problems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;* 오늘은 특별한 알고리즘을 배우는 것이 아니라, ‘방법론’ 에 가깝기
때문에, Section과 Additional의 구분이 별로 없고 모두 소문제들로 구성되어
있습니다. 여기 나온 모든 소문제를 고민해 보길 권합니다.&lt;/p&gt;

&lt;h2 id=&quot;divide-and-conquer&quot;&gt;Divide and Conquer&lt;/h2&gt;

&lt;p&gt;어떤 문제들은 문제 자체가 &lt;strong&gt;재귀적&lt;/strong&gt;입니다. 즉, 어떤 커다란 문제 X를
풀기 위해, X를 여러 개의 작은 문제 $x_1, x_2, \dots x_k$로 나눈 다음,
각각을 풀고, 합칠 수 있습니다. 프로그래밍으로 생각해 보자면, 재귀함수를
쓰는 것이 자연스러운 문제들이 있습니다. 이러한 문제들에 대해, Divide and
Conquer (분할 정복) 이라는 기법이 매우 유용합니다.&lt;br /&gt;
지금까지 여러분은 분할 정복을 쓰는 알고리즘을 상당히 많이 만나 보았기
때문에, 분할 정복이라는 말이 익숙하지 않더라도 생각하는 방법 자체는
그렇게 낯설지 않을 것입니다. 이 문제를 풀기 어렵지만, 작은 문제를 풀고
합치는 게 더 쉬울 수도 있다면, 분할 정복을 생각해 볼 수 있겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;merge-sort&quot;&gt;Merge Sort&lt;/h3&gt;

&lt;p&gt;병합 정렬 (Merge Sort) 는 대표적인 분할 정복 기법입니다. 앞서 말한 분할
정복을 쓰는 이유가 가장 잘 나타납니다. $n$ 크기의 배열을 정렬하는
것보다, $n/2$ 크기의 배열 2개를 정렬하고, 두 정렬된 배열을 정렬성을
유지하면서 합치는 것이 더 빠르기 때문입니다.&lt;br /&gt;
아래 예시와 Additional (1), (2) 모두 분할 정복을 이용하는 훌륭한
예시입니다.&lt;/p&gt;

&lt;h3 id=&quot;빠른-거듭-제곱&quot;&gt;빠른 거듭 제곱&lt;/h3&gt;

&lt;p&gt;Divide and Conquer를 사용하는 다른 예시를 생각해 봅시다. 이번의 목표는,
어떤 수 $x$의 $y$제곱을 계산하는 일입니다. 상식적으로, 곱셈을 $y$ 번
하는 일이므로, $O(y)$에 하는 것이 자연스러워 보입니다.&lt;br /&gt;
암호학, 특히 RSA 암호 체계에서는 $x^y \pmod{p}$를 계산할 일이 매우 많은데,
$y$가 거대한 수인 경우도 많이 있습니다. 만약 $10,702,103$의
$2,718,281,828$ 제곱 같은 것을 계산하려고 한다면, 어떨까요? 이때 우리는
‘exponentiation by squaring’ 이라는 방법을 쓸 수 있습니다. 만약
$x^y$에서 $y$가 홀수라면, $x^{y-1} \times x$로 식을 정리합니다. 만약
$y$가 짝수라면, $(x^{y/2})^2$ 로 정리합니다. 이 방법이 $\order{\log y}$
에 제곱을 수행한다는 사실을 생각해 봅시다.&lt;/p&gt;

&lt;h2 id=&quot;dynamic-programming&quot;&gt;Dynamic Programming&lt;/h2&gt;

&lt;h3 id=&quot;memoization--top-down-dp&quot;&gt;Memoization : Top Down DP&lt;/h3&gt;

&lt;p&gt;분할 정복은 정말 강력한 도구입니다. 예를 들어, 피보나치 수열도 분할
정복으로 계산할 수 있습니다. fib(n)을 계산하기 위해, fib(n-1) 과
fib(n-2)를 호출하면 됩니다. 그러나 이 방법의 시간 복잡도는 처참합니다.
호출되는 과정을 보면, $f(n)$ 은 한 번 호출하더라도, $f(1)$ 이나 $f(2)$
같은 함수들을 수없이 많이 호출하고 있기 때문입니다. 우리는 이런 중복되는
과정을, 약간의 메모리를 이용하여, 한번만 계산하고 싶습니다.&lt;br /&gt;
이를 위해 사용하는 기법이 Memoization입니다.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 미리 배열 fib[]에,
매번 호출될 때마다 내가 계산한 값을 적어 놓습니다. 매번 함수가 호출될
때마다, 혹시 이 값이 내가 본 적 있는 값인지 메모지를 확인하고, 메모지에
적힌 값은 다시 계산하는 대신, 메모지를 보고 바로 답하는 것입니다.&lt;br /&gt;
함수 호출의 순서를 보면, 큰 값들 (TOP) 이 먼저 호출되고, 그 과정에서
작은 값들 (DOWN)의 값들의 계산이 필요함을 눈치챈 다음, 내려가면서 이
값들을 계산하고 다시 올라오면서 문제를 해결하는 과정을 볼 수 있습니다.
이 과정을 TOP-DOWN 방식의 Dynamic Programming 이라고 부릅니다.&lt;/p&gt;

&lt;h3 id=&quot;bottom-up-dp&quot;&gt;Bottom Up DP&lt;/h3&gt;

&lt;p&gt;물론, 피보나치 수열을 계산하기 위해 꼭 저런 방식을 쓸 필요는 없습니다.
작은 값들을 이용해서 큰 값을 계산할 수만 있다면, 다음과 같이 간단하게
코딩해도 됩니다.&lt;/p&gt;
&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 방법은, 계산 순서를 볼 때, 작은 값들을 먼저 계산해놓고 그걸 이용해서
위로 올라가며 계산하는 방법입니다. 이를 Bottom-UP 방식의 Dynamic
Programming이라고 부릅니다.&lt;br /&gt;
Top-Down과 Bottom-Up 중 무엇이 더 구현하기 편하고, 어느쪽이 유리한지는
그때그때 다르기 때문에, 상황에 따라 다른 방법을 사용해야 합니다. 중요한
것은 다음의 원칙입니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Optimal Substructure : 큰 문제 $f(X)$를 해결하기 위해, $f(Y)$ such
that $Y &amp;lt; X$의 답을 이용하는 것입니다.&lt;sup id=&quot;fnref:2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 즉, 작은 문제의 답이 항상
더 큰 문제의 답을 제공하는데 도움이 되는 경우를 의미합니다. 이
조건은 Divide and Conquer과 Dynamic Programming 모두에 적용됩니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Overlapping Subproblem : 위 Overlapping Substructure를 적용함에
있어서, 겹치는 문제를 여러번 풀어야 해서 이를 최적화하고 싶은 경우를
의미합니다. Fibonacci가 대표적입니다. 이 원칙은 Dynamic
Programming의 기본 원리입니다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dp-예시--2차원-경로-문제&quot;&gt;DP 예시 : 2차원 경로 문제&lt;/h3&gt;

&lt;p&gt;양수로 이루어진 $n \times n$ 행렬이 주어져 있습니다. 이때, 우리는
$(1, 1)$ 에서 출발하여, $(n, n)$ 위치까지 이동하되, 아래쪽 또는
오른쪽으로만 이동할 수 있습니다. 이동하는 과정에서, 행렬의 방문한 칸에
쓰여 있는 숫자들을 더한 값이 이 경로의 최종 점수입니다. 점수를
최대화하는 이동 경로를 찾아 봅시다.&lt;br /&gt;
Optimal Substructure를 생각해 봅시다. 어떤 칸 $(i, j)$ 에 도착하기
위해서는, $(i-1, j)$ 또는 $(i, j-1)$ 에서 와야 합니다. 이때, $(i-1, j)$
까지 어떻게 왔는지는 별로 관심이 없지만, 이 시점까지 온 점수가 최대가
되면 좋을 것 같습니다. 즉, 경로와 무관하게 일단 어떻게든 최선을 다해
$(i-1, j)$ 또는 $(i, j-1)$ 까지 왔다면, 그 경로들에서 한칸을 연장하여
$(i, j)$ 에 오는 최적 경로가 나타나기 때문입니다. 즉, 다음과 같은 DP를
구상합니다. \(C_{ij} = \begin{cases}
    0 &amp;amp; \text{if } i = 0 \text{ or } j = 0\\
    \max({C_{i-1, j}, C_{i, j-1}}) + M_{ij} &amp;amp; \text{otherwise}
\end{cases}\) 만약 $C_{44}$를 계산하려고 한다면, $C_{34}$와 $C_{43}$ 을
계산해야하고, 그러면 $C_{33}, C_{24}, C_{33}, C_{42}$ 를 계산해야
합니다. 벌써 $C_{33}$ 을 두번 계산했습니다! Overlapping Substructure가
보입니다. 이를 최적화하여 계산해도 좋고, 아래와 같이 Bottom-Up DP를
생각해도 됩니다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이렇게 하면 Dynamic Programming을 이용, $O(n^2)$ 에 계산하게 됩니다.&lt;br /&gt;
방금 본 것처럼, 2차원 그리드 위에서도 합리적인 DP 순서를 줄 수 있으면
(왼쪽 위부터 오른쪽 아래) 다이나믹 프로그래밍이 가능합니다. 이외에도
DP는 정말 다양한 형태로 등장하고, 유용하기 때문에 많은 연습이
필요합니다.&lt;/p&gt;

&lt;p&gt;추천문제 : 아래 (3), (4), (5) 이후에도 더 풀어보고 싶다면, BOJ 기준
1005, 11066, 9251번을 확인해 보세요.&lt;/p&gt;

&lt;h1 id=&quot;additional-topics--problems&quot;&gt;Additional Topics / Problems&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Karatsuba Algorithm&lt;/strong&gt; 우리가 곱셈은 $O(1)$에 수행된다고 믿었지만,
사실 생각해 보면 상식적으로 그럴 리가 없습니다. 10억 자리 수를
곱하는 일과 $3 \times 5$를 하는 일이 같은 시간에 수행될 리는 없기
때문입니다. 일상적으로 사용하는 수의 범위에서, 특히 C++의 int 나
long long 범위에서 곱셈이 자연스럽게 상수 비슷한 시간에 수행되기
때문에 우리는 앞으로도 $O(1)$에 기본 사칙연산이 작동한다는 믿음을
갖고 말하겠지만, 여기서는 잠깐만 이 부분을 의심해 봅시다. 다음
흐름을 따라가며, Karatsuba의 아이디어와, 이 아이디어를 처음 들었던
유명한 수학자 Kolmogorov&lt;sup id=&quot;fnref:3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;가 받았던 충격을 느껴봅시다.&lt;/p&gt;

    &lt;p&gt;(1) 초등학교에서 배운 방법대로 $139 \times 312$를 계산해 보고, 이
    방법을 그대로 컴퓨터로 구현해 낸다면 $n$자리 수를 곱셈하는데
    어느정도의 시간이 들지 예측해 보세요.&lt;/p&gt;

    &lt;p&gt;(2) 이하, $x, y$는 $B$진법의 $n$자리 수라고 합시다. 먼저, 적당한
    $m &amp;lt; n$을 골라, $x = x_1 B^m + x_0$, $y = y_1 B^m + y_0$ 이라고
    씁시다. $m$을 $n$의 절반이 되게 고르면 됩니다.&lt;sup id=&quot;fnref:4&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

    &lt;p&gt;(3) 이제, $xy$ 가 $(x_1 B^m + x_0) (y_1 B^m + y_0)$ 이므로,
    $x_1y_1 B^{2m} + (x_1y_0 + x_0y_1)B^m + x_0y_0$으로 나타납니다.
    $x_1y_1, x_0y_0$은 그대로 계산하고, 가운데 항을 계산하는 대신,
    $(x_1 + x_0) (y_1 + y_0)$을 계산하고 앞 두개를 빼면 같은 항을
    얻습니다.&lt;/p&gt;

    &lt;p&gt;(4) 이 알고리즘의 시간 복잡도를 증명하세요. Week 1의 Master Theorem.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;($\star$)&lt;strong&gt;Closest Pair Problem : BOJ 2261&lt;/strong&gt;&lt;br /&gt;
다음 문제를 고민하고 해결해 봅시다. $\R^2$ 상의 점 $n$개에 대하여,
가장 가까운 두 점 간의 거리를 찾고자 합니다. 조금 더 수학적으로는,
$l = \min_{i, j} d(p_i, p_j)$ 을 찾는 문제입니다. 흐름을 따라가며,
분할 정복이 얼마나 강력한 툴인지 다시한번 느껴봅시다.&lt;/p&gt;

    &lt;p&gt;(1) 자명한 ‘쉬운 알고리즘’ 은 $O(n^2)$ 입니다. 우리는 이 문제에 대해
    $O(n \log^2 n)$, 나아가 $O(n \log n)$ 알고리즘을 생각하려고
    합니다.&lt;/p&gt;

    &lt;p&gt;(2) 먼저, Divide and Conquer를 생각하기 위해, $x$축을 기준으로
    반으로 자르겠습니다.&lt;/p&gt;

    &lt;p&gt;(3) 그러면, [두 점이 왼쪽에 있는 경우], [두 점이 오른쪽에 있는
    경우], [양쪽에서 하나씩 뽑는 경우] 를 각각 풀면 됩니다. 이
    방법이 시간 복잡도에 전혀 발전이 없음을 보이세요.&lt;/p&gt;

    &lt;p&gt;(4) 그러나, [양쪽] 케이스를 정말 모두 확인해야 할까요? 얇은
    Strip만 보면 충분함을 관찰하세요.&lt;/p&gt;

    &lt;p&gt;(5) &lt;strong&gt;Challenge&lt;/strong&gt; 양쪽 케이스에서, Strip 안의 점 $p_i$에 대해, 최대
    7번의 비교로 충분함을 보이세요.&lt;/p&gt;

    &lt;p&gt;(6) 이 방법의 시간 복잡도를 증명하고, 어떻게 더 줄일지 생각해
    보세요.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;행렬 곱셈 순서 : BOJ 11049&lt;/strong&gt;&lt;br /&gt;
BOJ 11049번을 보고, 이 문제를 어떻게 해결할 수 있는지 생각해 봅시다.&lt;/p&gt;

    &lt;p&gt;(1) 단순하게는 풀 방법이 잘 떠오르지 않습니다. 하나 가능한 방법은
    모든 가능한 행렬 곱셈 순서를 Naive하게 나열하고 확인하는 것인데,
    이 방법에서 확인해야 할 곱셈 순서가 몇 가지일까요? 이걸 계산하는
    문제는 상당히 어렵습니다. 언젠가 수학 세션을 하게 되면 생각해
    보기로 합시다.&lt;/p&gt;

    &lt;p&gt;(2) 마지막 곱셈의 위치를 기준으로 생각해 봅시다.&lt;br /&gt;
    마지막 곱셈의 위치가 $(A_1 A_2 \dots A_k)$와
    $(A_{k+1} A_{k+2} \dots A_n)$ 을 곱하는 것일 때...&lt;/p&gt;

    &lt;p&gt;(3) DP[i][j] = i번째부터 j번째까지의 행렬을 최대한 잘 곱했을
    때의 최소 비용 이라고 정의합시다. 점화식을 세워 보고, 그
    점화식을 어떻게 빨리 계산할 수 있을지 고민해 보세요.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Knapsack Problem : BOJ 12865&lt;/strong&gt;&lt;br /&gt;
이 문제는 매우 유명한 0-1 Knapsack이라는 문제입니다. 각 물품마다
$w_i$의 무게와 $v_i$의 가치가 있고, 가방에 무게가 $W$ 이하가 되게
넣어야 할 때 가치를 최대화하세요.&lt;/p&gt;

    &lt;p&gt;(1) Heuristic은 매우 중요한 알고리즘의 일부이지만 이 문제에서 먹히지
    않습니다. 혹시 Naive하게 $v_i / w_i$ 가 최대인것부터
    밀어넣는다는 생각을 하셨나요? 가방에 2의 무게만 넣을 수 있고,
    무게가 1, 가치가 5인 물건과 무게가 2, 가치가 6인 물건이 있는
    경우를 생각해 보세요.&lt;/p&gt;

    &lt;p&gt;(2) DP 문제를 접근하는 좋은 방법은, DP 테이블을 먼저 구상하는
    것입니다. DP[i][j] 를 다음과 같이 정의할 때... 라고
    시작합시다. 어떻게 정의해야 할까요? 힌트 : DP 칸수를 $N \times W$ 로 시도해 봅시다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;DP on data structures : BOJ 15681&lt;/strong&gt;&lt;br /&gt;
고정관념을 버리면 쉽게 풀 수 있습니다. 루트 있는 트리에서, 노드
$x$에 대해, 그 노드를 루트로 하는 서브트리의 정점의 수를 빠르게
답하려면 어떻게 할까요?&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;이 문제는 쿼리형 문제 라고 부르는 형태인데, “쿼리” 라고 불리는
“질문”이 $Q$개 주어지고 이 쿼리들에 답해야 하는 상황입니다.
자료구조에 대해 얘기할 때, OO에 대한 쿼리를 빠르게 처리하는
자료구조 라는 식으로 이해한 기억이 있을 것입니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;쿼리가 들어올 때마다 트리를 돌아보면서 대답하면, 한 쿼리를
해결하는 데 $O(n)$ 시간이 들고 (루트만 계속 물어볼 수도
있으니까), 전체 $O(qn)$ 시간이 든다는 의미입니다. 당연히 이
복잡도는 용납할 수 없습니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;쿼리당 $O(1)$ 에 해결하기 위해, 미리 시간을 좀 써서 전처리
(Preprocessing) 하고, 쿼리가 들어오면 그때그때 답해주면
어떨까요? 즉, $O(n + q)$ 에 해결하겠다는 의미입니다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;‘기억하다’ 라는 뜻의 memorization이 &lt;strong&gt;아닙니다&lt;/strong&gt;. ‘메모하다’ 라고
받아들여 주세요 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;이렇게 써놓기는 했지만 $X, Y$가 수일 때만 사용가능한 것은
아닙니다. 합리적인 Order를 줄 수 있으면 되겠죠? &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Andrey Kolmogorov. 주로 확률론을 연구했지만 알고리즘에도 상당히
많은 관심을 가졌던 수학자입니다 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;아직 “$n$이 홀수면 어떻게 하지” 라는 고민이 든다면, Big-O
Notation에 대한 “철학” 이 부족한 것입니다. ㅎㅎ &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="ds-alg-note" /><summary type="html">Contents Divide and Conquer Merge Sort 빠른 거듭 제곱 Dynamic Programming Memoization : Top Down DP Bottom Up DP DP 예시 : 2차원 경로 문제 Additional Topics / Problems * 오늘은 특별한 알고리즘을 배우는 것이 아니라, ‘방법론’ 에 가깝기 때문에, Section과 Additional의 구분이 별로 없고 모두 소문제들로 구성되어 있습니다. 여기 나온 모든 소문제를 고민해 보길 권합니다. Divide and Conquer 어떤 문제들은 문제 자체가 재귀적입니다. 즉, 어떤 커다란 문제 X를 풀기 위해, X를 여러 개의 작은 문제 $x_1, x_2, \dots x_k$로 나눈 다음, 각각을 풀고, 합칠 수 있습니다. 프로그래밍으로 생각해 보자면, 재귀함수를 쓰는 것이 자연스러운 문제들이 있습니다. 이러한 문제들에 대해, Divide and Conquer (분할 정복) 이라는 기법이 매우 유용합니다. 지금까지 여러분은 분할 정복을 쓰는 알고리즘을 상당히 많이 만나 보았기 때문에, 분할 정복이라는 말이 익숙하지 않더라도 생각하는 방법 자체는 그렇게 낯설지 않을 것입니다. 이 문제를 풀기 어렵지만, 작은 문제를 풀고 합치는 게 더 쉬울 수도 있다면, 분할 정복을 생각해 볼 수 있겠습니다. Merge Sort 병합 정렬 (Merge Sort) 는 대표적인 분할 정복 기법입니다. 앞서 말한 분할 정복을 쓰는 이유가 가장 잘 나타납니다. $n$ 크기의 배열을 정렬하는 것보다, $n/2$ 크기의 배열 2개를 정렬하고, 두 정렬된 배열을 정렬성을 유지하면서 합치는 것이 더 빠르기 때문입니다. 아래 예시와 Additional (1), (2) 모두 분할 정복을 이용하는 훌륭한 예시입니다. 빠른 거듭 제곱 Divide and Conquer를 사용하는 다른 예시를 생각해 봅시다. 이번의 목표는, 어떤 수 $x$의 $y$제곱을 계산하는 일입니다. 상식적으로, 곱셈을 $y$ 번 하는 일이므로, $O(y)$에 하는 것이 자연스러워 보입니다. 암호학, 특히 RSA 암호 체계에서는 $x^y \pmod{p}$를 계산할 일이 매우 많은데, $y$가 거대한 수인 경우도 많이 있습니다. 만약 $10,702,103$의 $2,718,281,828$ 제곱 같은 것을 계산하려고 한다면, 어떨까요? 이때 우리는 ‘exponentiation by squaring’ 이라는 방법을 쓸 수 있습니다. 만약 $x^y$에서 $y$가 홀수라면, $x^{y-1} \times x$로 식을 정리합니다. 만약 $y$가 짝수라면, $(x^{y/2})^2$ 로 정리합니다. 이 방법이 $\order{\log y}$ 에 제곱을 수행한다는 사실을 생각해 봅시다. Dynamic Programming Memoization : Top Down DP 분할 정복은 정말 강력한 도구입니다. 예를 들어, 피보나치 수열도 분할 정복으로 계산할 수 있습니다. fib(n)을 계산하기 위해, fib(n-1) 과 fib(n-2)를 호출하면 됩니다. 그러나 이 방법의 시간 복잡도는 처참합니다. 호출되는 과정을 보면, $f(n)$ 은 한 번 호출하더라도, $f(1)$ 이나 $f(2)$ 같은 함수들을 수없이 많이 호출하고 있기 때문입니다. 우리는 이런 중복되는 과정을, 약간의 메모리를 이용하여, 한번만 계산하고 싶습니다. 이를 위해 사용하는 기법이 Memoization입니다.1 미리 배열 fib[]에, 매번 호출될 때마다 내가 계산한 값을 적어 놓습니다. 매번 함수가 호출될 때마다, 혹시 이 값이 내가 본 적 있는 값인지 메모지를 확인하고, 메모지에 적힌 값은 다시 계산하는 대신, 메모지를 보고 바로 답하는 것입니다. 함수 호출의 순서를 보면, 큰 값들 (TOP) 이 먼저 호출되고, 그 과정에서 작은 값들 (DOWN)의 값들의 계산이 필요함을 눈치챈 다음, 내려가면서 이 값들을 계산하고 다시 올라오면서 문제를 해결하는 과정을 볼 수 있습니다. 이 과정을 TOP-DOWN 방식의 Dynamic Programming 이라고 부릅니다. Bottom Up DP 물론, 피보나치 수열을 계산하기 위해 꼭 저런 방식을 쓸 필요는 없습니다. 작은 값들을 이용해서 큰 값을 계산할 수만 있다면, 다음과 같이 간단하게 코딩해도 됩니다. for (int i = 2; i&amp;lt;=n; i++) fib[i] = fib[i-1] + fib[i-2] 이 방법은, 계산 순서를 볼 때, 작은 값들을 먼저 계산해놓고 그걸 이용해서 위로 올라가며 계산하는 방법입니다. 이를 Bottom-UP 방식의 Dynamic Programming이라고 부릅니다. Top-Down과 Bottom-Up 중 무엇이 더 구현하기 편하고, 어느쪽이 유리한지는 그때그때 다르기 때문에, 상황에 따라 다른 방법을 사용해야 합니다. 중요한 것은 다음의 원칙입니다. Optimal Substructure : 큰 문제 $f(X)$를 해결하기 위해, $f(Y)$ such that $Y &amp;lt; X$의 답을 이용하는 것입니다.2 즉, 작은 문제의 답이 항상 더 큰 문제의 답을 제공하는데 도움이 되는 경우를 의미합니다. 이 조건은 Divide and Conquer과 Dynamic Programming 모두에 적용됩니다. Overlapping Subproblem : 위 Overlapping Substructure를 적용함에 있어서, 겹치는 문제를 여러번 풀어야 해서 이를 최적화하고 싶은 경우를 의미합니다. Fibonacci가 대표적입니다. 이 원칙은 Dynamic Programming의 기본 원리입니다. DP 예시 : 2차원 경로 문제 양수로 이루어진 $n \times n$ 행렬이 주어져 있습니다. 이때, 우리는 $(1, 1)$ 에서 출발하여, $(n, n)$ 위치까지 이동하되, 아래쪽 또는 오른쪽으로만 이동할 수 있습니다. 이동하는 과정에서, 행렬의 방문한 칸에 쓰여 있는 숫자들을 더한 값이 이 경로의 최종 점수입니다. 점수를 최대화하는 이동 경로를 찾아 봅시다. Optimal Substructure를 생각해 봅시다. 어떤 칸 $(i, j)$ 에 도착하기 위해서는, $(i-1, j)$ 또는 $(i, j-1)$ 에서 와야 합니다. 이때, $(i-1, j)$ 까지 어떻게 왔는지는 별로 관심이 없지만, 이 시점까지 온 점수가 최대가 되면 좋을 것 같습니다. 즉, 경로와 무관하게 일단 어떻게든 최선을 다해 $(i-1, j)$ 또는 $(i, j-1)$ 까지 왔다면, 그 경로들에서 한칸을 연장하여 $(i, j)$ 에 오는 최적 경로가 나타나기 때문입니다. 즉, 다음과 같은 DP를 구상합니다. \(C_{ij} = \begin{cases} 0 &amp;amp; \text{if } i = 0 \text{ or } j = 0\\ \max({C_{i-1, j}, C_{i, j-1}}) + M_{ij} &amp;amp; \text{otherwise} \end{cases}\) 만약 $C_{44}$를 계산하려고 한다면, $C_{34}$와 $C_{43}$ 을 계산해야하고, 그러면 $C_{33}, C_{24}, C_{33}, C_{42}$ 를 계산해야 합니다. 벌써 $C_{33}$ 을 두번 계산했습니다! Overlapping Substructure가 보입니다. 이를 최적화하여 계산해도 좋고, 아래와 같이 Bottom-Up DP를 생각해도 됩니다. for (int i = 1; i&amp;lt;=n; i++) for (int j = 1; j&amp;lt;=n; j++) C[i][j] = M[i][j] + max(C[i-1][j], C[i][j-1]); 이렇게 하면 Dynamic Programming을 이용, $O(n^2)$ 에 계산하게 됩니다. 방금 본 것처럼, 2차원 그리드 위에서도 합리적인 DP 순서를 줄 수 있으면 (왼쪽 위부터 오른쪽 아래) 다이나믹 프로그래밍이 가능합니다. 이외에도 DP는 정말 다양한 형태로 등장하고, 유용하기 때문에 많은 연습이 필요합니다. 추천문제 : 아래 (3), (4), (5) 이후에도 더 풀어보고 싶다면, BOJ 기준 1005, 11066, 9251번을 확인해 보세요. Additional Topics / Problems Karatsuba Algorithm 우리가 곱셈은 $O(1)$에 수행된다고 믿었지만, 사실 생각해 보면 상식적으로 그럴 리가 없습니다. 10억 자리 수를 곱하는 일과 $3 \times 5$를 하는 일이 같은 시간에 수행될 리는 없기 때문입니다. 일상적으로 사용하는 수의 범위에서, 특히 C++의 int 나 long long 범위에서 곱셈이 자연스럽게 상수 비슷한 시간에 수행되기 때문에 우리는 앞으로도 $O(1)$에 기본 사칙연산이 작동한다는 믿음을 갖고 말하겠지만, 여기서는 잠깐만 이 부분을 의심해 봅시다. 다음 흐름을 따라가며, Karatsuba의 아이디어와, 이 아이디어를 처음 들었던 유명한 수학자 Kolmogorov3가 받았던 충격을 느껴봅시다. (1) 초등학교에서 배운 방법대로 $139 \times 312$를 계산해 보고, 이 방법을 그대로 컴퓨터로 구현해 낸다면 $n$자리 수를 곱셈하는데 어느정도의 시간이 들지 예측해 보세요. (2) 이하, $x, y$는 $B$진법의 $n$자리 수라고 합시다. 먼저, 적당한 $m &amp;lt; n$을 골라, $x = x_1 B^m + x_0$, $y = y_1 B^m + y_0$ 이라고 씁시다. $m$을 $n$의 절반이 되게 고르면 됩니다.4 (3) 이제, $xy$ 가 $(x_1 B^m + x_0) (y_1 B^m + y_0)$ 이므로, $x_1y_1 B^{2m} + (x_1y_0 + x_0y_1)B^m + x_0y_0$으로 나타납니다. $x_1y_1, x_0y_0$은 그대로 계산하고, 가운데 항을 계산하는 대신, $(x_1 + x_0) (y_1 + y_0)$을 계산하고 앞 두개를 빼면 같은 항을 얻습니다. (4) 이 알고리즘의 시간 복잡도를 증명하세요. Week 1의 Master Theorem. ($\star$)Closest Pair Problem : BOJ 2261 다음 문제를 고민하고 해결해 봅시다. $\R^2$ 상의 점 $n$개에 대하여, 가장 가까운 두 점 간의 거리를 찾고자 합니다. 조금 더 수학적으로는, $l = \min_{i, j} d(p_i, p_j)$ 을 찾는 문제입니다. 흐름을 따라가며, 분할 정복이 얼마나 강력한 툴인지 다시한번 느껴봅시다. (1) 자명한 ‘쉬운 알고리즘’ 은 $O(n^2)$ 입니다. 우리는 이 문제에 대해 $O(n \log^2 n)$, 나아가 $O(n \log n)$ 알고리즘을 생각하려고 합니다. (2) 먼저, Divide and Conquer를 생각하기 위해, $x$축을 기준으로 반으로 자르겠습니다. (3) 그러면, [두 점이 왼쪽에 있는 경우], [두 점이 오른쪽에 있는 경우], [양쪽에서 하나씩 뽑는 경우] 를 각각 풀면 됩니다. 이 방법이 시간 복잡도에 전혀 발전이 없음을 보이세요. (4) 그러나, [양쪽] 케이스를 정말 모두 확인해야 할까요? 얇은 Strip만 보면 충분함을 관찰하세요. (5) Challenge 양쪽 케이스에서, Strip 안의 점 $p_i$에 대해, 최대 7번의 비교로 충분함을 보이세요. (6) 이 방법의 시간 복잡도를 증명하고, 어떻게 더 줄일지 생각해 보세요. 행렬 곱셈 순서 : BOJ 11049 BOJ 11049번을 보고, 이 문제를 어떻게 해결할 수 있는지 생각해 봅시다. (1) 단순하게는 풀 방법이 잘 떠오르지 않습니다. 하나 가능한 방법은 모든 가능한 행렬 곱셈 순서를 Naive하게 나열하고 확인하는 것인데, 이 방법에서 확인해야 할 곱셈 순서가 몇 가지일까요? 이걸 계산하는 문제는 상당히 어렵습니다. 언젠가 수학 세션을 하게 되면 생각해 보기로 합시다. (2) 마지막 곱셈의 위치를 기준으로 생각해 봅시다. 마지막 곱셈의 위치가 $(A_1 A_2 \dots A_k)$와 $(A_{k+1} A_{k+2} \dots A_n)$ 을 곱하는 것일 때... (3) DP[i][j] = i번째부터 j번째까지의 행렬을 최대한 잘 곱했을 때의 최소 비용 이라고 정의합시다. 점화식을 세워 보고, 그 점화식을 어떻게 빨리 계산할 수 있을지 고민해 보세요. Knapsack Problem : BOJ 12865 이 문제는 매우 유명한 0-1 Knapsack이라는 문제입니다. 각 물품마다 $w_i$의 무게와 $v_i$의 가치가 있고, 가방에 무게가 $W$ 이하가 되게 넣어야 할 때 가치를 최대화하세요. (1) Heuristic은 매우 중요한 알고리즘의 일부이지만 이 문제에서 먹히지 않습니다. 혹시 Naive하게 $v_i / w_i$ 가 최대인것부터 밀어넣는다는 생각을 하셨나요? 가방에 2의 무게만 넣을 수 있고, 무게가 1, 가치가 5인 물건과 무게가 2, 가치가 6인 물건이 있는 경우를 생각해 보세요. (2) DP 문제를 접근하는 좋은 방법은, DP 테이블을 먼저 구상하는 것입니다. DP[i][j] 를 다음과 같이 정의할 때... 라고 시작합시다. 어떻게 정의해야 할까요? 힌트 : DP 칸수를 $N \times W$ 로 시도해 봅시다. DP on data structures : BOJ 15681 고정관념을 버리면 쉽게 풀 수 있습니다. 루트 있는 트리에서, 노드 $x$에 대해, 그 노드를 루트로 하는 서브트리의 정점의 수를 빠르게 답하려면 어떻게 할까요? 이 문제는 쿼리형 문제 라고 부르는 형태인데, “쿼리” 라고 불리는 “질문”이 $Q$개 주어지고 이 쿼리들에 답해야 하는 상황입니다. 자료구조에 대해 얘기할 때, OO에 대한 쿼리를 빠르게 처리하는 자료구조 라는 식으로 이해한 기억이 있을 것입니다. 쿼리가 들어올 때마다 트리를 돌아보면서 대답하면, 한 쿼리를 해결하는 데 $O(n)$ 시간이 들고 (루트만 계속 물어볼 수도 있으니까), 전체 $O(qn)$ 시간이 든다는 의미입니다. 당연히 이 복잡도는 용납할 수 없습니다. 쿼리당 $O(1)$ 에 해결하기 위해, 미리 시간을 좀 써서 전처리 (Preprocessing) 하고, 쿼리가 들어오면 그때그때 답해주면 어떨까요? 즉, $O(n + q)$ 에 해결하겠다는 의미입니다. ‘기억하다’ 라는 뜻의 memorization이 아닙니다. ‘메모하다’ 라고 받아들여 주세요 &amp;#8617; 이렇게 써놓기는 했지만 $X, Y$가 수일 때만 사용가능한 것은 아닙니다. 합리적인 Order를 줄 수 있으면 되겠죠? &amp;#8617; Andrey Kolmogorov. 주로 확률론을 연구했지만 알고리즘에도 상당히 많은 관심을 가졌던 수학자입니다 &amp;#8617; 아직 “$n$이 홀수면 어떻게 하지” 라는 고민이 든다면, Big-O Notation에 대한 “철학” 이 부족한 것입니다. ㅎㅎ &amp;#8617;</summary></entry><entry><title type="html">IX. Dynamic Programming &amp;amp; Divide and Conquer (2)</title><link href="http://localhost:4000/ds-alg-note/09-dp-dnc-2/" rel="alternate" type="text/html" title="IX. Dynamic Programming &amp;amp; Divide and Conquer (2)" /><published>2021-08-25T00:00:00+09:00</published><updated>2021-08-25T00:00:00+09:00</updated><id>http://localhost:4000/ds-alg-note/09-dp-dnc-2</id><content type="html" xml:base="http://localhost:4000/ds-alg-note/09-dp-dnc-2/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;hr /&gt;

&lt;p&gt;오늘은 &lt;strong&gt;연습문제만&lt;/strong&gt; 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Segment Tree&lt;/strong&gt; : 수열을 다루는 자료구조중 하나입니다. 어떤 수열
$a_1, a_2, \dots a_n$ 이 주어집니다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;구간 $[i, j]$가 주어지면, $a_i + a_{i+1} + \dots + a_j$ 의 값을
구합니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;$i, v$ 가 주어지면, $a_i$ 에 $v$를 더합니다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;첫번째 쿼리만 주어지고, 두번째 쿼리가 주어지지 않는다면, 이
문제를 쿼리당 $O(1)$ 에 처리할 수 있습니다. 부분합 배열이라고
부릅니다. 이 방법을 설명하세요.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;우리는 Complete Binary Tree를 만들어서 이 문제를 해결하고자
합니다. 각 노드는 어떤 구간을 담당할 것입니다. 각 노드들은 다음
원칙을 지킵니다. “노드의 값은, 두 자식 노드의 값을 합한 값을
갖는다. 각 노드는 두 자식 노드가 담당하는 구간을 합한 구간을
담당한다&quot;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;전체 노드의 개수가 몇 개인지 생각해 보세요. 첫 번째 쿼리가
주어졌을 때, 이를 해결하기 위해 총 확인해야 하는 노드가 몇
개인지 생각해 보세요. 두 번째 쿼리에 대해서도 같은 과정을 반복해
보세요.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;이 방법이 두 쿼리를 빠르게 해결할 수 있음을 이해하고, 시간
복잡도를 계산해 보세요.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Segment Tree with Lazy Propagation&lt;/strong&gt; : 위 문제와 거의 같습니다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;구간 $[i, j]$가 주어지면, $a_i + a_{i+1} + \dots + a_j$ 의 값을
구합니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;구간 $[i, j]$와 값 $v$ 가 주어지면, $a_i, a_{i+1}, \dots a_j$ 에
모두 $v$를 더합니다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;일반적인 세그먼트 트리가 이 문제를 잘 해결하지 못함을
관찰하세요.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;추가적인 기법으로, 갱신을 “미루는” 방법을 사용하겠습니다. 각
노드마다, 이 노드가 지금까지 얼마나 갱신을 미루고 있었는지를
추가로 저장합니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;1번, 2번 쿼리가 주어졌을 때 각각 어떻게 이 정보를 이용하여 값을
계산할지 제시하고, 그 방법들의 시간 복잡도를 계산하세요.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Merge Sort Tree&lt;/strong&gt; : 이번에는 위와 같이 수열이 주어지는 상황에서,
이런 문제를 생각하겠습니다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;구간 $[i, j]$와 어떤 수 $k$가 주어지면,
$a_i, a_{i+1}, \dots a_j$ 에서 $k$보다 큰 값의 개수를 구합니다.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;머지 소트 트리는, 세그먼트 트리와 거의 같은 방법으로 만들되, 각
트리가 머지 소트의 중간 과정을 담고 있는 트리입니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;즉, 각 트리가 정수값 하나가 아닌 작은 수열을 들고 있습니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;이 트리가 위 문제를 빠르게 해결할 수 있음을 보이세요. 목표하는
시간복잡도는 쿼리당 $O(\log^2 n)$ 입니다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Edit Distance&lt;/strong&gt; : 편집 거리란, 두 수열 $S, T$에 대해, 값의 삽입,
삭제, 대체 연산을 이용하여 $S$를 $T$로 만들고자 할 때 필요한
최소한의 연산 횟수로 정의합니다. 각 수열의 길이가 $m, n$ 일 때, 편집
거리를 $O(mn)$에 구하는 알고리즘을 제시하세요.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Longest Common Subsequence&lt;/strong&gt; : 두 수열 $S, T$에 대해, 두 수열이
가지고 있는 최대 공통 부분 수열을 구하고자 합니다. 두 수열의 길이가
$m, n$일 때, LCS의 길이를 $O(mn)$에 구하는 알고리즘을 제시하세요.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Longest Increasing Subsequence&lt;/strong&gt; : 어떤 수열 $a_1, \dots a_n$ 이
주어졌을 때, 이 중 가장 긴 증가하는 부분 수열 (not necessarily
contiguous) 의 길이를 구하고자 합니다.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;자명한 DP식을 생각해 봅시다. 각 $i$에 대해, $D_i$는 $i$번째를 끝
원소로 하는 가장 긴 증가하는 부분 수열의 길이로 정의합니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;이제, $D_i = \max_{j &amp;lt; i, A_j &amp;lt; A_i} D_j + 1$ 로 계산
가능합니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;이 DP를 그대로 계산하면 $O(n^2)$ 시간이 걸릴 것입니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;이보다 빠른 시간 복잡도 $O(n \log n)$ 을 달성하는 방법이,
지금까지 공부한 내용만으로 2가지가 가능합니다. 두 가지를
제시하세요. &lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Lowest Common Ancestor - Binary Lifting &amp;amp; Sparse Table&lt;/strong&gt; : 트리 $T$에 대해, 정점
$u, v$의 최소 공통 조상을 구하고자 합니다.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;가장 자명한 방법은 두 노드를 루트까지 타고 올라가면서 모든 조상
노드를 찾은 뒤, 조상 노드 번호의 수열을 루트부터 거꾸로
확인하면서 어디까지 겹치는지 확인하는 방법입니다. 이는 $O(n)$
시간이 걸립니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;약간의 &lt;strong&gt;Preprocessing&lt;/strong&gt;을 통해, 각 쿼리를 $O(\log n)$ 에
처리하는 방법을 이해해 보고자 합니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;각 노드 $u$의 부모 노드를 안다면, 모든 노드의 2대 부모 노드를
빠르게 구할 수 있음을 이해하세요. 이를 확장하여 $2^{k-1}$ 번째
부모를 안다면 $2^{k}$ 번째 부모도 알 수 있음을 이해하세요.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;따라서, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;par[x][i]&lt;/code&gt; 를 $x$의 $2^i$번째 부모로 정의할 때, 이
배열을 모두 채우는 데 $O(n \log n)$ 시간이 걸립니다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;이 배열을 이용, $O(\log n)$ 시간에 각 쿼리에 답하는 방법을
제시하세요. 일반성을 잃지 않고, 깊이가 같은 경우만 보여도 됨을 관찰하세요.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;목표는 $u$ 의 $k$번째 부모가 $v$의 $k$번째 부모와 같은 최소 $k$ 찾기입니다. $k$ 를 이진수로 맞추고, par 배열로 짜 맞춰 봅시다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;하나는 Binary Search, 다른 하나는 Segment Tree &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="ds-alg-note" /><summary type="html">Contents 오늘은 연습문제만 있습니다. Segment Tree : 수열을 다루는 자료구조중 하나입니다. 어떤 수열 $a_1, a_2, \dots a_n$ 이 주어집니다. 구간 $[i, j]$가 주어지면, $a_i + a_{i+1} + \dots + a_j$ 의 값을 구합니다. $i, v$ 가 주어지면, $a_i$ 에 $v$를 더합니다. 첫번째 쿼리만 주어지고, 두번째 쿼리가 주어지지 않는다면, 이 문제를 쿼리당 $O(1)$ 에 처리할 수 있습니다. 부분합 배열이라고 부릅니다. 이 방법을 설명하세요. 우리는 Complete Binary Tree를 만들어서 이 문제를 해결하고자 합니다. 각 노드는 어떤 구간을 담당할 것입니다. 각 노드들은 다음 원칙을 지킵니다. “노드의 값은, 두 자식 노드의 값을 합한 값을 갖는다. 각 노드는 두 자식 노드가 담당하는 구간을 합한 구간을 담당한다&quot; 전체 노드의 개수가 몇 개인지 생각해 보세요. 첫 번째 쿼리가 주어졌을 때, 이를 해결하기 위해 총 확인해야 하는 노드가 몇 개인지 생각해 보세요. 두 번째 쿼리에 대해서도 같은 과정을 반복해 보세요. 이 방법이 두 쿼리를 빠르게 해결할 수 있음을 이해하고, 시간 복잡도를 계산해 보세요. Segment Tree with Lazy Propagation : 위 문제와 거의 같습니다. 구간 $[i, j]$가 주어지면, $a_i + a_{i+1} + \dots + a_j$ 의 값을 구합니다. 구간 $[i, j]$와 값 $v$ 가 주어지면, $a_i, a_{i+1}, \dots a_j$ 에 모두 $v$를 더합니다. 일반적인 세그먼트 트리가 이 문제를 잘 해결하지 못함을 관찰하세요. 추가적인 기법으로, 갱신을 “미루는” 방법을 사용하겠습니다. 각 노드마다, 이 노드가 지금까지 얼마나 갱신을 미루고 있었는지를 추가로 저장합니다. 1번, 2번 쿼리가 주어졌을 때 각각 어떻게 이 정보를 이용하여 값을 계산할지 제시하고, 그 방법들의 시간 복잡도를 계산하세요. Merge Sort Tree : 이번에는 위와 같이 수열이 주어지는 상황에서, 이런 문제를 생각하겠습니다. 구간 $[i, j]$와 어떤 수 $k$가 주어지면, $a_i, a_{i+1}, \dots a_j$ 에서 $k$보다 큰 값의 개수를 구합니다. 머지 소트 트리는, 세그먼트 트리와 거의 같은 방법으로 만들되, 각 트리가 머지 소트의 중간 과정을 담고 있는 트리입니다. 즉, 각 트리가 정수값 하나가 아닌 작은 수열을 들고 있습니다. 이 트리가 위 문제를 빠르게 해결할 수 있음을 보이세요. 목표하는 시간복잡도는 쿼리당 $O(\log^2 n)$ 입니다. Edit Distance : 편집 거리란, 두 수열 $S, T$에 대해, 값의 삽입, 삭제, 대체 연산을 이용하여 $S$를 $T$로 만들고자 할 때 필요한 최소한의 연산 횟수로 정의합니다. 각 수열의 길이가 $m, n$ 일 때, 편집 거리를 $O(mn)$에 구하는 알고리즘을 제시하세요. Longest Common Subsequence : 두 수열 $S, T$에 대해, 두 수열이 가지고 있는 최대 공통 부분 수열을 구하고자 합니다. 두 수열의 길이가 $m, n$일 때, LCS의 길이를 $O(mn)$에 구하는 알고리즘을 제시하세요. Longest Increasing Subsequence : 어떤 수열 $a_1, \dots a_n$ 이 주어졌을 때, 이 중 가장 긴 증가하는 부분 수열 (not necessarily contiguous) 의 길이를 구하고자 합니다. 자명한 DP식을 생각해 봅시다. 각 $i$에 대해, $D_i$는 $i$번째를 끝 원소로 하는 가장 긴 증가하는 부분 수열의 길이로 정의합니다. 이제, $D_i = \max_{j &amp;lt; i, A_j &amp;lt; A_i} D_j + 1$ 로 계산 가능합니다. 이 DP를 그대로 계산하면 $O(n^2)$ 시간이 걸릴 것입니다. 이보다 빠른 시간 복잡도 $O(n \log n)$ 을 달성하는 방법이, 지금까지 공부한 내용만으로 2가지가 가능합니다. 두 가지를 제시하세요. 1 Lowest Common Ancestor - Binary Lifting &amp;amp; Sparse Table : 트리 $T$에 대해, 정점 $u, v$의 최소 공통 조상을 구하고자 합니다. 가장 자명한 방법은 두 노드를 루트까지 타고 올라가면서 모든 조상 노드를 찾은 뒤, 조상 노드 번호의 수열을 루트부터 거꾸로 확인하면서 어디까지 겹치는지 확인하는 방법입니다. 이는 $O(n)$ 시간이 걸립니다. 약간의 Preprocessing을 통해, 각 쿼리를 $O(\log n)$ 에 처리하는 방법을 이해해 보고자 합니다. 각 노드 $u$의 부모 노드를 안다면, 모든 노드의 2대 부모 노드를 빠르게 구할 수 있음을 이해하세요. 이를 확장하여 $2^{k-1}$ 번째 부모를 안다면 $2^{k}$ 번째 부모도 알 수 있음을 이해하세요. 따라서, par[x][i] 를 $x$의 $2^i$번째 부모로 정의할 때, 이 배열을 모두 채우는 데 $O(n \log n)$ 시간이 걸립니다. 이 배열을 이용, $O(\log n)$ 시간에 각 쿼리에 답하는 방법을 제시하세요. 일반성을 잃지 않고, 깊이가 같은 경우만 보여도 됨을 관찰하세요. 목표는 $u$ 의 $k$번째 부모가 $v$의 $k$번째 부모와 같은 최소 $k$ 찾기입니다. $k$ 를 이진수로 맞추고, par 배열로 짜 맞춰 봅시다. 하나는 Binary Search, 다른 하나는 Segment Tree &amp;#8617;</summary></entry></feed>