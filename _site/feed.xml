<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-10-02T23:22:42+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Gratus907’s Study Note</title><subtitle>Hello World!</subtitle><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><entry><title type="html">GCPC 2020 팀연습</title><link href="http://localhost:4000/cp-rounds/team-practice-gcpc-2020/" rel="alternate" type="text/html" title="GCPC 2020 팀연습" /><published>2021-09-28T00:00:00+09:00</published><updated>2021-09-28T00:00:00+09:00</updated><id>http://localhost:4000/cp-rounds/team-practice-gcpc-2020</id><content type="html" xml:base="http://localhost:4000/cp-rounds/team-practice-gcpc-2020/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#f--flip-flow-10분-ac&quot; id=&quot;markdown-toc-f--flip-flow-10분-ac&quot;&gt;F : Flip Flow (10분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#a--adolescent-architecture--k--knightly-knowledge-45--85분-ac-각-1wa&quot; id=&quot;markdown-toc-a--adolescent-architecture--k--knightly-knowledge-45--85분-ac-각-1wa&quot;&gt;A : Adolescent Architecture / K : Knightly Knowledge (45 / 85분 AC, 각 1WA)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#c--confined-catching-67분-ac&quot; id=&quot;markdown-toc-c--confined-catching-67분-ac&quot;&gt;C : Confined Catching (67분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#i--impressive-integers-103분-ac-4-wa&quot; id=&quot;markdown-toc-i--impressive-integers-103분-ac-4-wa&quot;&gt;I : Impressive Integers (103분 AC, 4 WA)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#d--decorative-dominoes-142분-ac&quot; id=&quot;markdown-toc-d--decorative-dominoes-142분-ac&quot;&gt;D : Decorative Dominoes (142분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#g--gravity-grid-160분-ac-3-wa&quot; id=&quot;markdown-toc-g--gravity-grid-160분-ac-3-wa&quot;&gt;G : Gravity Grid (160분 AC, 3 WA)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#b--bookshelf-building-175분-ac-3-wa&quot; id=&quot;markdown-toc-b--bookshelf-building-175분-ac-3-wa&quot;&gt;B : Bookshelf Building (175분 AC, 3 WA)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#m--mixtape-management-199분-ac&quot; id=&quot;markdown-toc-m--mixtape-management-199분-ac&quot;&gt;M : Mixtape Management (199분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#l--lexicographical-lecturing-209분-ac&quot; id=&quot;markdown-toc-l--lexicographical-lecturing-209분-ac&quot;&gt;L : Lexicographical Lecturing (209분 AC)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#review&quot; id=&quot;markdown-toc-review&quot;&gt;Review&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;멤버가 조금씩 바뀌면서 지난 3년간 UCPC, ICPC, HashCode 등을 함께해온 팀 Little Piplup으로 이번에는 다시 제가 참여하게 되었습니다.&lt;/p&gt;

&lt;p&gt;이 팀은 2019년 저와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Coffeetea&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DHDroid&lt;/code&gt;로 시작해서 PS 공부도 같이 하고, 많은 대회를 뛰면서 나름 행복 PS 해온 팀입니다. 2020년에는 Hashcode를 기점으로 저랑 그전까지 같이 연습셋을 많이 돌았던 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dlwocks31&lt;/code&gt;이 들어와서 4명이 되었습니다.&lt;/p&gt;

&lt;p&gt;Hashcode는 4인팀이지만, UCPC와 ICPC는 3인 1팀입니다. 또한, ICPC의 경우 휴학생이 본선에 진출할수 없다는 규정이 있는데 이 팀은 저를 제외한 3명이 모두 휴학생 (병특 중)이라 2020 ICPC에서는 자연스럽게 제가 다른 팀을 찾아 나가고 3명이서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Army Piplup&lt;/code&gt; 을 구성해서 나갈 수 있었고, 2020 UCPC는 dlwocks31이 다른 팀원들이랑 출전했었습니다. 2021 UCPC는… 2명 2명을 가르고 한명씩을 더 영입했는데, 저랑 dlwocks31쪽은 어리석은 실수로 대회를 치르지 못했었습니다.&lt;/p&gt;

&lt;p&gt;이번에는 dlwocks31이 딱히 PS에 더이상 동기가 많이 떨어졌다는 식으로 기회를 양보하기도 했고, 저는 다른 팀원들을 모으더라도 서울대에서 본선을 진출하기는 쉽지 않겠다는 판단이 들어서 행복 PS를 위해 이 팀 그대로 나가기로 했습니다. 무엇보다 같이 문제를 풀고 팀연습하는 과정을 즐길 수 있는 팀이라서 그렇기도 합니다.&lt;/p&gt;

&lt;p&gt;ICPC는 순수하게 PS를 즐기러 나가지만 (본선 진출권도 없으므로) 그래도 이왕 모인거 팀연습이나 한두번 하자는 생각으로 GCPC 2020 셋을 돌았습니다.&lt;/p&gt;

&lt;p&gt;GCPC는 비교적 쉬운 리저널로, 원래 5시간 셋이지만 예선만 나갈거기도 하고 저희한테 시간이 많이 없어서 3.5시간으로 잡고 돌았습니다. 풀만한 문제는 다 푼듯 합니다.&lt;/p&gt;

&lt;p&gt;DHdroid가 ABCD, 제가 EFGHI, Coffeetea가 JKLM을 읽자고 생각했지만 커뮤니케이션 미스로 Coffeetea가 I부터 읽었고 M은 아무도 잡지 않았습니다. ㅋㅋㅋㅋ&lt;/p&gt;

&lt;h3 id=&quot;f--flip-flow-10분-ac&quot;&gt;F : Flip Flow (10분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Gratus907     Code : Gratus907&lt;/code&gt;&lt;br /&gt;
재밌게도 GCPC는 문제제목이 문제 번호를 따라갑니다.&lt;/p&gt;

&lt;p&gt;모래시계를 뒤집으면서 남은 모래의 양을 확인하는 문제인데, 전체 시간 $t$가 작아서 그대로 시뮬레이션 할 수 있습니다. 10분에 AC.&lt;/p&gt;

&lt;h3 id=&quot;a--adolescent-architecture--k--knightly-knowledge-45--85분-ac-각-1wa&quot;&gt;A : Adolescent Architecture / K : Knightly Knowledge (45 / 85분 AC, 각 1WA)&lt;/h3&gt;
&lt;p&gt;각각 DHDroid / Coffeetea가 잡았습니다.&lt;/p&gt;

&lt;p&gt;E는 딱 보기에도 어려웠고, G는 귀찮은 구현이 필요해 보였습니다. H는 너무 문제가 길어서 걸러버렸고… ‘컴퓨터가 남으면’ G를 짜겠다고 말했는데, DHdroid와 Coffeetea가 A, K가 쉽다고 주장했으므로 컴퓨터를 제가 잡고있는건 좋은 전략이 아니라고 생각했습니다.&lt;/p&gt;

&lt;p&gt;다만 둘다 구현을 그렇게 빠르게 쳐내지는 못했습니다. 저는 두 문제 다 읽지 않았지만 각각 2000, 2500바이트의 코딩이 필요했던 것으로 보아 뇌절도 있었지만 근본적으로 구현난이도가 좀 있었던것 같습니다.&lt;/p&gt;

&lt;p&gt;저는 양쪽 다 구현에 참여하지 않았고, 둘다 구상이 끝나고 구현만 남은 상태였기 때문에, DHDroid가 A번을 코딩할 때는 Coffeetea랑 같이 I번을, Coffeetea가 K번을 코딩하는 동안 DHDroid랑 같이 C, D를 풀 수 있었습니다. Coffeetea가 K번의 구현에서 상당히 많이 고전했기 때문에, 버그를 찾기 위해 코드를 따로 보면서 (실전에서는 코드 출력에 해당하는 선택입니다) 저한테 중간에 컴퓨터를 넘겨서 I번을 (몇번의 디버깅 끝에) 성공했습니다.&lt;/p&gt;

&lt;h3 id=&quot;c--confined-catching-67분-ac&quot;&gt;C : Confined Catching (67분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Gratus907, DHDroid&lt;/code&gt;&lt;br /&gt;
굉장히 재밌는 퍼즐틱한 문제였다고 생각합니다.&lt;br /&gt;
상하좌우로 움직일 수 있는 ‘말’ 이 나에게 2개, 상대에게 1개 주어집니다. $100 \times 100$ 그리드 안에서, 내가 두 말을 동시에 움직이면, 상대가 그걸 보고 도망칠 수 있습니다. 말 두 개를 잘 coordination해서, 상대 말을 ‘잡으면’ 이기는 게임입니다. 단, 600턴의 시간 제한이 있습니다.&lt;/p&gt;

&lt;p&gt;처음에는 두 말이 이루는 직사각형을 좁히는 등 몇가지 아이디어를 생각했지만, 적절한 아이디어가 없어 고민하던 중에 제가 말 하나는 $x$좌표를 먼저 따라붙고, 말 하나는 $y$좌표를 먼저 따라붙는 아이디어를 제시했습니다. 상대가 어느쪽으로 도망치든 두 말 중 적어도 하나는 거리를 줄일 수 있음을 보장받기 때문에 (직선상의 경우가 예외가 되지만, 다음 턴에는 다시 줄일 수 있습니다) 어떻게 될 것 같았고, 잘 코너로 몰면 이길 수 있다고 생각했습니다.&lt;/p&gt;

&lt;p&gt;DHDroid가 이걸 받고 잠깐 생각해보더니 ‘내 말 두 개와 벽이 이루는 직사각형이 줄어든다’ 는 논증으로 이 방법이 올바름을 증명했고, 제가 Coffeetea에게 잠깐 컴퓨터를 받아서 구현해서 맞았습니다.&lt;/p&gt;

&lt;h3 id=&quot;i--impressive-integers-103분-ac-4-wa&quot;&gt;I : Impressive Integers (103분 AC, 4 WA)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Coffeetea, Gratus907&lt;/code&gt;&lt;br /&gt;
요약하자면, 어떤 $n$이 주어졌을 때, 자연수 $a, b, c$를 골라서, 한 변의 길이가 $c$인 정삼각형을 한 변의 길이가 $a$ 와 $b$인 정삼각형들로 채우는데 정확히 $n$개를 쓰도록 할 수 있는지에 대한 문제입니다.&lt;/p&gt;

&lt;p&gt;Coffeetea가 먼저 맨 위에 1개 또는 4개만 쓰고, 나머지를 잘 채워넣으면 될것같다는 간단하지만 문제를 바로 해결하는 아이디어를 던졌고, 제가 빈 로직을 채워넣어서 문제를 해결했습니다. $n$이 큰 짝수일 때는, 맨 위에 큰 삼각형 1개를 놓고, 아래를 한 변의 길이가 1인 삼각형 $n-1$개로 채울 수 있습니다. ($n-1$이 홀수이기 때문에, 위아래로 채워넣으면 됩니다) 반대로 $n$이 큰 홀수일 때는 맨 위에 삼각형 4개를 놓고, 아래를 한 변의 길이가 짝수인 삼각형 $n-4$개로 채워넣으면 됩니다. 이 방법으로 $n = 2, 3, 5$ 외에는 모든 경우를 해결할 수 있음을 보이면 됩니다.&lt;/p&gt;

&lt;p&gt;구현에서 숫자를 off-by-one 에러 내서 무려 4번을 틀렸습니다. 흑흑…&lt;/p&gt;

&lt;h3 id=&quot;d--decorative-dominoes-142분-ac&quot;&gt;D : Decorative Dominoes (142분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : DHDroid, Gratus907     Code : Gratus907&lt;/code&gt;  &lt;br /&gt;
재밌게 풀었습니다. 도미노에 숫자를 써넣되, 숫자가 2번 이상 중복되어서는 안 되고, 도미노칸 하나는 적어도 주변에 같은 숫자가 써있는 도미노가 하나 있어야 합니다.&lt;/p&gt;

&lt;p&gt;문제를 이분 매칭으로 만들어 풀면 그렇게 어렵지는 않은데 구현이 상당히 귀찮습니다. DHDroid가 이분매칭의 대략적인 아이디어를 제시하고, 제가 정확히 어떻게 풀건지 좀 고민해보다가 풀었습니다. pair를 노드로 다시 인코딩한다던가 하는 구현의 잡다한 트릭들이 많이 들어간것 같습니다.&lt;/p&gt;

&lt;p&gt;이때, 제가 구현하는 동안 DHDroid는 계속 L에 대한 아이디어를 제시하고 Coffeetea와 B를 해결했습니다. D와 L을 오가면서 저랑 DHdroid가 풀이를 둘다 거의 완성했었기 때문에, L번도 사실 시간이 충분하다면 코딩할 수 있었습니다.&lt;/p&gt;

&lt;h3 id=&quot;g--gravity-grid-160분-ac-3-wa&quot;&gt;G : Gravity Grid (160분 AC, 3 WA)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Gratus907     Code : Gratus907&lt;/code&gt;&lt;br /&gt;
단순 시뮬레이션 문제입니다. 중력이 작용하는 칸에서 열만 고르면서 틱택토를 하는데, $k$개를 한줄로 (가로, 세로, 대각선) 모으면 승리합니다.&lt;/p&gt;

&lt;p&gt;가로 방향, 세로 방향, 대각선 방향의 DSU를 관리하면 어렵지 않습니다. 가로방향과 세로방향의 크기는 자명한데, 대각선방향은 대각선에 적절한 인덱스를 부여하여 $(h + w)$개의 DSU를 $\min(h, w)$개 칸을 갖도록 관리하면 잘 해볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;중간에 실수로, $h$와 $w$를 바꿔 썼는데 놀랍게도 WA가 아니라 MLE를 받았습니다. 어떤 원리로 MLE가 나는지는 파악하지 못한 채로, 벡터로 정수 900만 개를 allocate하는거 자체가 문제가 있는건가 하는 생각에 new int를 쓰는 등 삽질을 했지만 원인은 단순 실수였음을 한참 나중에 찾아냈습니다.&lt;/p&gt;

&lt;h3 id=&quot;b--bookshelf-building-175분-ac-3-wa&quot;&gt;B : Bookshelf Building (175분 AC, 3 WA)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : DHDroid, Coffeetea     Code : DHDroid&lt;/code&gt;  &lt;br /&gt;
읽어보지 않았지만 제가 G번 푸는 동안 둘이 잘 풀고 코딩했습니다.&lt;/p&gt;

&lt;h3 id=&quot;m--mixtape-management-199분-ac&quot;&gt;M : Mixtape Management (199분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : Coffeetea, Gratus907&lt;/code&gt;
쉬운 문제이지만 팀원간의 커뮤니케이션 실수로 아무도 읽지 않아서 버려진 문제입니다. 문제가 매우 길고 지문이 혼란스러운데, 숫자의 크기 정렬과 문자열로써의 정렬 간에 발생하는 차이에 대한 문제입니다.&lt;/p&gt;

&lt;p&gt;이 숫자가 몇번째에 위치해야 하는지를 파악한 다음, 그 앞에는 모두 1들을, 자기 자신은 2를, 뒤에는 3들을 붙이면 됩니다. 이 말만으로는 전혀 무슨말인지 알 수가 없지만..&lt;/p&gt;

&lt;p&gt;예제 4 2 6 1 5 7 3 을 보면, 1이 4번째이므로 1 1 1 2 3 3 3 으로 만듭니다. 이후에는, 2가 두번째이므로 11, 12, 13, 2 (이미 끝난 숫자는 건드리지 않습니다), 33, 33, 33으로 만들고… 이런식으로 1, 2, 3을 붙여서 만들면 됩니다.&lt;/p&gt;

&lt;p&gt;예제에 대한 저희의 답은 1112 12 131312 2 33132 3313332 332 입니다. 20줄 내외의 코드로 해결가능합니다. ㅋㅋ! 199분 AC.&lt;/p&gt;

&lt;h3 id=&quot;l--lexicographical-lecturing-209분-ac&quot;&gt;L : Lexicographical Lecturing (209분 AC)&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Solve : DHDroid, Gratus907     Code : Gratus907&lt;/code&gt;
먼저 문제를 설명하자면, $n$ 개의 길이 $L$짜리 문자열이 주어지고, 이 문자열의 어떤 $[i, j]$ 구간들만을 이용하여 정렬한 결과가 원래의 정렬 결과와 같게 하는 최소 길이 $[i, j]$를 찾는 문제입니다.&lt;/p&gt;

&lt;p&gt;Prefix에 관한 배열을 관리하는데, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p[k][j]&lt;/code&gt; 는 현재 보는 $k$번 문자열과 그 앞 문자열의 $j$번째 문자를 비교한 결과를 저장합니다. 이때, 우리가 원하는 $[i, j]$는 이 $p$배열에서 다음과 같게 됩니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$p$배열의 sub-matrix $[2, n] \times [i, j]$를 뽑았을 때, 모든 행에 leading 1이 있어야 합니다. $p$배열의 정의를 생각해보면, sub-matrix의 row가 1로 시작한다면 (첫번째 non-zero element가 1이라는 뜻) 정렬 결과가 올바르고, -1이라면 정렬 결과가 틀리며, 모든 element가 0이라면 비교가 불가능해서 판단할 수 없기 때문에 역시 올바르지 않습니다.&lt;/li&gt;
  &lt;li&gt;그러면, 이를 어떻게 파악할 것인지가 문제인데…&lt;/li&gt;
  &lt;li&gt;각 i, j마다, “내 뒤로 보이는 첫번째 +1”과 “내 뒤로 보이는 첫번째 -1” 의 위치를 저장합니다. 이제, 어떤 $[i, -]$ 구간이 올바르기 위해서는 $i$번 뒤로 나타나는 첫번째 1의 위치가 첫번째 -1보다 앞이어야 합니다.&lt;/li&gt;
  &lt;li&gt;이제, $i$로 시작하는 구간들 중, 적어도 모든 행이 leading 1을 갖도록 구간 끝점을 뒤로 밀어줘야 합니다.&lt;/li&gt;
  &lt;li&gt;각 $i$로 시작하는 구간들을 $O(n)$에 판단가능해서, $O(nL)$ 시간에 작동합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이번 연습 하이라이트는, M번을 맞고 나서 시간이 11분 남아있었는데 제가 이걸 10분 만에 짜서 예제만 돌려보고 바로 내서 맞았다는 점입니다. ㅋㅋ!! 
제가 구현을 못하는것은 구현이 느려서가 아니라 말렸을때 답이 없어서 그런거고, 사실 구현 속도는 그럭저럭 느리지 않은 것 같습니다.&lt;/p&gt;

&lt;h3 id=&quot;review&quot;&gt;Review&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;여전히 이 팀은 그냥 PS를 즐길 수 있게 해주는 원동력입니다. 세명의 장단점이 비교적 뚜렷하고 서로 보완적인 구성입니다.&lt;/li&gt;
  &lt;li&gt;GCPC 셋 자체는 괜찮은데, 5시간이었다면 아마 남은 1시간 반동안 하나 잡고 풀기 쉽지 않았을 것 같습니다. 실제로 남은 문제들은 충격적인 난이도 (다이아 또는 ?) 를 가지고 있었습니다.&lt;/li&gt;
  &lt;li&gt;제가 구현에 묶여있는동안 두명이 J도 좀 풀어놨던데, 무슨 각도정렬 + 미친기하 + 단절점 문제였습니다. 결과적으로 솔루션은 거의 다 맞았던 것으로 기억하는데, 저는 24시간 줘도 그걸 구현할 자신이 없으므로 아마 어차피 AC를 받지는 못했을 것입니다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="cp-rounds" /><summary type="html">Contents F : Flip Flow (10분 AC) A : Adolescent Architecture / K : Knightly Knowledge (45 / 85분 AC, 각 1WA) C : Confined Catching (67분 AC) I : Impressive Integers (103분 AC, 4 WA) D : Decorative Dominoes (142분 AC) G : Gravity Grid (160분 AC, 3 WA) B : Bookshelf Building (175분 AC, 3 WA) M : Mixtape Management (199분 AC) L : Lexicographical Lecturing (209분 AC) Review 멤버가 조금씩 바뀌면서 지난 3년간 UCPC, ICPC, HashCode 등을 함께해온 팀 Little Piplup으로 이번에는 다시 제가 참여하게 되었습니다. 이 팀은 2019년 저와 Coffeetea, DHDroid로 시작해서 PS 공부도 같이 하고, 많은 대회를 뛰면서 나름 행복 PS 해온 팀입니다. 2020년에는 Hashcode를 기점으로 저랑 그전까지 같이 연습셋을 많이 돌았던 Dlwocks31이 들어와서 4명이 되었습니다. Hashcode는 4인팀이지만, UCPC와 ICPC는 3인 1팀입니다. 또한, ICPC의 경우 휴학생이 본선에 진출할수 없다는 규정이 있는데 이 팀은 저를 제외한 3명이 모두 휴학생 (병특 중)이라 2020 ICPC에서는 자연스럽게 제가 다른 팀을 찾아 나가고 3명이서 Army Piplup 을 구성해서 나갈 수 있었고, 2020 UCPC는 dlwocks31이 다른 팀원들이랑 출전했었습니다. 2021 UCPC는… 2명 2명을 가르고 한명씩을 더 영입했는데, 저랑 dlwocks31쪽은 어리석은 실수로 대회를 치르지 못했었습니다. 이번에는 dlwocks31이 딱히 PS에 더이상 동기가 많이 떨어졌다는 식으로 기회를 양보하기도 했고, 저는 다른 팀원들을 모으더라도 서울대에서 본선을 진출하기는 쉽지 않겠다는 판단이 들어서 행복 PS를 위해 이 팀 그대로 나가기로 했습니다. 무엇보다 같이 문제를 풀고 팀연습하는 과정을 즐길 수 있는 팀이라서 그렇기도 합니다. ICPC는 순수하게 PS를 즐기러 나가지만 (본선 진출권도 없으므로) 그래도 이왕 모인거 팀연습이나 한두번 하자는 생각으로 GCPC 2020 셋을 돌았습니다. GCPC는 비교적 쉬운 리저널로, 원래 5시간 셋이지만 예선만 나갈거기도 하고 저희한테 시간이 많이 없어서 3.5시간으로 잡고 돌았습니다. 풀만한 문제는 다 푼듯 합니다. DHdroid가 ABCD, 제가 EFGHI, Coffeetea가 JKLM을 읽자고 생각했지만 커뮤니케이션 미스로 Coffeetea가 I부터 읽었고 M은 아무도 잡지 않았습니다. ㅋㅋㅋㅋ F : Flip Flow (10분 AC) Solve : Gratus907 Code : Gratus907 재밌게도 GCPC는 문제제목이 문제 번호를 따라갑니다. 모래시계를 뒤집으면서 남은 모래의 양을 확인하는 문제인데, 전체 시간 $t$가 작아서 그대로 시뮬레이션 할 수 있습니다. 10분에 AC. A : Adolescent Architecture / K : Knightly Knowledge (45 / 85분 AC, 각 1WA) 각각 DHDroid / Coffeetea가 잡았습니다. E는 딱 보기에도 어려웠고, G는 귀찮은 구현이 필요해 보였습니다. H는 너무 문제가 길어서 걸러버렸고… ‘컴퓨터가 남으면’ G를 짜겠다고 말했는데, DHdroid와 Coffeetea가 A, K가 쉽다고 주장했으므로 컴퓨터를 제가 잡고있는건 좋은 전략이 아니라고 생각했습니다. 다만 둘다 구현을 그렇게 빠르게 쳐내지는 못했습니다. 저는 두 문제 다 읽지 않았지만 각각 2000, 2500바이트의 코딩이 필요했던 것으로 보아 뇌절도 있었지만 근본적으로 구현난이도가 좀 있었던것 같습니다. 저는 양쪽 다 구현에 참여하지 않았고, 둘다 구상이 끝나고 구현만 남은 상태였기 때문에, DHDroid가 A번을 코딩할 때는 Coffeetea랑 같이 I번을, Coffeetea가 K번을 코딩하는 동안 DHDroid랑 같이 C, D를 풀 수 있었습니다. Coffeetea가 K번의 구현에서 상당히 많이 고전했기 때문에, 버그를 찾기 위해 코드를 따로 보면서 (실전에서는 코드 출력에 해당하는 선택입니다) 저한테 중간에 컴퓨터를 넘겨서 I번을 (몇번의 디버깅 끝에) 성공했습니다. C : Confined Catching (67분 AC) Solve : Gratus907, DHDroid 굉장히 재밌는 퍼즐틱한 문제였다고 생각합니다. 상하좌우로 움직일 수 있는 ‘말’ 이 나에게 2개, 상대에게 1개 주어집니다. $100 \times 100$ 그리드 안에서, 내가 두 말을 동시에 움직이면, 상대가 그걸 보고 도망칠 수 있습니다. 말 두 개를 잘 coordination해서, 상대 말을 ‘잡으면’ 이기는 게임입니다. 단, 600턴의 시간 제한이 있습니다. 처음에는 두 말이 이루는 직사각형을 좁히는 등 몇가지 아이디어를 생각했지만, 적절한 아이디어가 없어 고민하던 중에 제가 말 하나는 $x$좌표를 먼저 따라붙고, 말 하나는 $y$좌표를 먼저 따라붙는 아이디어를 제시했습니다. 상대가 어느쪽으로 도망치든 두 말 중 적어도 하나는 거리를 줄일 수 있음을 보장받기 때문에 (직선상의 경우가 예외가 되지만, 다음 턴에는 다시 줄일 수 있습니다) 어떻게 될 것 같았고, 잘 코너로 몰면 이길 수 있다고 생각했습니다. DHDroid가 이걸 받고 잠깐 생각해보더니 ‘내 말 두 개와 벽이 이루는 직사각형이 줄어든다’ 는 논증으로 이 방법이 올바름을 증명했고, 제가 Coffeetea에게 잠깐 컴퓨터를 받아서 구현해서 맞았습니다. I : Impressive Integers (103분 AC, 4 WA) Solve : Coffeetea, Gratus907 요약하자면, 어떤 $n$이 주어졌을 때, 자연수 $a, b, c$를 골라서, 한 변의 길이가 $c$인 정삼각형을 한 변의 길이가 $a$ 와 $b$인 정삼각형들로 채우는데 정확히 $n$개를 쓰도록 할 수 있는지에 대한 문제입니다. Coffeetea가 먼저 맨 위에 1개 또는 4개만 쓰고, 나머지를 잘 채워넣으면 될것같다는 간단하지만 문제를 바로 해결하는 아이디어를 던졌고, 제가 빈 로직을 채워넣어서 문제를 해결했습니다. $n$이 큰 짝수일 때는, 맨 위에 큰 삼각형 1개를 놓고, 아래를 한 변의 길이가 1인 삼각형 $n-1$개로 채울 수 있습니다. ($n-1$이 홀수이기 때문에, 위아래로 채워넣으면 됩니다) 반대로 $n$이 큰 홀수일 때는 맨 위에 삼각형 4개를 놓고, 아래를 한 변의 길이가 짝수인 삼각형 $n-4$개로 채워넣으면 됩니다. 이 방법으로 $n = 2, 3, 5$ 외에는 모든 경우를 해결할 수 있음을 보이면 됩니다. 구현에서 숫자를 off-by-one 에러 내서 무려 4번을 틀렸습니다. 흑흑… D : Decorative Dominoes (142분 AC) Solve : DHDroid, Gratus907 Code : Gratus907 재밌게 풀었습니다. 도미노에 숫자를 써넣되, 숫자가 2번 이상 중복되어서는 안 되고, 도미노칸 하나는 적어도 주변에 같은 숫자가 써있는 도미노가 하나 있어야 합니다. 문제를 이분 매칭으로 만들어 풀면 그렇게 어렵지는 않은데 구현이 상당히 귀찮습니다. DHDroid가 이분매칭의 대략적인 아이디어를 제시하고, 제가 정확히 어떻게 풀건지 좀 고민해보다가 풀었습니다. pair를 노드로 다시 인코딩한다던가 하는 구현의 잡다한 트릭들이 많이 들어간것 같습니다. 이때, 제가 구현하는 동안 DHDroid는 계속 L에 대한 아이디어를 제시하고 Coffeetea와 B를 해결했습니다. D와 L을 오가면서 저랑 DHdroid가 풀이를 둘다 거의 완성했었기 때문에, L번도 사실 시간이 충분하다면 코딩할 수 있었습니다. G : Gravity Grid (160분 AC, 3 WA) Solve : Gratus907 Code : Gratus907 단순 시뮬레이션 문제입니다. 중력이 작용하는 칸에서 열만 고르면서 틱택토를 하는데, $k$개를 한줄로 (가로, 세로, 대각선) 모으면 승리합니다. 가로 방향, 세로 방향, 대각선 방향의 DSU를 관리하면 어렵지 않습니다. 가로방향과 세로방향의 크기는 자명한데, 대각선방향은 대각선에 적절한 인덱스를 부여하여 $(h + w)$개의 DSU를 $\min(h, w)$개 칸을 갖도록 관리하면 잘 해볼 수 있습니다. 중간에 실수로, $h$와 $w$를 바꿔 썼는데 놀랍게도 WA가 아니라 MLE를 받았습니다. 어떤 원리로 MLE가 나는지는 파악하지 못한 채로, 벡터로 정수 900만 개를 allocate하는거 자체가 문제가 있는건가 하는 생각에 new int를 쓰는 등 삽질을 했지만 원인은 단순 실수였음을 한참 나중에 찾아냈습니다. B : Bookshelf Building (175분 AC, 3 WA) Solve : DHDroid, Coffeetea Code : DHDroid 읽어보지 않았지만 제가 G번 푸는 동안 둘이 잘 풀고 코딩했습니다. M : Mixtape Management (199분 AC) Solve : Coffeetea, Gratus907 쉬운 문제이지만 팀원간의 커뮤니케이션 실수로 아무도 읽지 않아서 버려진 문제입니다. 문제가 매우 길고 지문이 혼란스러운데, 숫자의 크기 정렬과 문자열로써의 정렬 간에 발생하는 차이에 대한 문제입니다. 이 숫자가 몇번째에 위치해야 하는지를 파악한 다음, 그 앞에는 모두 1들을, 자기 자신은 2를, 뒤에는 3들을 붙이면 됩니다. 이 말만으로는 전혀 무슨말인지 알 수가 없지만.. 예제 4 2 6 1 5 7 3 을 보면, 1이 4번째이므로 1 1 1 2 3 3 3 으로 만듭니다. 이후에는, 2가 두번째이므로 11, 12, 13, 2 (이미 끝난 숫자는 건드리지 않습니다), 33, 33, 33으로 만들고… 이런식으로 1, 2, 3을 붙여서 만들면 됩니다. 예제에 대한 저희의 답은 1112 12 131312 2 33132 3313332 332 입니다. 20줄 내외의 코드로 해결가능합니다. ㅋㅋ! 199분 AC. L : Lexicographical Lecturing (209분 AC) Solve : DHDroid, Gratus907 Code : Gratus907 먼저 문제를 설명하자면, $n$ 개의 길이 $L$짜리 문자열이 주어지고, 이 문자열의 어떤 $[i, j]$ 구간들만을 이용하여 정렬한 결과가 원래의 정렬 결과와 같게 하는 최소 길이 $[i, j]$를 찾는 문제입니다. Prefix에 관한 배열을 관리하는데, p[k][j] 는 현재 보는 $k$번 문자열과 그 앞 문자열의 $j$번째 문자를 비교한 결과를 저장합니다. 이때, 우리가 원하는 $[i, j]$는 이 $p$배열에서 다음과 같게 됩니다. $p$배열의 sub-matrix $[2, n] \times [i, j]$를 뽑았을 때, 모든 행에 leading 1이 있어야 합니다. $p$배열의 정의를 생각해보면, sub-matrix의 row가 1로 시작한다면 (첫번째 non-zero element가 1이라는 뜻) 정렬 결과가 올바르고, -1이라면 정렬 결과가 틀리며, 모든 element가 0이라면 비교가 불가능해서 판단할 수 없기 때문에 역시 올바르지 않습니다. 그러면, 이를 어떻게 파악할 것인지가 문제인데… 각 i, j마다, “내 뒤로 보이는 첫번째 +1”과 “내 뒤로 보이는 첫번째 -1” 의 위치를 저장합니다. 이제, 어떤 $[i, -]$ 구간이 올바르기 위해서는 $i$번 뒤로 나타나는 첫번째 1의 위치가 첫번째 -1보다 앞이어야 합니다. 이제, $i$로 시작하는 구간들 중, 적어도 모든 행이 leading 1을 갖도록 구간 끝점을 뒤로 밀어줘야 합니다. 각 $i$로 시작하는 구간들을 $O(n)$에 판단가능해서, $O(nL)$ 시간에 작동합니다. 이번 연습 하이라이트는, M번을 맞고 나서 시간이 11분 남아있었는데 제가 이걸 10분 만에 짜서 예제만 돌려보고 바로 내서 맞았다는 점입니다. ㅋㅋ!! 제가 구현을 못하는것은 구현이 느려서가 아니라 말렸을때 답이 없어서 그런거고, 사실 구현 속도는 그럭저럭 느리지 않은 것 같습니다. Review 여전히 이 팀은 그냥 PS를 즐길 수 있게 해주는 원동력입니다. 세명의 장단점이 비교적 뚜렷하고 서로 보완적인 구성입니다. GCPC 셋 자체는 괜찮은데, 5시간이었다면 아마 남은 1시간 반동안 하나 잡고 풀기 쉽지 않았을 것 같습니다. 실제로 남은 문제들은 충격적인 난이도 (다이아 또는 ?) 를 가지고 있었습니다. 제가 구현에 묶여있는동안 두명이 J도 좀 풀어놨던데, 무슨 각도정렬 + 미친기하 + 단절점 문제였습니다. 결과적으로 솔루션은 거의 다 맞았던 것으로 기억하는데, 저는 24시간 줘도 그걸 구현할 자신이 없으므로 아마 어차피 AC를 받지는 못했을 것입니다.</summary></entry><entry><title type="html">Semantic Segmentation : Introduction</title><link href="http://localhost:4000/deep-learning-study/semantic-segmentation/" rel="alternate" type="text/html" title="Semantic Segmentation : Introduction" /><published>2021-09-26T00:00:00+09:00</published><updated>2021-09-26T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/semantic-segmentation</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/semantic-segmentation/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#문제-소개&quot; id=&quot;markdown-toc-문제-소개&quot;&gt;문제 소개&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#활용&quot; id=&quot;markdown-toc-활용&quot;&gt;활용&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#개요&quot; id=&quot;markdown-toc-개요&quot;&gt;개요&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;이 글의 상당 부분은, 서베이 논문인 Minaee, S., Boykov, Y., Porikli, F., Plaza, A., Kehtarnavaz, N., &amp;amp; Terzopoulos, D. (2020). Image Segmentation Using Deep Learning: A Survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1–22. https://doi.org/10.1109/TPAMI.2021.3059968 을 정리한 내용입니다.&lt;/p&gt;

&lt;h2 id=&quot;문제-소개&quot;&gt;문제 소개&lt;/h2&gt;
&lt;p&gt;Semantic Segmentation이란, Computer Vision 분야의 대표적인 task중 하나로, 간단히 요약하자면&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;이미지가 주어졌을 때&lt;/strong&gt;, 그 이미지를 픽셀단위로 &lt;strong&gt;어떤 대상인지&lt;/strong&gt; 를 분류해내는 문제입니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/65248dcf9168b967e664f799c65014d13df38e1e7bff5db23b3db50ee05952ff.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;br /&gt;
출처 : Stanford cs231n slides&lt;/p&gt;

&lt;p&gt;이 사진은 대표적인 네 가지의 task를 비교한 것인데, 굉장히 직관적으로 무슨 의미인지 알 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;활용&quot;&gt;활용&lt;/h2&gt;
&lt;p&gt;Semantic segmentation은 딱 느낌에도 매우 유용할 것 같은데, 대표적인 활용처 몇개를 생각해보면…&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;자율 주행 : 자율주행에서 지금 눈앞에 보이는 것이 도로인지, 흙바닥인지, 물웅덩이인지를 판단하는 작업은 굉장히 중요합니다.&lt;/li&gt;
  &lt;li&gt;의료 이미지 : CT 사진에서, 각 고형장기를 분류한다거나, 정상조직과 비정상조직을 구분하는 작업도 결국은 segmentation에 기반합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;
&lt;p&gt;여기서는 정말 대략적인 아이디어를 한줄로 정리하고, 개별 네트워크 구조에 대한 포스팅을 통해 전체 내용을 붙여나가려고 합니다.&lt;/p&gt;

&lt;p&gt;이 이미지가 개인지, 고양이인지를 판단하는 Classification의 경우, 통상적으로 convolutional neural network (CNN) 에 기반한 방법들을 사용합니다. 사진 전체의 정보를 인코딩한 $3 \times W \times H$ 텐서를 가지고 시작해서, Convolution layer를 거치면서 정보들을 추출하고, 마지막에 fully connected layer를 붙여서 실제로 클래스를 구분해내는 식으로 진행하게 되는 것입니다.&lt;/p&gt;

&lt;p&gt;이 방법을 semantic segmentation같은 문제에서 적용하기 어려운 이유는, 마지막 fully connected layer가 기하적인 위치정보를 다 날려버리기 때문입니다. 즉, ‘고양이가’ 있다는 정보는 어떻게 분류해볼 수 있을지라도, 고양이가 ‘어디에’ 있는지에 대해서는 전혀 알 수가 없게 됩니다. 그렇기 때문에 fully connected layer를 쓸 수 없습니다.&lt;/p&gt;

&lt;p&gt;이를 개선하기 위해 나온 아이디어로, 마지막 정보를 Fully connected로 처리하는 대신 $1 \times 1$ Convolution을 쓰는 방법을 생각해 볼 수 있습니다. Convolution은 위치정보를 어느정도 보존할 수 있다는 점에서 착안한 아이디어인데, 이는 2016년에 &lt;strong&gt;Fully Convolutional Network (FCN)&lt;/strong&gt; 이라는 이름으로 발표되었습니다. 여기에 추가로 Conditional Random Field, Markov Random Field 등의 모델들을 적용하면 더 높은 정확도를 얻을 수 있다고 합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/d945a1658b049113080a2dbfb06afd68ae4b46cb6059c4a462159cf9fafa4159.png&quot; alt=&quot;picture 1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CNN에서는 Convolution과 함께 Pooling을 반복하기 때문에, 갈수록 feature map의 크기가 줄어들게 됩니다. 그런데 우리는 각 픽셀단위로 어떤 클래스인지를 찾아내는 것이 목표이기 때문에, 다시 feature map의 크기를 원본 이미지 크기만큼 키워야 합니다. 이를 위해 다양한 방법들이 있는데, FCN에서는 skip connection / upsampling 이라고 해서, 네트워크를 타고 흐르는 중간의 정보를 뽑아다가 최종 정보와 함께 사용하는 방식을 사용합니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/0ba5dd41655ed3613a70807a6580e8dfe8ee2a0bea10f9684f934e5eecd4b4d3.png&quot; alt=&quot;picture 2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;CNN에서 사용하는 개념 중, feature map의 크기를 거꾸로 늘리게 되는 deconvolution이라는 연산이 있습니다 (convolution의 계산적인 inverse이긴 한데, 정확한 inverse는 아닙니다. transposed convolution이 좀더 정확한 말인데, 이 부분도 나중에 다루겠습니다). CNN을 타고 feature map의 개수가 줄어들었다는 것이 문제가 된다면, 다시 deconvolution을 그만큼 거꾸로 돌려서 feature map을 돌이켜주면 되지 않을까요? 이를 &lt;strong&gt;Encoder-Decoder&lt;/strong&gt; 형태의 구조라고 부르며, &lt;strong&gt;U-Net&lt;/strong&gt; 을 필두로 (이 이름은, 말그대로 convolution과 deconvolution을 U자형으로 쌓아서 붙여진 이름입니다) 여러 모델들이 성공적인 결과를 보여주었습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/becc0a664a9a998e0f9d78b27411a3bb3fa0ac435f41b799ce11600416e38e7f.png&quot; alt=&quot;picture 3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Convolution에서 pooling을 통해 정보를 잃다가 다시 이걸 만들어주는 것 대신, 처음부터 feature map의 크기를 줄이지 않으면 어떨까요? 그렇다고 pooling을 아예 하지 않을 수는 없는데, 필터의 크기가 크면 연산이 너무 많아지는 데다가 learning capacity가 너무 커지는 현상들이 발생하기 때문입니다. 이런 문제를 어느정도 해결하는 Dilated convolution은 Convolution을 할 때부터 적당히 필터에 제로 패딩을 붙여줌으로써, 공간적인 정보를 잃지 않고 feature map의 크기를 유지해 줍니다. 이 연산을 이용하여 (원래의 upsampling과 함께 쓰긴 합니다) Dilated Convolutional Model 들이 개발되었는데, 대표적으로 Google의 &lt;strong&gt;DeepLab&lt;/strong&gt; 를 예시로 들 수 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../../images/2e524914bd271cef4334b42466615f08a209df30df675c74151349d76ca87345.png&quot; alt=&quot;picture 4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;우선은 FCN, U-Net, DeepLab을 필두로 정리를 시작해 보려고 합니다.&lt;/p&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="deep-learning-study" /><summary type="html">Contents 문제 소개 활용 개요 이 글의 상당 부분은, 서베이 논문인 Minaee, S., Boykov, Y., Porikli, F., Plaza, A., Kehtarnavaz, N., &amp;amp; Terzopoulos, D. (2020). Image Segmentation Using Deep Learning: A Survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1–22. https://doi.org/10.1109/TPAMI.2021.3059968 을 정리한 내용입니다. 문제 소개 Semantic Segmentation이란, Computer Vision 분야의 대표적인 task중 하나로, 간단히 요약하자면 이미지가 주어졌을 때, 그 이미지를 픽셀단위로 어떤 대상인지 를 분류해내는 문제입니다. 출처 : Stanford cs231n slides 이 사진은 대표적인 네 가지의 task를 비교한 것인데, 굉장히 직관적으로 무슨 의미인지 알 수 있습니다. 활용 Semantic segmentation은 딱 느낌에도 매우 유용할 것 같은데, 대표적인 활용처 몇개를 생각해보면… 자율 주행 : 자율주행에서 지금 눈앞에 보이는 것이 도로인지, 흙바닥인지, 물웅덩이인지를 판단하는 작업은 굉장히 중요합니다. 의료 이미지 : CT 사진에서, 각 고형장기를 분류한다거나, 정상조직과 비정상조직을 구분하는 작업도 결국은 segmentation에 기반합니다. 개요 여기서는 정말 대략적인 아이디어를 한줄로 정리하고, 개별 네트워크 구조에 대한 포스팅을 통해 전체 내용을 붙여나가려고 합니다. 이 이미지가 개인지, 고양이인지를 판단하는 Classification의 경우, 통상적으로 convolutional neural network (CNN) 에 기반한 방법들을 사용합니다. 사진 전체의 정보를 인코딩한 $3 \times W \times H$ 텐서를 가지고 시작해서, Convolution layer를 거치면서 정보들을 추출하고, 마지막에 fully connected layer를 붙여서 실제로 클래스를 구분해내는 식으로 진행하게 되는 것입니다. 이 방법을 semantic segmentation같은 문제에서 적용하기 어려운 이유는, 마지막 fully connected layer가 기하적인 위치정보를 다 날려버리기 때문입니다. 즉, ‘고양이가’ 있다는 정보는 어떻게 분류해볼 수 있을지라도, 고양이가 ‘어디에’ 있는지에 대해서는 전혀 알 수가 없게 됩니다. 그렇기 때문에 fully connected layer를 쓸 수 없습니다. 이를 개선하기 위해 나온 아이디어로, 마지막 정보를 Fully connected로 처리하는 대신 $1 \times 1$ Convolution을 쓰는 방법을 생각해 볼 수 있습니다. Convolution은 위치정보를 어느정도 보존할 수 있다는 점에서 착안한 아이디어인데, 이는 2016년에 Fully Convolutional Network (FCN) 이라는 이름으로 발표되었습니다. 여기에 추가로 Conditional Random Field, Markov Random Field 등의 모델들을 적용하면 더 높은 정확도를 얻을 수 있다고 합니다. CNN에서는 Convolution과 함께 Pooling을 반복하기 때문에, 갈수록 feature map의 크기가 줄어들게 됩니다. 그런데 우리는 각 픽셀단위로 어떤 클래스인지를 찾아내는 것이 목표이기 때문에, 다시 feature map의 크기를 원본 이미지 크기만큼 키워야 합니다. 이를 위해 다양한 방법들이 있는데, FCN에서는 skip connection / upsampling 이라고 해서, 네트워크를 타고 흐르는 중간의 정보를 뽑아다가 최종 정보와 함께 사용하는 방식을 사용합니다. CNN에서 사용하는 개념 중, feature map의 크기를 거꾸로 늘리게 되는 deconvolution이라는 연산이 있습니다 (convolution의 계산적인 inverse이긴 한데, 정확한 inverse는 아닙니다. transposed convolution이 좀더 정확한 말인데, 이 부분도 나중에 다루겠습니다). CNN을 타고 feature map의 개수가 줄어들었다는 것이 문제가 된다면, 다시 deconvolution을 그만큼 거꾸로 돌려서 feature map을 돌이켜주면 되지 않을까요? 이를 Encoder-Decoder 형태의 구조라고 부르며, U-Net 을 필두로 (이 이름은, 말그대로 convolution과 deconvolution을 U자형으로 쌓아서 붙여진 이름입니다) 여러 모델들이 성공적인 결과를 보여주었습니다. Convolution에서 pooling을 통해 정보를 잃다가 다시 이걸 만들어주는 것 대신, 처음부터 feature map의 크기를 줄이지 않으면 어떨까요? 그렇다고 pooling을 아예 하지 않을 수는 없는데, 필터의 크기가 크면 연산이 너무 많아지는 데다가 learning capacity가 너무 커지는 현상들이 발생하기 때문입니다. 이런 문제를 어느정도 해결하는 Dilated convolution은 Convolution을 할 때부터 적당히 필터에 제로 패딩을 붙여줌으로써, 공간적인 정보를 잃지 않고 feature map의 크기를 유지해 줍니다. 이 연산을 이용하여 (원래의 upsampling과 함께 쓰긴 합니다) Dilated Convolutional Model 들이 개발되었는데, 대표적으로 Google의 DeepLab 를 예시로 들 수 있습니다. 우선은 FCN, U-Net, DeepLab을 필두로 정리를 시작해 보려고 합니다.</summary></entry><entry><title type="html">Stochastic Gradient Descent</title><link href="http://localhost:4000/deep-learning-study/sgd/" rel="alternate" type="text/html" title="Stochastic Gradient Descent" /><published>2021-09-24T00:00:00+09:00</published><updated>2021-09-24T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/sgd</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/sgd/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#stochastic-gradient-descent&quot; id=&quot;markdown-toc-stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#batch-sgd--cyclic-sgd&quot; id=&quot;markdown-toc-batch-sgd--cyclic-sgd&quot;&gt;Batch SGD / Cyclic SGD&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sgd-convergence-theorem&quot; id=&quot;markdown-toc-sgd-convergence-theorem&quot;&gt;SGD Convergence Theorem&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 2강 (9월 7일), 3강 (9월 9일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;stochastic-gradient-descent&quot;&gt;Stochastic Gradient Descent&lt;/h2&gt;

&lt;p&gt;ML에는 많은 Finite sum optimization이 있다. 우리는
$F(x) = \frac{1}{N} \sum_{i = 1}^{N} f_i(x)$ 를 최적화하고 싶다.
대표적으로, Gradient Descent를 쓸 수 있다. But, $N$이 매우 크면 이
함수를 한번 계산하는 시간이 매우 오래 걸린다.&lt;/p&gt;

&lt;p&gt;위 식을, 이 함수의 &lt;strong&gt;기댓값&lt;/strong&gt; 으로 이해할 수 있다.
\(\underset{x \in \R^p}{\minimize}\ \E_I[f_I(x)], \ I \sim \uniform{1}{N}\)&lt;/p&gt;

&lt;p&gt;이런 motivation을 통해, Stochastic (Random) Gradient Descent를 생각한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm (Stochastic Gradient Descent)&lt;/strong&gt; &lt;br /&gt;
임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha_k &amp;gt; 0$ 에 대해
다음을 반복한다.
\(i(k) \sim \uniform{1}{N},\quad x^{k+1} = x^k - \alpha_k \nabla{f_{i(k)}(x^k)}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;대략의 아이디어&lt;/strong&gt; :&lt;br /&gt;
GD처럼, Taylor expansion하고 Stochastic을 고려하여 Expectation을 씌운다.&lt;/p&gt;

&lt;p&gt;$x^k$ 근처에서 $F(x) = \frac{1}{N} \sum_{i = 1}^{N} f_i(x)$를 테일러
전개하고 $x^{k+1}$ 대입하면,
\(F(x^{k+1}) = F(x^k) - \alpha_k \nabla F(x^k)^T \nabla f_{i(k)}(x^k) + \order{\alpha_k^2}\)
이제, 양쪽에 $\E$ 를 씌운다.
\(\expect{F(x^{k+1})} = \expect{F(x^k)} - \alpha_k \expect{\nabla F(x^k)^T \nabla f_{i(k)}(x^k)} + \order{\alpha_k^2}\)
$\nabla F(x^k)^T$ 는 기댓값에 영향이 없고, $\nabla f_{i(k)}(x^k)$ 의
기댓값은 $\nabla F(x^k)$ 이므로,
\(\expect{F(x^{k+1})} = \expect{F(x^k)} - \alpha_k \norm{\nabla F(x^k)}^2 + \order{\alpha_k^2}\)
적당히 $\alpha_k$를 충분히 작게 잡으면, 기댓값이 감소할 수 있을 것 같다.&lt;/p&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Stochastic Gradient Descent도 수렴성에 관한 정리를 기술할 수
있으나, 증명이 매우 Tedious하고 ML 세팅에서는 그렇게 중요하지 않다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;직접 구현해서 테스트해 보면, 초반에 SGD가 GD보다 수렴속도가 빠르지만,
Eventually GD에게 따라잡힌다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;그러나, 우리는 ML을 공부하는데 있어 SGD를 Subroutine으로 쓸 것이고, 짧은 Training 시간의 환경에서 SGD가 in practice GD보다 잘 수렴한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Stochastic Gradient Descent에서, $i(k)$ 자체의 성질은 전혀 활용하지 않았다.&lt;/li&gt;
  &lt;li&gt;실제로, SGD의 수렴성 증명에서 중요한 것은, 다음과 같은 Framework면 충분하기 때문.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Algorithm (Stochastic Gradient Descent)&lt;/strong&gt; &lt;br /&gt;
임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha_k &amp;gt; 0$ 에 대해
다음을 반복한다.
\(i(k) \sim \uniform{1}{N},\quad x^{k+1} = x^k - \alpha_k g^k\) 이때,
$g^k$ 는 Stochastic gradient로, $\nabla F(x^k)$ 의 Unbiased Estimator
이면 - 즉, 기댓값이 $\nabla F(x^k)$ 이면 충분하다.&lt;/p&gt;

&lt;h2 id=&quot;batch-sgd--cyclic-sgd&quot;&gt;Batch SGD / Cyclic SGD&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;예를 들어, $g^k$를 고르는 방법으로 Batch sampling with/without
Replacement를 생각할 수 있다.&lt;/li&gt;
  &lt;li&gt;즉, $N$개 중 일부인 $B$개를 랜덤하게 계속
뽑아서, $\frac{1}{B}\sum_{b = 1}^{B} \nabla f_{i(k, b)}(x^k)$, 즉
$B$개의 batch에 대한 gradient의 평균을 쓰는 것.&lt;/li&gt;
  &lt;li&gt;이때, Batch를 뽑을 때
중복을 허용하는지 여부는 상관 없다 (둘 다 Unbiased estimator가 되기
때문). 중복을 허용하고 싶으면 random한 $B$개를 뽑고, 허용하고 싶지
않으면 random permutation의 첫 $B$개를 쓰면 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;특히, Batch 방법의 경우, GPU를 이용한 Parallel 연산에 유리하다는
추가적인 장점이 있다. GPU와 병렬처리를 최대한 활용하기 위해, GPU
memory에 들어가는 최대 $B$를 이용하는 것이 가장 유리하다. Batch size는
noise 정도에 따라 성능이 달라지는데, noise가 클수록 large batch가
유리하다.&lt;/p&gt;

&lt;p&gt;그런데…이 알고리즘에서, 원래 랜덤하지 않은 것을 억지로 랜덤하게 만들어서 풀고 있는 것 아닌가? Stochastic하게 뽑는 대신, 그냥 순서대로 돌리면서 쓰면 안 되나?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm : Cyclic SGD&lt;/strong&gt;&lt;br /&gt;
임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha &amp;gt; 0$ 에 대해 다음을 반복한다.
\(x^{k+1} = x^k - \alpha_k \nabla{f_{(k \text{ mod } N + 1)}(x^k)}\)&lt;/p&gt;

&lt;p&gt;이 방법은 stochastic한 부분이 사실 없다. 장단점은...&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(+)&lt;/code&gt; 확실하게 $N$개의 데이터를 $N$번마다 한번씩 정확하게 사용한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-)&lt;/code&gt; SGD의 수렴성에 대한 정리를 쓸 수 없다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-)&lt;/code&gt; 일반 SGD에 비해 Theoretically / Empirically, some case에서는 잘 작동하지 않음.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(-)&lt;/code&gt; Deep Learning으로 가면, Neural network가 이 순서(cyclic order)를 기억하는 경향 발생.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;특히 기억하는 경향에 의한 overfitting이 큰 이슈이기 때문에, 이를
방지해야 한다. 적당히 섞어주면 어떨까?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm : Shuffled Cyclic SGD&lt;/strong&gt;&lt;br /&gt;
임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha &amp;gt; 0$ 에 대해 다음을
반복한다.
\(x^{k+1} = x^k - \alpha \nabla{f_{\sigma^{(k/N)}(k \text{ mod } N + 1)}(x^k)}\)&lt;/p&gt;

&lt;p&gt;즉, $N$번에 한 번씩, 인덱스들을 랜덤하게 permutation해버린 다음, 그
순서로 다음 $N$번의 iteration을 Cyclic하게 돌린다. 이렇게 하면, 정확하게
$N$개의 데이터를 한번씩 쓴다는 장점을 챙기면서도, neural network가
학습하는 일을 막을 수 있다. 기존에는 강한 theory가 별로 없었지만, recent
breakthrough들이 이를 개선하고 있다.&lt;/p&gt;

&lt;p&gt;그냥 일반적인 세팅에서는, &lt;strong&gt;Shuffled cyclic minibatch SGD without
replacement&lt;/strong&gt; 를 쓰면 되고, &lt;strong&gt;GPU가 허락하는 최대한 큰 Batch size&lt;/strong&gt;를
잡으면 된다. Deep Learning의 많은 경우, 수학적인 분석이 실제
performance를 정확하게 예측하지 못하는 경향이 있는데, empirically this
is best.&lt;/p&gt;

&lt;p&gt;일반적인 expectation으로 표현된 최적화 문제, 예를 들어 확률변수
$\omega$에 대해 이런 문제들
\(\underset{x \in \R^p}{\minimize}\ \E_\omega[f_\omega(x)]\) 의 경우,
똑같이 SGD로 풀 수 있다. GD로도 할 수는 있지만,
일반적으로 ‘gradient의 기댓값’ 을 구하기가 어렵기 때문에...&lt;/p&gt;

&lt;p&gt;참고 : Optimization / ML에서, 대충 ‘한바퀴’ 를 &lt;strong&gt;Epoch&lt;/strong&gt; 라고 부른다. 대충
데이터들을 한바퀴 돌면 된다. Gradient descent면 한번 = 1 epoch, SGD면
$N$번, Batched SGD면 $N / B$ 번 정도.&lt;/p&gt;

&lt;h2 id=&quot;sgd-convergence-theorem&quot;&gt;SGD Convergence Theorem&lt;/h2&gt;

&lt;p&gt;상세하게 다루어야 할 내용은 아니지만, 앞서 공부한 Lipschitz Gradient Lemma 등을 이용해서 비슷한 증명을 쓸 수 있다.&lt;/p&gt;

&lt;p&gt;$F : \R^n \to \R$ 이 미분가능하고, $\nabla F$ 가 $L$-Lipschitz 연속이며,
$F$가 $-\infty$가 아닌 최소값을 가지며, $g^k$가 다음 조건
\(\E[g^k \di x^k] = \nabla F(x^k), \quad \quad \expect{\norm{g^k - \nabla F(x^k)}^2 \di x^k} \leq \sigma^2\)
을 만족할 때, 즉 $g^k$ 가 Gradient에 대한 Unbiased estimator이고 그
분산이 $\sigma^2$ 이하일 때, 다음이 성립한다.
\(\frac{1}{M}\sum_{k = 0}^{M-1} \expect{\norm{\nabla F(x^k)}^2} \leq \frac{1}{\sqrt{M}}\left(2L(F(x^0) - F^*) + \sigma^2\right)\)&lt;/p&gt;

&lt;p&gt;즉, Gradient의 크기의 평균이 $M$번의 iteration에 의해
$\order{\frac{1}{\sqrt{M}}}$로 감소한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Proof.&lt;/em&gt;&lt;/strong&gt; 먼저, Lipschitz Gradient Lemma를
$x = x^k, \delta = -\alpha g^k$에 대해 쓰면,
\(F(x^{k+1}) \leq F(x^k) -\alpha \nabla F(x^k)^T g^k + \frac{\alpha^2L}{2}\norm{g^k}^2\)
$x^k$ 가 이미 주어졌을 때의 Conditional expectation을 쓴다.
\(\expect{F(x^{k+1}) \di x^k} \leq F(x^k) - \alpha \norm{\nabla F(x^k)}^2 + \frac{\alpha^2 L}{2}\left(\norm{\nabla F(x^k)}^2 + \sigma^2\right)\)
이제 이를 다시 Total expectation을 취하면,
\(\expect{F(x^{k+1})} \leq \expect{F(x^k)} - \alpha\left(1 - \frac{\alpha L}{2}\right) \expect{\nabla F(x^k)} + \frac{\alpha^2 \sigma^2 L}{2}\)
이를 $k = 0 \dots M-1$에 대해 양변을 더하여
\(\alpha\left(1 - \frac{\alpha L}{2}\right) \sum_{k = 1}^{M-1}\expect{\nabla F(x^k)} \leq (F(x^0) - F^*) + \expect{F(x^k) - F^*} + \frac{\alpha^2 \sigma^2 L}{2}\)
마지막으로, $\alpha = \frac{1}{L \sqrt{K}}$ 를 취하여 주어진 식을
얻는다. ◻&lt;/p&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry><entry><title type="html">Shallow Neural Networks - Introduction</title><link href="http://localhost:4000/deep-learning-study/shallow-nn/" rel="alternate" type="text/html" title="Shallow Neural Networks - Introduction" /><published>2021-09-24T00:00:00+09:00</published><updated>2021-09-24T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/shallow-nn</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/shallow-nn/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#shallow-neural-network--introduction&quot; id=&quot;markdown-toc-shallow-neural-network--introduction&quot;&gt;Shallow Neural Network : Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#kl-divergence&quot; id=&quot;markdown-toc-kl-divergence&quot;&gt;KL-Divergence&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 3강 (9월 9일), 4강 (9월 14일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;shallow-neural-network--introduction&quot;&gt;Shallow Neural Network : Introduction&lt;/h2&gt;

&lt;p&gt;데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨
$Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이때, 어떤
&lt;strong&gt;True Unknown Function&lt;/strong&gt; $f_\star : \mathcal{X} \to \mathcal{Y}$ 가
있다고 생각하면, $Y_i = f_\star(X_i)$ 를 만족한다.&lt;/p&gt;

&lt;p&gt;우리는, $X_i, Y_i$로부터, $f_\star$과 가까운 어떤 함수 $f$를 찾아내는
작업을 수행하고 싶다. $X_i$들에 대해 $Y_i$는 사람이 수집한 데이터를 쓰기
때문에, 이를 &lt;strong&gt;Supervised Learning&lt;/strong&gt;이라고 부른다.&lt;/p&gt;

&lt;p&gt;뭔가를 시작하기 전에, 일단 $f_\star$과 가까운 $f$가 도대체 무슨 말인지를
명확히 해야 한다. 뭔가를 최소화하는 문제로 만들고 싶은데... 가장 자명한
방법으로 생각하면 어떤 손실함수 $\ell$을 도입해서, 이렇게 쓰고 싶다.
\(\underset{f \in \mathcal{F}}{\minimize}\ \sup_{x \in \mathcal{X}} \ell(f(x), f_\star(x))\)
이 문제는, (1) 모든 가능한 함수들의 공간 위에서 뭔가를 최적화한다는 것은
알고리즘적으로 말이 안 되고, (2) 이 최적화 문제의 해는 $f_\star$이니까,
사실 최적화 문제도 딱히 아니다. 모든 $x$에 대해 $f_\star$를 알고 있으면
최적화를 생각할 이유가 없다.&lt;/p&gt;

&lt;p&gt;대신에, 함수들의 공간을 제약하자. 어떤 파라미터 $\theta$를 이용하여,
우리는 다음과 같은 최적화 문제로 바꾸고 싶다.
\(\underset{\theta \in \Theta}{\minimize}\ \sup_{x \in \mathcal{X}} \ell(f_\theta(x), f_\star(x))\)&lt;/p&gt;

&lt;p&gt;여전히, 일단 우리는 모든 $x$에 대해 $f_\star$를 알고 있지 않다. 우리가
알고 있는 $x_1, x_2, \dots$ 에 대한 답 $y_1, y_2 \dots$ 들을 맞춰낼 수
있는 함수를 일단 만드는 정도가 최선이 아닐까? 그리고, 최악의 경우를
최소화하는 대신, 평균을 최적화하는게 뭔가 ‘일반적으로’ 좋은 솔루션을
제공할 것 같다. supremum을 최소화한다는 것은 너무 지나친 목표이다.
\(\underset{\theta \in \Theta}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_\theta(x_i), f_\star(x_i))\)
우리는 $f_\star(x_i) = y_i$ 임을 알고 있으므로, 이제 뭔가가 가능하다.&lt;/p&gt;

&lt;p&gt;이제, $\theta$를 이용하여 표현되는 $f_\theta$를 &lt;strong&gt;model&lt;/strong&gt; 또는 &lt;strong&gt;neural
network&lt;/strong&gt;라고 부를 것이다. 또한, 이 최적화 문제를 푸는 작업을
&lt;strong&gt;training&lt;/strong&gt; 이라고 부를 것이다. 즉, 파라미터를 이용해서 표현한 모델
$f_\theta$를 SGD와 같은 알고리즘을 이용하여 training한다는 표현이 된다.
현재 거의 모든 방법들이 SGD에 기반하고 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example : Least square regression&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$\mathcal{X} = \R^p, \mathcal{Y} = \R, \Theta = \R^p$이고, 모델
$f_\theta(x) = x^T \theta$, $L(y_1, y_2) = \frac{1}{2}(y_1 - y_2)^2$ 인
문제를 Least square라고 부른다. 즉, 주어진 데이터들을 비슷하게 맞춰내는
Linear한 함수를 찍는 것.&lt;/p&gt;

&lt;h2 id=&quot;kl-divergence&quot;&gt;KL-Divergence&lt;/h2&gt;

&lt;p&gt;As a mathematical tool, 어떤 $p, q \in \R^n$이 probability mass vector일
때, 즉 $p_i, q_i \geq 0$ 이고 $\sum p_i = \sum q_i = 1$일 때, 우리는 두
distribution의 차이를 생각하고 싶다.&lt;/p&gt;

&lt;p&gt;Kullback-Leibler Divergence (KL-Divergence)를 다음과 같이 정의한다.
\(\DKL{p}{q} = \sum_{i = 1}^{n} p_i \log\frac{p_i}{q_i} = -\sum_{i = 1}^{n} p_i \log q_i + \sum_{i = 1}^{n} p_i \log p_i\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;이는 다시, 정보이론의 용어로는 Cross entropy $H(p, q)$ 와 Entropy
$H(p)$의 합으로 쓰여진다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;편의를 위해 (자연스럽게), $0 \log (0 / 0) = 0$ 으로, $0 \log 0 = 0$
으로, $x &amp;gt; 0$이면 $x \log (x / 0) = \infty$ 으로 둔다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;몇가지 성질들을 살펴보면...&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\DKL{p}{q}$ 는 일반적으로 $\DKL{q}{p}$ 와 같지 않다. (그래서
  metric은 아님)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\DKL{p}{q} \geq 0$ 이고, $p \neq q$ 이면 $\DKL{p}{q} &amp;gt; 0$ (과제)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;$\DKL{p}{q} = \infty$ 인 경우도 가능.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;KL-Divergence를 확률론의 notation으로 쓰면, random variable $I$가
$p_i$의 확률분포를 가질 때,
\(\DKL{p}{q} = \expectwith{I}{\log\left(\frac{p_i}{q_i}\right)}\) 이렇게
expectation으로 쓸 수도 있다.&lt;/p&gt;

&lt;p&gt;Symmetrized version $(\DKL{p}{q} + \DKL{q}{p}) / 2$ 같은 것을 생각하면?&lt;br /&gt;
$\Rightarrow$ Jensen-Shannon Divergence라고 부르는데, 그래도 여전히
infinity라는 문제가 남아서 메트릭이 되지는 않는다.&lt;/p&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="deep-learning-study" /><summary type="html">Contents Shallow Neural Network : Introduction KL-Divergence 심층 신경망의 수학적 기초 3강 (9월 9일), 4강 (9월 14일) 에 기반합니다. 이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다. Shallow Neural Network : Introduction 데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨 $Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이때, 어떤 True Unknown Function $f_\star : \mathcal{X} \to \mathcal{Y}$ 가 있다고 생각하면, $Y_i = f_\star(X_i)$ 를 만족한다. 우리는, $X_i, Y_i$로부터, $f_\star$과 가까운 어떤 함수 $f$를 찾아내는 작업을 수행하고 싶다. $X_i$들에 대해 $Y_i$는 사람이 수집한 데이터를 쓰기 때문에, 이를 Supervised Learning이라고 부른다. 뭔가를 시작하기 전에, 일단 $f_\star$과 가까운 $f$가 도대체 무슨 말인지를 명확히 해야 한다. 뭔가를 최소화하는 문제로 만들고 싶은데... 가장 자명한 방법으로 생각하면 어떤 손실함수 $\ell$을 도입해서, 이렇게 쓰고 싶다. \(\underset{f \in \mathcal{F}}{\minimize}\ \sup_{x \in \mathcal{X}} \ell(f(x), f_\star(x))\) 이 문제는, (1) 모든 가능한 함수들의 공간 위에서 뭔가를 최적화한다는 것은 알고리즘적으로 말이 안 되고, (2) 이 최적화 문제의 해는 $f_\star$이니까, 사실 최적화 문제도 딱히 아니다. 모든 $x$에 대해 $f_\star$를 알고 있으면 최적화를 생각할 이유가 없다. 대신에, 함수들의 공간을 제약하자. 어떤 파라미터 $\theta$를 이용하여, 우리는 다음과 같은 최적화 문제로 바꾸고 싶다. \(\underset{\theta \in \Theta}{\minimize}\ \sup_{x \in \mathcal{X}} \ell(f_\theta(x), f_\star(x))\) 여전히, 일단 우리는 모든 $x$에 대해 $f_\star$를 알고 있지 않다. 우리가 알고 있는 $x_1, x_2, \dots$ 에 대한 답 $y_1, y_2 \dots$ 들을 맞춰낼 수 있는 함수를 일단 만드는 정도가 최선이 아닐까? 그리고, 최악의 경우를 최소화하는 대신, 평균을 최적화하는게 뭔가 ‘일반적으로’ 좋은 솔루션을 제공할 것 같다. supremum을 최소화한다는 것은 너무 지나친 목표이다. \(\underset{\theta \in \Theta}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_\theta(x_i), f_\star(x_i))\) 우리는 $f_\star(x_i) = y_i$ 임을 알고 있으므로, 이제 뭔가가 가능하다. 이제, $\theta$를 이용하여 표현되는 $f_\theta$를 model 또는 neural network라고 부를 것이다. 또한, 이 최적화 문제를 푸는 작업을 training 이라고 부를 것이다. 즉, 파라미터를 이용해서 표현한 모델 $f_\theta$를 SGD와 같은 알고리즘을 이용하여 training한다는 표현이 된다. 현재 거의 모든 방법들이 SGD에 기반하고 있다. Example : Least square regression $\mathcal{X} = \R^p, \mathcal{Y} = \R, \Theta = \R^p$이고, 모델 $f_\theta(x) = x^T \theta$, $L(y_1, y_2) = \frac{1}{2}(y_1 - y_2)^2$ 인 문제를 Least square라고 부른다. 즉, 주어진 데이터들을 비슷하게 맞춰내는 Linear한 함수를 찍는 것. KL-Divergence As a mathematical tool, 어떤 $p, q \in \R^n$이 probability mass vector일 때, 즉 $p_i, q_i \geq 0$ 이고 $\sum p_i = \sum q_i = 1$일 때, 우리는 두 distribution의 차이를 생각하고 싶다. Kullback-Leibler Divergence (KL-Divergence)를 다음과 같이 정의한다. \(\DKL{p}{q} = \sum_{i = 1}^{n} p_i \log\frac{p_i}{q_i} = -\sum_{i = 1}^{n} p_i \log q_i + \sum_{i = 1}^{n} p_i \log p_i\) 이는 다시, 정보이론의 용어로는 Cross entropy $H(p, q)$ 와 Entropy $H(p)$의 합으로 쓰여진다. 편의를 위해 (자연스럽게), $0 \log (0 / 0) = 0$ 으로, $0 \log 0 = 0$ 으로, $x &amp;gt; 0$이면 $x \log (x / 0) = \infty$ 으로 둔다. 몇가지 성질들을 살펴보면... $\DKL{p}{q}$ 는 일반적으로 $\DKL{q}{p}$ 와 같지 않다. (그래서 metric은 아님) $\DKL{p}{q} \geq 0$ 이고, $p \neq q$ 이면 $\DKL{p}{q} &amp;gt; 0$ (과제) $\DKL{p}{q} = \infty$ 인 경우도 가능. KL-Divergence를 확률론의 notation으로 쓰면, random variable $I$가 $p_i$의 확률분포를 가질 때, \(\DKL{p}{q} = \expectwith{I}{\log\left(\frac{p_i}{q_i}\right)}\) 이렇게 expectation으로 쓸 수도 있다. Symmetrized version $(\DKL{p}{q} + \DKL{q}{p}) / 2$ 같은 것을 생각하면? $\Rightarrow$ Jensen-Shannon Divergence라고 부르는데, 그래도 여전히 infinity라는 문제가 남아서 메트릭이 되지는 않는다.</summary></entry><entry><title type="html">Binary Classification : Support Vector Machine / Logistic Regression</title><link href="http://localhost:4000/deep-learning-study/svm-and-lr/" rel="alternate" type="text/html" title="Binary Classification : Support Vector Machine / Logistic Regression" /><published>2021-09-24T00:00:00+09:00</published><updated>2021-09-24T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/svm-and-lr</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/svm-and-lr/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#binary-classification&quot; id=&quot;markdown-toc-binary-classification&quot;&gt;Binary Classification&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#linear-classification&quot; id=&quot;markdown-toc-linear-classification&quot;&gt;Linear Classification&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#support-vector-machine&quot; id=&quot;markdown-toc-support-vector-machine&quot;&gt;Support Vector Machine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#logistic-regression&quot; id=&quot;markdown-toc-logistic-regression&quot;&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 3강 (9월 9일), 4강 (9월 14일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;binary-classification&quot;&gt;Binary Classification&lt;/h2&gt;

&lt;p&gt;잠시 앞서의 정의를 돌아보자.&lt;/p&gt;

&lt;p&gt;데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨
$Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이때, 어떤
&lt;strong&gt;True Unknown Function&lt;/strong&gt; $f_\star : \mathcal{X} \to \mathcal{Y}$ 가
있다고 생각하면, $Y_i = f_\star(X_i)$ 를 만족한다.&lt;/p&gt;

&lt;p&gt;우리는, $X_i, Y_i$로부터, $f_\star$과 가까운 어떤 함수 $f$를 찾아내는
작업을 수행하고 싶다. $X_i$들에 대해 $Y_i$는 사람이 수집한 데이터를 쓰기
때문에, 이를 &lt;strong&gt;Supervised Learning&lt;/strong&gt;이라고 부른다.&lt;/p&gt;

&lt;p&gt;Supervised Learning을 위해, 우리는 다음과 같은 최적화 문제를 생각할 것이다.
\(\underset{\theta \in \Theta}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_\theta(x_i), f_\star(x_i))\)&lt;/p&gt;

&lt;p&gt;특히, 이번에는 $\mathcal{X} = \R^p$, $\mathcal{Y} = \Set{-1, +1}$ 인 문제를 생각하자.
즉, 데이터를 두 클래스로 분리해내는 것이다. 이때, 특별히 이 데이터가
&lt;strong&gt;linearly seperable&lt;/strong&gt;한지를 생각한다. 어떤 초평면 $a^T x + b$ 가
존재하여, $y$값을 $a^T x + b$의 부호에 따라 찍어낼 수 있으면 linearly
seperable하다고 정의한다.&lt;/p&gt;

&lt;h2 id=&quot;linear-classification&quot;&gt;Linear Classification&lt;/h2&gt;

&lt;p&gt;Binary classifcation, 특히 linear classifcation 문제를 해결하기 위해
다음과 같은 affine model을 생각한다. \(f_{a, b}(x) = \sgn(a^T x + b)\)
여기에 loss function으로, 틀린 라벨의 개수를 세는 것이 매우 자연스럽다.
이렇게 컴팩트하게 쓸 수 있다.
\(\ell(y_1, y_2) = \frac{1}{2}\abs{1 - y_1 y_2}\)&lt;/p&gt;

&lt;p&gt;이제, 다음의 최적화 문제를 풀고 싶다.
\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_{a, b}(x_i), y_i)\)
그러면 Linearly seperable한지는 이 최적화 문제의 최적해가 0인지와
동치이다. 그런데, 이 함수는 연속함수가 아니기 때문에 (정확히는 대충
미분가능하다는 조건을 요구한다) SGD같은 알고리즘을 돌릴수가 없다.&lt;/p&gt;

&lt;h2 id=&quot;support-vector-machine&quot;&gt;Support Vector Machine&lt;/h2&gt;

&lt;p&gt;따라서, 이 문제를 continuous하게 relaxation하고자 한다. 관점을 바꾸면,
이 라벨이 1일 / -1일 ‘Confidence’를 반환하도록 모델을 좀 잘 확장하고자
한다. 0.5이면 ‘아마도 1일 것으로 보인다’ 같은 느낌으로.&lt;/p&gt;

&lt;p&gt;이를 위해서는 $y_i f_{a, b}(x_i) &amp;gt; 0$ 을 만족해야 한다.&lt;/p&gt;

&lt;p&gt;그런데, 실제로는 이렇게 하면 $f$값이 0 근처에서만 왔다갔다하는 문제가 있고, 이는 numerical한 면에서나 neural network의 confidence라는 해석으로나 적절하지 않으므로 적당히
margin을 주는 것이 바람직하다.&lt;/p&gt;

&lt;p&gt;적당히 margin을 1만큼 줘서, $y_i f_{a, b}(x_i) \geq 1$ 을 만족하면
좋을 것 같다. 여기서 ‘좋을 것 같다’ 는 말은 반대로 저 성질을 만족하지
않으면 페널티를 부과하겠다는 발상으로도 해석될 수 있고… 이 페널티 함수를 최소화하는 문제로 쓰면,
\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i f_{a, b}(x_i)) = \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i (a^T x_i + b))\)&lt;/p&gt;

&lt;p&gt;데이터가 linearly seperable하면, 이 식도 optimal value가 0임을 알 수
있다. 이 방법을 &lt;strong&gt;Support Vector Machine&lt;/strong&gt; 이라고 부르며, 흔히
regularizer를 추가한 아래 식으로
쓴다.\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i (a^T x_i + b)) + \frac{\lambda}{2}\norm{a}^2\)&lt;/p&gt;

&lt;p&gt;이 최적화 문제 (Relaxation 넣기 전!)가 원본 문제의 relaxation이라는
사실을 보이는 것은 어렵지 않다. 원래 문제의 최적해를 $p_1^\star$ 라 하고,
SVM의 최적해를 $p_2^\star$ 라 하면, $p_1^\star = 0 \iff p_2^\star = 0$ 임을 알 수
있다.&lt;/p&gt;

&lt;p&gt;결국, relaxed supervised learning은 point prediction을 relaxation 해서
label value 대신 그 label의 probability를 예측하는 방향으로 생각하는 것.
Single prediction보다 훨씬 realistic한 세팅으로 생각할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h2&gt;

&lt;p&gt;Linear binary classification에 대한 또다른 방법. 여전히 Decision
boundary $a^T x + b$ 를 알고자 한다. 먼저...&lt;/p&gt;

&lt;p&gt;Binary classification에서, 우리가 확인한 데이터의 Label을 확률벡터로
만들어서 (만약 완전히 label이 하나라면, (1, 0) 과 (0, 1) 처럼) 표현한
것을 empirical distribution $\mathcal{P}(y)$ 라고 정의하기로 한다.&lt;/p&gt;

&lt;p&gt;다음과 같은 모델을 이용하여 최적화하는 supervised learning을 Logistic
Regression이라 한다. \(f_{a, b}(x) = \begin{bmatrix}
    \frac{1}{1 + e^{a^T x + b}} \\
    \frac{1}{1 + e^{-(a^Tx + b)}}
\end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;이 모델을 이용하여, 다음과 같은 최적화 문제를 해결하고자 한다.
\(\underset{a \in \R^p, b \in \R}{\minimize}\ \DKL{\mathcal{P}(Y_i)}{f_{a, b}(X_i)}\)
즉, 우리는 empirical distribution과의 KL-Divergence를 최소화하고 싶다.
이 식을 정리하면...
\(\underset{a \in \R^p, b \in \R}{\minimize}\ H(\mathcal{P}(Y), f_{a, b}(X)) + \text{ Terms independent of } a, b\)
정확히 Cross entropy $H$를 전개하고, 오른쪽 term들을 다 버리면...
\(\underset{a \in \R^p, b \in \R}{\minimize}\ - \frac{1}{N}\sum_{i = 1}^{N} \P(y_i = -1) \log\left(\frac{1}{1 + e^{a^Tx_i + b}}\right) + \P(y_i = 1)\log\left(\frac{1}{1 + e^{-a^Tx_i - b}}\right)\)
이는 다시, $\P(y_i = 1)$ 과 $\P(y_i = -1)$ 이 one-hot이므로, 둘중에
어느쪽이 1인지를 깔끔하게 정리하여,
\(\underset{a \in \R^p, b \in \R}{\minimize}\ - \frac{1}{N}\sum_{i = 1}^{N} \log\left(\frac{1}{1 + e^{-y_i(a^Tx_i + b)}}\right)\)
단조감소함수인 Loss function $\ell(z) = \log(1 + e^{-z})$를 도입하여
부호를 떼고 깔끔하게 정리할 수 있다.
\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N}\ell(y_i(a^T x_i + b))\)
이 문제를 해결한 후, $a^T x + b$ 의 부호에 따라 prediction한다.&lt;/p&gt;

&lt;p&gt;SVM과 비교하면, 출발점이 달랐지만 결국은 같은 문제가 되는데, $\ell(z)$
를 어떻게 정의하느냐의 문제가 된다. SVM은 $\max(0, 1-z)$이고, Logistic
regression은 $\log(1 + e^{-z})$ 를 쓰는 경우로 생각할 수 있다. 좌표에
그려보면 두 함수가 사실 굉장히 비슷하게 생겼다.&lt;/p&gt;

&lt;p&gt;SVM과 LR은 둘다 (Decision boundary가 hyperplane이라는 관점에서) Linear
classifier이지만, LR이 좀더 자연스럽게 multiclass classification으로
확장된다&lt;/p&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="deep-learning-study" /><summary type="html">Contents Binary Classification Linear Classification Support Vector Machine Logistic Regression 심층 신경망의 수학적 기초 3강 (9월 9일), 4강 (9월 14일) 에 기반합니다. 이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다. Binary Classification 잠시 앞서의 정의를 돌아보자. 데이터 $X_1, \dots X_n \in \mathcal{X}$이 있고, 이에 대한 정답 라벨 $Y_1, \dots Y_n \in \mathcal{Y}$이 주어진 경우를 생각해 보자. 이때, 어떤 True Unknown Function $f_\star : \mathcal{X} \to \mathcal{Y}$ 가 있다고 생각하면, $Y_i = f_\star(X_i)$ 를 만족한다. 우리는, $X_i, Y_i$로부터, $f_\star$과 가까운 어떤 함수 $f$를 찾아내는 작업을 수행하고 싶다. $X_i$들에 대해 $Y_i$는 사람이 수집한 데이터를 쓰기 때문에, 이를 Supervised Learning이라고 부른다. Supervised Learning을 위해, 우리는 다음과 같은 최적화 문제를 생각할 것이다. \(\underset{\theta \in \Theta}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_\theta(x_i), f_\star(x_i))\) 특히, 이번에는 $\mathcal{X} = \R^p$, $\mathcal{Y} = \Set{-1, +1}$ 인 문제를 생각하자. 즉, 데이터를 두 클래스로 분리해내는 것이다. 이때, 특별히 이 데이터가 linearly seperable한지를 생각한다. 어떤 초평면 $a^T x + b$ 가 존재하여, $y$값을 $a^T x + b$의 부호에 따라 찍어낼 수 있으면 linearly seperable하다고 정의한다. Linear Classification Binary classifcation, 특히 linear classifcation 문제를 해결하기 위해 다음과 같은 affine model을 생각한다. \(f_{a, b}(x) = \sgn(a^T x + b)\) 여기에 loss function으로, 틀린 라벨의 개수를 세는 것이 매우 자연스럽다. 이렇게 컴팩트하게 쓸 수 있다. \(\ell(y_1, y_2) = \frac{1}{2}\abs{1 - y_1 y_2}\) 이제, 다음의 최적화 문제를 풀고 싶다. \(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \ell(f_{a, b}(x_i), y_i)\) 그러면 Linearly seperable한지는 이 최적화 문제의 최적해가 0인지와 동치이다. 그런데, 이 함수는 연속함수가 아니기 때문에 (정확히는 대충 미분가능하다는 조건을 요구한다) SGD같은 알고리즘을 돌릴수가 없다. Support Vector Machine 따라서, 이 문제를 continuous하게 relaxation하고자 한다. 관점을 바꾸면, 이 라벨이 1일 / -1일 ‘Confidence’를 반환하도록 모델을 좀 잘 확장하고자 한다. 0.5이면 ‘아마도 1일 것으로 보인다’ 같은 느낌으로. 이를 위해서는 $y_i f_{a, b}(x_i) &amp;gt; 0$ 을 만족해야 한다. 그런데, 실제로는 이렇게 하면 $f$값이 0 근처에서만 왔다갔다하는 문제가 있고, 이는 numerical한 면에서나 neural network의 confidence라는 해석으로나 적절하지 않으므로 적당히 margin을 주는 것이 바람직하다. 적당히 margin을 1만큼 줘서, $y_i f_{a, b}(x_i) \geq 1$ 을 만족하면 좋을 것 같다. 여기서 ‘좋을 것 같다’ 는 말은 반대로 저 성질을 만족하지 않으면 페널티를 부과하겠다는 발상으로도 해석될 수 있고… 이 페널티 함수를 최소화하는 문제로 쓰면, \(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i f_{a, b}(x_i)) = \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i (a^T x_i + b))\) 데이터가 linearly seperable하면, 이 식도 optimal value가 0임을 알 수 있다. 이 방법을 Support Vector Machine 이라고 부르며, 흔히 regularizer를 추가한 아래 식으로 쓴다.\(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N} \max(0, 1 - y_i (a^T x_i + b)) + \frac{\lambda}{2}\norm{a}^2\) 이 최적화 문제 (Relaxation 넣기 전!)가 원본 문제의 relaxation이라는 사실을 보이는 것은 어렵지 않다. 원래 문제의 최적해를 $p_1^\star$ 라 하고, SVM의 최적해를 $p_2^\star$ 라 하면, $p_1^\star = 0 \iff p_2^\star = 0$ 임을 알 수 있다. 결국, relaxed supervised learning은 point prediction을 relaxation 해서 label value 대신 그 label의 probability를 예측하는 방향으로 생각하는 것. Single prediction보다 훨씬 realistic한 세팅으로 생각할 수 있다. Logistic Regression Linear binary classification에 대한 또다른 방법. 여전히 Decision boundary $a^T x + b$ 를 알고자 한다. 먼저... Binary classification에서, 우리가 확인한 데이터의 Label을 확률벡터로 만들어서 (만약 완전히 label이 하나라면, (1, 0) 과 (0, 1) 처럼) 표현한 것을 empirical distribution $\mathcal{P}(y)$ 라고 정의하기로 한다. 다음과 같은 모델을 이용하여 최적화하는 supervised learning을 Logistic Regression이라 한다. \(f_{a, b}(x) = \begin{bmatrix} \frac{1}{1 + e^{a^T x + b}} \\ \frac{1}{1 + e^{-(a^Tx + b)}} \end{bmatrix}\) 이 모델을 이용하여, 다음과 같은 최적화 문제를 해결하고자 한다. \(\underset{a \in \R^p, b \in \R}{\minimize}\ \DKL{\mathcal{P}(Y_i)}{f_{a, b}(X_i)}\) 즉, 우리는 empirical distribution과의 KL-Divergence를 최소화하고 싶다. 이 식을 정리하면... \(\underset{a \in \R^p, b \in \R}{\minimize}\ H(\mathcal{P}(Y), f_{a, b}(X)) + \text{ Terms independent of } a, b\) 정확히 Cross entropy $H$를 전개하고, 오른쪽 term들을 다 버리면... \(\underset{a \in \R^p, b \in \R}{\minimize}\ - \frac{1}{N}\sum_{i = 1}^{N} \P(y_i = -1) \log\left(\frac{1}{1 + e^{a^Tx_i + b}}\right) + \P(y_i = 1)\log\left(\frac{1}{1 + e^{-a^Tx_i - b}}\right)\) 이는 다시, $\P(y_i = 1)$ 과 $\P(y_i = -1)$ 이 one-hot이므로, 둘중에 어느쪽이 1인지를 깔끔하게 정리하여, \(\underset{a \in \R^p, b \in \R}{\minimize}\ - \frac{1}{N}\sum_{i = 1}^{N} \log\left(\frac{1}{1 + e^{-y_i(a^Tx_i + b)}}\right)\) 단조감소함수인 Loss function $\ell(z) = \log(1 + e^{-z})$를 도입하여 부호를 떼고 깔끔하게 정리할 수 있다. \(\underset{a \in \R^p, b \in \R}{\minimize}\ \frac{1}{N}\sum_{i = 1}^{N}\ell(y_i(a^T x_i + b))\) 이 문제를 해결한 후, $a^T x + b$ 의 부호에 따라 prediction한다. SVM과 비교하면, 출발점이 달랐지만 결국은 같은 문제가 되는데, $\ell(z)$ 를 어떻게 정의하느냐의 문제가 된다. SVM은 $\max(0, 1-z)$이고, Logistic regression은 $\log(1 + e^{-z})$ 를 쓰는 경우로 생각할 수 있다. 좌표에 그려보면 두 함수가 사실 굉장히 비슷하게 생겼다. SVM과 LR은 둘다 (Decision boundary가 hyperplane이라는 관점에서) Linear classifier이지만, LR이 좀더 자연스럽게 multiclass classification으로 확장된다</summary></entry><entry><title type="html">서울대학교 프로그래밍 대회 (SNUPC) 2021 후기 / 풀이(A-G) &amp;amp; Whining</title><link href="http://localhost:4000/cp-rounds/snupc-2021/" rel="alternate" type="text/html" title="서울대학교 프로그래밍 대회 (SNUPC) 2021 후기 / 풀이(A-G) &amp;amp; Whining" /><published>2021-09-12T00:00:00+09:00</published><updated>2021-09-12T00:00:00+09:00</updated><id>http://localhost:4000/cp-rounds/snupc-2021</id><content type="html" xml:base="http://localhost:4000/cp-rounds/snupc-2021/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#snupc&quot; id=&quot;markdown-toc-snupc&quot;&gt;SNUPC&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#phase-1--easy-problems-0분---60분&quot; id=&quot;markdown-toc-phase-1--easy-problems-0분---60분&quot;&gt;Phase 1 : Easy problems (0분 - 60분)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#a-b&quot; id=&quot;markdown-toc-a-b&quot;&gt;A, B&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#g--자연수-색칠하기&quot; id=&quot;markdown-toc-g--자연수-색칠하기&quot;&gt;G : 자연수 색칠하기&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#f--and와-or&quot; id=&quot;markdown-toc-f--and와-or&quot;&gt;F : AND와 OR&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#phase-2--spurt-60분---120분&quot; id=&quot;markdown-toc-phase-2--spurt-60분---120분&quot;&gt;Phase 2 : Spurt (60분 - 120분)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#e--뛰는-기물&quot; id=&quot;markdown-toc-e--뛰는-기물&quot;&gt;E : 뛰는 기물&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#c--실-전화기&quot; id=&quot;markdown-toc-c--실-전화기&quot;&gt;C : 실 전화기&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#d--누텔라-트리&quot; id=&quot;markdown-toc-d--누텔라-트리&quot;&gt;D : 누텔라 트리&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#phase-3--too-hard&quot; id=&quot;markdown-toc-phase-3--too-hard&quot;&gt;Phase 3 : Too hard&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#대회가-끝나고&quot; id=&quot;markdown-toc-대회가-끝나고&quot;&gt;대회가 끝나고&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;9월 11일 (토)에 진행된 서울대학교 프로그래밍 경시대회 (SNUPC) 2021 Division 2에 참가해 6등 했습니다.&lt;/p&gt;

&lt;h2 id=&quot;snupc&quot;&gt;SNUPC&lt;/h2&gt;
&lt;p&gt;SNUPC는 한국에서 열리는 프로그래밍 대회 중 개인 대회로는 아마 가장 높은 난이도를 자랑하는 대회가 아닌가 싶습니다. Division 1과 2로 나누어 수행되는데, 기억에는 Division 1의 참가자 상당수가 ACM-ICPC World Final 참가자들 급의 실력을 가진 (실제 WF 무대를 경험한 사람들도 10명은 있을 겁니다) 것으로 기억합니다. 제가 참가한 Division 2는 (공식적으로는) 퍼플 이하의 참가자들을 위한 대회이기 때문에 난이도가 훨씬 덜하지만, 다른 대학 대회들과 비교하면 오히려 정상적인 수준입니다.&lt;/p&gt;

&lt;p&gt;저는 2019년에 Div2 9등 (3등상), 2020년에 7등 (3등상), 올해 6등 (3등상) 의 성적을 얻었습니다. 제 실력은 분명 조금씩 발전하고 있지만, 대회가 점점 더 고여가기 때문에 제가 내년에도 Div2 우승을 노리는 것보다는 아마 Div1에 나가지 않을까 싶습니다. SNUPC는 대학원생들도 꽤 많이 나오고, 저한테는 앞으로도 당분간은 좋은 취미일 (?) PS를 즐길수있게 해주는 좋은 대회이기 때문에 석사과정 정도까지는 토요일 하루 빼서 나와볼만 하다고 생각합니다.&lt;/p&gt;

&lt;h2 id=&quot;phase-1--easy-problems-0분---60분&quot;&gt;Phase 1 : Easy problems (0분 - 60분)&lt;/h2&gt;
&lt;h3 id=&quot;a-b&quot;&gt;A, B&lt;/h3&gt;
&lt;p&gt;A, B 두 문제는 워낙 쉬운 문제라서 딱히 commentate할 부분은 없습니다.&lt;/p&gt;

&lt;p&gt;B 퍼솔을 먹어서 기분이 좀 좋았습니다. :)&lt;/p&gt;

&lt;p&gt;C를 조금 손대 보았고, 실제로 맞는 관찰을 헀지만, 구현에서 실수가 조금 있어서 AC를 받지 못했습니다. 스코어보드를 보고 의외로 G가 쉬운 문제라고 판단하여 G로 갔습니다.&lt;/p&gt;

&lt;h3 id=&quot;g--자연수-색칠하기&quot;&gt;G : 자연수 색칠하기&lt;/h3&gt;
&lt;p&gt;서로소인 두 색을 서로 다른 색으로 색칠해야 한다는 조건이 있는데, 이 조건의 충분조건으로 다음과 같은 색칠을 생각합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;소수는 모두 서로소이므로, 소수끼리는 서로 다른 색으로 칠합니다.&lt;/li&gt;
  &lt;li&gt;소수가 아닌 수는, 무조건 가장 큰 소인수에 해당하는 색으로 칠합니다. 
이렇게 칠하면, $\pi(n) + 1$ 개의 색을 쓰게 됩니다 (1은 따로 칠해야 하므로) 소수는 모두 서로 다른 색으로 칠해야 하므로 이보다 적게 색깔을 쓰는 방법은 없습니다. 또한, 두번째 조건에 의해 서로소인 수는 소인수를 공유하지 않으므로 다른 색으로 칠하게 되어, 이 칠하는 방법이 올바릅니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;f--and와-or&quot;&gt;F : AND와 OR&lt;/h3&gt;
&lt;p&gt;두 수 $a, b$를 두 수 $c, d$로 바꾸되, 이때 $a, b$와 $c, d$는 각각 AND한 값과 OR한 값이 같아야 합니다. $N$개의 수가 주어지고, 이 수들에 대해 이 연산을 원하는 만큼 수행한 후, 곱을 최소화하는 문제입니다.&lt;br /&gt;
생각해 보면, 두 수에 모두 켜져 있는 비트는 c, d 에서도 켜져 있어야 하고, 한쪽에만 켜져 있는 비트는 한쪽에만 켜져 있어야 하고… 해서 각 비트 단위로 조건을 생각하면 $a + b = c + d$ 여야 한다는 것을 알 수 있습니다 (충분조건은 아닙니다)&lt;/p&gt;

&lt;p&gt;따라서, $N$개의 수에 대해 그 합을 바꿀 방법은 없습니다. 합을 유지하면서 곱을 최소화하는 방법은 최대한 큰 수와 최대한 작은 수로 수의 크기 갭을 벌리는 것입니다. 이를 위해, 모든 수를 OR하여 하나를 만들고, 앞으로 그 수는 건드리지 않는 방법으로 모든 수에 켜진 bit의 union에 해당하는 수를 하나 만들어서 앞으로의 연산에서 제외하는 식으로 진행하면 됩니다.&lt;/p&gt;

&lt;p&gt;이 구현은 $O(N^2)$ 이기 때문에, 더 줄여야 합니다. 특정 비트 $k$번을 생각하고, $k$번 비트가 $N$개의 수를 통틀어 몇 번 켜지는지 확인하여 구현하면 $O(30 N)$ 에 해결할 수 있습니다.&lt;/p&gt;

&lt;p&gt;이문제까지 해결한 다음, 다시 스코어보드를 확인했는데 CDEFG가 풀린 숫자가 거기서 거기인 신기한 스코어보드를 보고 좀 당황했습니다.&lt;/p&gt;
&lt;h2 id=&quot;phase-2--spurt-60분---120분&quot;&gt;Phase 2 : Spurt (60분 - 120분)&lt;/h2&gt;
&lt;h3 id=&quot;e--뛰는-기물&quot;&gt;E : 뛰는 기물&lt;/h3&gt;
&lt;p&gt;가로와 세로로 나이트처럼 움직이되, $(m, n)$칸 움직일 수 있는 (또는 $(n, m), (-n, m)$ 등) $(m, n)$-나이트를 정의합니다. 무한한 정수 격자점 $\Z^2$를 무한히 많은 나이트 move로 커버하기 위해, 최소 몇 개의 시작점 (몇 마리의 나이트) 가 필요한지에 대한 문제입니다.&lt;/p&gt;

&lt;p&gt;어렵지 않은 관찰로 시작합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$\gcd(m, n) = g &amp;gt; 1$ 이면, 전체 보드를 $g * g$ 칸 정사각형으로 분할했을 때, 같은 정사각형 안에서는 움직일 방법이 없습니다. 즉, 적어도 $g^2$ 개는 필요합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서, $m, n$이 서로소인 경우만 해결하면 됩니다.&lt;br /&gt;
여기서 추가로, $(1, 1)$ 나이트 같은 경우, $x + y$ 좌표의 홀짝성을 바꿀 수 있는 방법이 없습니다. 이는 $(3, 3)$나이트나, $(3, 5)$ 등 다른 (홀수, 홀수) 나이트도 가지고 있는 문제입니다. 이유는 $x + y$, $x - y$ 가 모두 짝수이기 때문입니다. 이를 해결하기 위해 적어도 2마리가 필요할 것입니다.&lt;/p&gt;

&lt;p&gt;그렇지 않고, $(2, 3)$ 나이트같은 경우 이 나이트가 모든 칸을 방문할 수 있음을 주장합니다. 이 증명을 엄밀하게 하는 것은 상당히 귀찮은 일이며, 풀이 슬라이드에 잘 나와 있습니다. ㅋㅋ! 저는 엄밀한 증명까지는 하지 않고, 그림을 몇개 그려 보고 대충 지그재그로 잘 움직이다가 밑으로 훅 내려오는 것을 반복하면 $(1, 0)$에 도달할 수 있다고 믿었습니다.&lt;/p&gt;

&lt;p&gt;간단히 아이디어만 소개하자면, $(m, n)$ 나이트에서 일반성을 잃지 않고 $n &amp;gt; m$ 이라고 하겠습니다. 이때 $n &amp;gt; 2m$ 인 경우, $n &amp;lt; 2m$ 인 경우를 나누어, 나이트로 잘 움직여서 $(m, n)$ 나이트가 다른 어떤 $(a, b)$ 나이트의 행동을 모두 할 수 있음을 보이고, (이때 a, b를 n, m보다 작게 줄이면서) base case로 $(1, 2)$ 나이트가 $(1, 0)$에 도달 가능함을 이용합니다.&lt;/p&gt;

&lt;p&gt;참고로, 체스를 좋아한다면 $(1, 2)$ 나이트로 엔드게임 시점에 바로 옆 칸에 가기 위해 3번의 움직임을 쓰는 상황을 calculate해본 경험이 많을 것입니다. 저는 그래서 조금 재밌었습니다. (비슷한 이치로 장기를 잘 두는 사람은 $(2, 3)$ 나이트도 추가로 머릿속에서 그려지는듯 합니다.)&lt;/p&gt;

&lt;p&gt;별개로 저는 이 문제에서 사소한 실수로 4틀했습니다. :( 페널티 싸움에서 패배해서 등수가 낮아진 매우 중요한 원인이 되었습니다.&lt;/p&gt;

&lt;h3 id=&quot;c--실-전화기&quot;&gt;C : 실 전화기&lt;/h3&gt;
&lt;p&gt;정오각형으로 노드가 배치된 그래프를 평면에 임베딩하기 위해, 노드를 최소 몇개 움직여야 하는지 찾는 문제.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;완전그래프 $K_5$는 평면 임베딩이 불가능함이 알려져 있으며, 예제로 주어져 있습니다.&lt;/li&gt;
  &lt;li&gt;여기서 edge를 하나 빼면 평면에 올릴 수 있고, 최대 2개만 움직이면 됩니다.&lt;/li&gt;
  &lt;li&gt;노드를 1개 움직여서 가능한지 아닌지만 판정하면 되고,&lt;/li&gt;
  &lt;li&gt;노드 한개를 충분히 멀리 움직이는 것이 없애는 것과 같은 효과이므로, 하나를 없애서 나머지가 충돌하지 않는지 확인하면 됩니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;d--누텔라-트리&quot;&gt;D : 누텔라 트리&lt;/h3&gt;
&lt;p&gt;트리에 검정색과 빨간색으로 칠해진 정점들이 있는데, 여기서 검정색에서 출발하여 빨간색들만 밟는 ‘누텔라 경로’ 가 몇 개 있는지 세는 문제입니다.&lt;/p&gt;

&lt;p&gt;빨간색에 한번 도달하면, 연결된 빨간색들 중 어디에 멈출지만 정하면 되기 때문에, 그 component에서 가능한 경우의 수는 빨간색의 개수입니다. 
이를 DSU로 미리 묶어서 처리하면 쉽게 해결 가능합니다.&lt;/p&gt;

&lt;h2 id=&quot;phase-3--too-hard&quot;&gt;Phase 3 : Too hard&lt;/h2&gt;

&lt;p&gt;7문제를 푼 순간, 제가 참가자들 중 가장 먼저 7솔브에 도달했기 떄문에 이거 Div2 우승하는거 아니냐 ㅋㅋ 라고 생각하며 잠깐 설렜습니다. 그런데 생각해보면 CDEFG의 난이도가 비슷해서 생긴 일이므로, 지금 (120분 시점) 6솔인 사람들은 시간이 주어진다면 충분히 7솔브가 가능하고, 저는 E번을 4틀하면서 페널티에서 엄청 밀렸으므로 8솔브를 해야 우승을 노릴 수 있었습니다 (그렇지 않더라도 사실 이 상황에서 저한테 달라질건 없지만요). H와 I 중 무엇을 풀지 고민하다가, H가 인터랙티브라서 I를 풀고자 시도했는데 I번에서도 뭔가 어려움이 많았습니다. $N \sqrt{N}$ 정도까지는 어떻게 잘 우기면 될거 같은데, $N = 2e6$이라서 루트도 허용하지 않는 처참한 시간제한을 보고 다시 H로 도망쳤지만 답이 없었습니다.&lt;/p&gt;

&lt;h2 id=&quot;대회가-끝나고&quot;&gt;대회가 끝나고&lt;/h2&gt;
&lt;p&gt;매년 SNUPC는 정말 많은 생각이 들게 합니다. 매년 뛰어난 사람들이 몰려오고 있고, 나는 정체된 것이 아닌가 하는 회의감부터, 그럼에도 불구하고 하나씩 풀어나갈 때 나름의 즐거움과 생각하는 과정의 즐거움은 PS를 그만둘 수 없게 하기도 합니다.&lt;/p&gt;

&lt;p&gt;내년에는 Div1에 나가보고 싶지만, 어떻게 될지는 모르겠습니다. 내년에 학교에 있을지도 불분명한 상황이라… 이번 H번을 보고, CP 대회에 대한 의욕을 갑자기 훅 잃은 것도 있습니다.&lt;/p&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="cp-rounds" /><summary type="html">Contents SNUPC Phase 1 : Easy problems (0분 - 60분) A, B G : 자연수 색칠하기 F : AND와 OR Phase 2 : Spurt (60분 - 120분) E : 뛰는 기물 C : 실 전화기 D : 누텔라 트리 Phase 3 : Too hard 대회가 끝나고 9월 11일 (토)에 진행된 서울대학교 프로그래밍 경시대회 (SNUPC) 2021 Division 2에 참가해 6등 했습니다. SNUPC SNUPC는 한국에서 열리는 프로그래밍 대회 중 개인 대회로는 아마 가장 높은 난이도를 자랑하는 대회가 아닌가 싶습니다. Division 1과 2로 나누어 수행되는데, 기억에는 Division 1의 참가자 상당수가 ACM-ICPC World Final 참가자들 급의 실력을 가진 (실제 WF 무대를 경험한 사람들도 10명은 있을 겁니다) 것으로 기억합니다. 제가 참가한 Division 2는 (공식적으로는) 퍼플 이하의 참가자들을 위한 대회이기 때문에 난이도가 훨씬 덜하지만, 다른 대학 대회들과 비교하면 오히려 정상적인 수준입니다. 저는 2019년에 Div2 9등 (3등상), 2020년에 7등 (3등상), 올해 6등 (3등상) 의 성적을 얻었습니다. 제 실력은 분명 조금씩 발전하고 있지만, 대회가 점점 더 고여가기 때문에 제가 내년에도 Div2 우승을 노리는 것보다는 아마 Div1에 나가지 않을까 싶습니다. SNUPC는 대학원생들도 꽤 많이 나오고, 저한테는 앞으로도 당분간은 좋은 취미일 (?) PS를 즐길수있게 해주는 좋은 대회이기 때문에 석사과정 정도까지는 토요일 하루 빼서 나와볼만 하다고 생각합니다. Phase 1 : Easy problems (0분 - 60분) A, B A, B 두 문제는 워낙 쉬운 문제라서 딱히 commentate할 부분은 없습니다. B 퍼솔을 먹어서 기분이 좀 좋았습니다. :) C를 조금 손대 보았고, 실제로 맞는 관찰을 헀지만, 구현에서 실수가 조금 있어서 AC를 받지 못했습니다. 스코어보드를 보고 의외로 G가 쉬운 문제라고 판단하여 G로 갔습니다. G : 자연수 색칠하기 서로소인 두 색을 서로 다른 색으로 색칠해야 한다는 조건이 있는데, 이 조건의 충분조건으로 다음과 같은 색칠을 생각합니다. 소수는 모두 서로소이므로, 소수끼리는 서로 다른 색으로 칠합니다. 소수가 아닌 수는, 무조건 가장 큰 소인수에 해당하는 색으로 칠합니다. 이렇게 칠하면, $\pi(n) + 1$ 개의 색을 쓰게 됩니다 (1은 따로 칠해야 하므로) 소수는 모두 서로 다른 색으로 칠해야 하므로 이보다 적게 색깔을 쓰는 방법은 없습니다. 또한, 두번째 조건에 의해 서로소인 수는 소인수를 공유하지 않으므로 다른 색으로 칠하게 되어, 이 칠하는 방법이 올바릅니다. F : AND와 OR 두 수 $a, b$를 두 수 $c, d$로 바꾸되, 이때 $a, b$와 $c, d$는 각각 AND한 값과 OR한 값이 같아야 합니다. $N$개의 수가 주어지고, 이 수들에 대해 이 연산을 원하는 만큼 수행한 후, 곱을 최소화하는 문제입니다. 생각해 보면, 두 수에 모두 켜져 있는 비트는 c, d 에서도 켜져 있어야 하고, 한쪽에만 켜져 있는 비트는 한쪽에만 켜져 있어야 하고… 해서 각 비트 단위로 조건을 생각하면 $a + b = c + d$ 여야 한다는 것을 알 수 있습니다 (충분조건은 아닙니다) 따라서, $N$개의 수에 대해 그 합을 바꿀 방법은 없습니다. 합을 유지하면서 곱을 최소화하는 방법은 최대한 큰 수와 최대한 작은 수로 수의 크기 갭을 벌리는 것입니다. 이를 위해, 모든 수를 OR하여 하나를 만들고, 앞으로 그 수는 건드리지 않는 방법으로 모든 수에 켜진 bit의 union에 해당하는 수를 하나 만들어서 앞으로의 연산에서 제외하는 식으로 진행하면 됩니다. 이 구현은 $O(N^2)$ 이기 때문에, 더 줄여야 합니다. 특정 비트 $k$번을 생각하고, $k$번 비트가 $N$개의 수를 통틀어 몇 번 켜지는지 확인하여 구현하면 $O(30 N)$ 에 해결할 수 있습니다. 이문제까지 해결한 다음, 다시 스코어보드를 확인했는데 CDEFG가 풀린 숫자가 거기서 거기인 신기한 스코어보드를 보고 좀 당황했습니다. Phase 2 : Spurt (60분 - 120분) E : 뛰는 기물 가로와 세로로 나이트처럼 움직이되, $(m, n)$칸 움직일 수 있는 (또는 $(n, m), (-n, m)$ 등) $(m, n)$-나이트를 정의합니다. 무한한 정수 격자점 $\Z^2$를 무한히 많은 나이트 move로 커버하기 위해, 최소 몇 개의 시작점 (몇 마리의 나이트) 가 필요한지에 대한 문제입니다. 어렵지 않은 관찰로 시작합니다. $\gcd(m, n) = g &amp;gt; 1$ 이면, 전체 보드를 $g * g$ 칸 정사각형으로 분할했을 때, 같은 정사각형 안에서는 움직일 방법이 없습니다. 즉, 적어도 $g^2$ 개는 필요합니다. 따라서, $m, n$이 서로소인 경우만 해결하면 됩니다. 여기서 추가로, $(1, 1)$ 나이트 같은 경우, $x + y$ 좌표의 홀짝성을 바꿀 수 있는 방법이 없습니다. 이는 $(3, 3)$나이트나, $(3, 5)$ 등 다른 (홀수, 홀수) 나이트도 가지고 있는 문제입니다. 이유는 $x + y$, $x - y$ 가 모두 짝수이기 때문입니다. 이를 해결하기 위해 적어도 2마리가 필요할 것입니다. 그렇지 않고, $(2, 3)$ 나이트같은 경우 이 나이트가 모든 칸을 방문할 수 있음을 주장합니다. 이 증명을 엄밀하게 하는 것은 상당히 귀찮은 일이며, 풀이 슬라이드에 잘 나와 있습니다. ㅋㅋ! 저는 엄밀한 증명까지는 하지 않고, 그림을 몇개 그려 보고 대충 지그재그로 잘 움직이다가 밑으로 훅 내려오는 것을 반복하면 $(1, 0)$에 도달할 수 있다고 믿었습니다. 간단히 아이디어만 소개하자면, $(m, n)$ 나이트에서 일반성을 잃지 않고 $n &amp;gt; m$ 이라고 하겠습니다. 이때 $n &amp;gt; 2m$ 인 경우, $n &amp;lt; 2m$ 인 경우를 나누어, 나이트로 잘 움직여서 $(m, n)$ 나이트가 다른 어떤 $(a, b)$ 나이트의 행동을 모두 할 수 있음을 보이고, (이때 a, b를 n, m보다 작게 줄이면서) base case로 $(1, 2)$ 나이트가 $(1, 0)$에 도달 가능함을 이용합니다. 참고로, 체스를 좋아한다면 $(1, 2)$ 나이트로 엔드게임 시점에 바로 옆 칸에 가기 위해 3번의 움직임을 쓰는 상황을 calculate해본 경험이 많을 것입니다. 저는 그래서 조금 재밌었습니다. (비슷한 이치로 장기를 잘 두는 사람은 $(2, 3)$ 나이트도 추가로 머릿속에서 그려지는듯 합니다.) 별개로 저는 이 문제에서 사소한 실수로 4틀했습니다. :( 페널티 싸움에서 패배해서 등수가 낮아진 매우 중요한 원인이 되었습니다. C : 실 전화기 정오각형으로 노드가 배치된 그래프를 평면에 임베딩하기 위해, 노드를 최소 몇개 움직여야 하는지 찾는 문제. 완전그래프 $K_5$는 평면 임베딩이 불가능함이 알려져 있으며, 예제로 주어져 있습니다. 여기서 edge를 하나 빼면 평면에 올릴 수 있고, 최대 2개만 움직이면 됩니다. 노드를 1개 움직여서 가능한지 아닌지만 판정하면 되고, 노드 한개를 충분히 멀리 움직이는 것이 없애는 것과 같은 효과이므로, 하나를 없애서 나머지가 충돌하지 않는지 확인하면 됩니다. D : 누텔라 트리 트리에 검정색과 빨간색으로 칠해진 정점들이 있는데, 여기서 검정색에서 출발하여 빨간색들만 밟는 ‘누텔라 경로’ 가 몇 개 있는지 세는 문제입니다. 빨간색에 한번 도달하면, 연결된 빨간색들 중 어디에 멈출지만 정하면 되기 때문에, 그 component에서 가능한 경우의 수는 빨간색의 개수입니다. 이를 DSU로 미리 묶어서 처리하면 쉽게 해결 가능합니다. Phase 3 : Too hard 7문제를 푼 순간, 제가 참가자들 중 가장 먼저 7솔브에 도달했기 떄문에 이거 Div2 우승하는거 아니냐 ㅋㅋ 라고 생각하며 잠깐 설렜습니다. 그런데 생각해보면 CDEFG의 난이도가 비슷해서 생긴 일이므로, 지금 (120분 시점) 6솔인 사람들은 시간이 주어진다면 충분히 7솔브가 가능하고, 저는 E번을 4틀하면서 페널티에서 엄청 밀렸으므로 8솔브를 해야 우승을 노릴 수 있었습니다 (그렇지 않더라도 사실 이 상황에서 저한테 달라질건 없지만요). H와 I 중 무엇을 풀지 고민하다가, H가 인터랙티브라서 I를 풀고자 시도했는데 I번에서도 뭔가 어려움이 많았습니다. $N \sqrt{N}$ 정도까지는 어떻게 잘 우기면 될거 같은데, $N = 2e6$이라서 루트도 허용하지 않는 처참한 시간제한을 보고 다시 H로 도망쳤지만 답이 없었습니다. 대회가 끝나고 매년 SNUPC는 정말 많은 생각이 들게 합니다. 매년 뛰어난 사람들이 몰려오고 있고, 나는 정체된 것이 아닌가 하는 회의감부터, 그럼에도 불구하고 하나씩 풀어나갈 때 나름의 즐거움과 생각하는 과정의 즐거움은 PS를 그만둘 수 없게 하기도 합니다. 내년에는 Div1에 나가보고 싶지만, 어떻게 될지는 모르겠습니다. 내년에 학교에 있을지도 불분명한 상황이라… 이번 H번을 보고, CP 대회에 대한 의욕을 갑자기 훅 잃은 것도 있습니다.</summary></entry><entry><title type="html">논문읽기 : VEQ</title><link href="http://localhost:4000/cs-adventure/VEQ/" rel="alternate" type="text/html" title="논문읽기 : VEQ" /><published>2021-09-11T00:00:00+09:00</published><updated>2021-09-11T00:00:00+09:00</updated><id>http://localhost:4000/cs-adventure/VEQ</id><content type="html" xml:base="http://localhost:4000/cs-adventure/VEQ/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#key-ideas&quot; id=&quot;markdown-toc-key-ideas&quot;&gt;Key Ideas&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#filtering--dag-graph-dp&quot; id=&quot;markdown-toc-filtering--dag-graph-dp&quot;&gt;Filtering : DAG Graph DP&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#adaptive-matching-order--static-equivalence&quot; id=&quot;markdown-toc-adaptive-matching-order--static-equivalence&quot;&gt;Adaptive Matching Order : Static Equivalence&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#run-time-pruning--dynamic-equivalence&quot; id=&quot;markdown-toc-run-time-pruning--dynamic-equivalence&quot;&gt;Run time pruning : Dynamic Equivalence&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#dynamic-equivalence-예시&quot; id=&quot;markdown-toc-dynamic-equivalence-예시&quot;&gt;Dynamic Equivalence 예시&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#실험-performance-analysis&quot; id=&quot;markdown-toc-실험-performance-analysis&quot;&gt;실험 (Performance Analysis)&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thoughts&quot; id=&quot;markdown-toc-thoughts&quot;&gt;Thoughts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;Kim, H., Choi, Y., Park, K., Lin, X., Hong, S. H., &amp;amp; Han, W. S. (2021). Versatile Equivalences: Speeding up Subgraph Query Processing and Subgraph Matching. Proceedings of the ACM SIGMOD International Conference on Management of Data, 925–937. https://doi.org/10.1145/3448016.3457265&lt;/p&gt;

&lt;p&gt;관련 포스팅 : &lt;strong&gt;&lt;a href=&quot;/cs-adventure/sub-iso-note&quot;&gt;Subgraph Isomorphism : Introduction&lt;/a&gt;&lt;/strong&gt; 을 먼저 읽어주세요!&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;이번에 정리할 논문은 제가 2020년 2학기에 연구실 학부생 인턴으로 지도 받았던 서울대학교 컴퓨터이론 및 응용 연구실 (박근수 교수님 연구팀) 에서 이번 2021년 SIGMOD에 발표한 논문이자, 제 이번 창의통합설계와 밀접한 관련이 있는 논문입니다. (그래서 다른 논문에 비해 훨씬 자세히 읽었습니다. 이 논문을 똑같이 구현할 각오(?) 를 하고 있었기 때문에…)&lt;/p&gt;

&lt;p&gt;Subgraph isomorphism에 관한 논문 정리할게 2편 더 남았는데, introduction에 매우 큰 공통점이 있으므로, &lt;strong&gt;&lt;a href=&quot;/cs-adventure/sub-iso-note&quot;&gt;Subgraph Isomorphism : Introduction&lt;/a&gt;&lt;/strong&gt; 라는 포스팅을 별도로 작성했습니다. 이 포스팅으로 Intro 내용 대부분을 때우게 되었습니다.&lt;/p&gt;

&lt;p&gt;이 알고리즘도 크게는 위 포스팅에서 다룬, Filtering - Matching order - Backtracking 의 틀 위에서 설명될 수 있습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;key-ideas&quot;&gt;Key Ideas&lt;/h1&gt;
&lt;h2 id=&quot;filtering--dag-graph-dp&quot;&gt;Filtering : DAG Graph DP&lt;/h2&gt;
&lt;p&gt;더 강한 필터링을 위해, 우리는 어떤 적당한 순서로 DP를 돌려서 Candidate Set (CS) 라는 자료구조를 구축합니다. 그래프에서 DP를 돌리기 위해서는 DP할 순서가 필요하기 때문에, Query Graph로부터 DAG를 만듭니다. 이때 DAG는 label이 좀 unique하면서 degree가 큰 정점을 하나 잡아서, 그 정점에서 BFS를 돌려서 얻을 것입니다. 이를 $q_D$라고 하고, 나중에 역방향으로 돌리기 위해 $q_D$의 inverse DAG $q_D^{-1}$ 로 만듭니다.&lt;/p&gt;

&lt;p&gt;CS는 각 $u \in V_q$에 대해, 집합 $C(u)$ 와 그 집합의 $v_{ip} \in C(u_i)$, $v_{jq} \in C(u_j)$ 사이에 이어진 간선을 저장하는 자료구조입니다. 이 자료구조는 DAF[^ref-daf] 에서 제시된 자료구조이지만, VEQ에서는 더 개선된 버전으로 적용됩니다. 최초의 CS는 label과 $G$에서의 연결관계만 가지고 대충 만들어 놓고 (label이 같은 정점들을 집어넣고, 그 정점과 연결되어 있는 정점을 BFS 순서로 돌면서 빌드) 이를 줄여나갈 것입니다.&lt;/p&gt;

&lt;p&gt;DAG DP는 기본적으로 $\abs{V_q}\abs{V_G}$ 크기의 큰 boolean DP 테이블을 채워나가는 방법입니다. 이 테이블 D는 $D(u_i, v_j)$ 가 곧 $v_j \in C(u_i)$를 의미하는 DP가 됩니다. DAG의 리프부터 시작해서 올라오면서, 다음을 계산합니다.&lt;/p&gt;

&lt;p&gt;$D(u, v)$ 가 1일 필요충분조건 : $u$의 모든 자식 노드 $u_c$에 대해,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$^\exists v_c$ adjacent to $v$, $D(u_c, v_c) = 1$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 조건까지는 DAF에서 사용한 DP의 정의입니다. VEQ에서는 여기서 더 강한 조건을 요구하여 더 강한 필터링을 달성합니다.&lt;br /&gt;
$D(u, v)$ 가 1일 필요충분조건 : $u$의 모든 자식 노드 $u_c$에 대해 DAF에서의 조건을 만족하며, $(u, v)$가 모든 label $l$에 대해 다음을 만족한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;label이 $l$인 $u$의 인접 노드 $u_{l_i}$들에 대해, $C(u_{l_i})$에 포함되는 정점들을 모두 모은 다음, 그들 중 $v$와 연결되어 있는 정점들 (즉, $v$에서 extend 가능한) 만 챙겨서, 이를 $N(u, v, l)$ 이라 합니다.&lt;/li&gt;
  &lt;li&gt;이 $N(u, v, l)$의 크기가, 적어도 $u$의 인접 노드들 중 label이 $l$인 노드보다는 많아야 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉, 직관적으로, 만약 $u_1$을 $v_1$에 매핑해놓고 보니까 $u_1$에는 라벨이 $l$인 이웃이 여섯개 있는데 $v_1$에서 extend가능한 라벨 $l$인 이웃이 네개밖에 없는 상황을 미리 판단해서 방지한다는 것입니다.&lt;/p&gt;

&lt;p&gt;이 조건을 VEQ 논문에서는 “Neighbor-Safety”라고 정의했습니다. 이 조건은 미리 preprocessing을 빡세게 해서 잘 구현하면 원래의 DP와 같은 시간 복잡도 $O(\abs{E_q}\abs{E_G})$에 가능하다고 합니다.&lt;/p&gt;

&lt;p&gt;또한, 이 DP를 최대한 잘 줄이기 위해, query DAG를 여러개 쓰면 더 좋은 결과를 얻을 수 있습니다. 실제로는 $q_D, q_D^{-1}, q_D$ 순서로 반복하면서 쓰면 되는데, 논문에 의하면 3번만 하면 더이상 큰 의미 없다고 합니다.&lt;/p&gt;

&lt;h2 id=&quot;adaptive-matching-order--static-equivalence&quot;&gt;Adaptive Matching Order : Static Equivalence&lt;/h2&gt;
&lt;p&gt;Adaptive Matching Order란, Matching order를 미리 정하지 않고, 백트래킹 하는 중에 다이나믹하게 정해 나가겠다는 의미입니다. 현재까지 찾은 partial embedding $M$에 대해, $M$에 이미 포함된 정점과 이웃한 정점들을 extendable하다고 정의하고, 이때 Candidate set $C(u)$에 들어 있는 정점들 중 partial embedding $M$을 고려할 때 $u$와 매칭 가능한 정점들을 $C_M(u)$ 라고 정의하겠습니다. (즉, $C(u)$에 있더라도, 이미 $M$에서 이웃들을 매칭했을 때 $u_c$를 $v_c$에다가 대고 매치했다면, $v_c$와 이웃하는 점만 남기고 나머지는 날리겠다는 말입니다)&lt;/p&gt;

&lt;p&gt;Extendable vertex중 하나를 택해서 다음 정점으로 삼고 backtracking해야 합니다. CFL-Match와 DAF의 경우 이부분에서 vertex를 core-forest-leaf 또는 core-leaf로 나눠서 매칭하는 전략을 쓰는데, 이 논문에서는 이와 같은 decomposition전략이 leaf가 적을 때 느려서 별로 좋지 않다고 주장합니다.&lt;/p&gt;

&lt;p&gt;대신에, 다음과 같은 방법을 씁니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;DAG DP를 할 때, 미리 query에 대해서 NEC (Neighbor Equivalence Class) 라는 기법을 이용해서 리프 노드를 합칠 것입니다. NEC는 2013년 Turbo-Iso라는 알고리즘 (Postech의 한욱신 교수님 연구팀) 논문 중에 제시된 방법으로, label이 같고 이웃하는 vertex가 같은 leaf를 하나로 합쳐버린 다음 (즉, $u_3$에 리프 $u_4$ 와 $u_5$가 달려있는데 두 라벨이 같으면) 이를 기록해두는 것입니다. 이게 말이 되는 이유는 어차피 $u_4$가 매칭될 수 있는 노드라면 $u_5$도 항상 매칭 가능해서, 두개의 임베딩이 동시에 찾아지기 때문입니다 (둘다 리프이므로 다른 노드를 고려할 필요가 없습니다)&lt;/li&gt;
  &lt;li&gt;만약 리프 $u$가 존재하여, $\abs{NEC(u)}$의 개수를 고려할 때 아직 매칭되지 않은 $C_M(u)$의 노드가 충분히 있다면 이쪽으로 가서 매칭합니다.&lt;/li&gt;
  &lt;li&gt;그렇지 않다면, 리프를 우선적으로 매칭하고,&lt;/li&gt;
  &lt;li&gt;리프가 없으면, $\abs{C_M(u)}$가 작은 노드부터 매칭합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;참고로, DAF의 경우 두개의 adaptive matching order 중 하나를 사용합니다. 이때 두 가지 중 하나가 $C_M(u)$의 크기가 작은 노드부터 매칭하는 것입니다.&lt;/p&gt;

&lt;h2 id=&quot;run-time-pruning--dynamic-equivalence&quot;&gt;Run time pruning : Dynamic Equivalence&lt;/h2&gt;
&lt;p&gt;백트래킹을 하는 중에도, 계속 Search space를 줄이고 싶습니다. 이를 위해서, Candidate Space를 잘 관찰하여 &lt;strong&gt;Equivalence Tree&lt;/strong&gt;의 개념을 정립합니다.&lt;/p&gt;

&lt;p&gt;$C(u)$의 원소 $v_i, v_j$에 대해, $v_i, v_j$와 연결된 $C(u_c)$의 vertex 가 모든 $u$의 이웃 $u_c$ 에 대해 같으면, 두 노드를 Neighbor equivalent in $C(u)$라고 정의합니다. 이를 통해, Cell 이라는 개념을 정의하는데, cell $\pi(u, v)$는 $C(u)$에서 $v$와 equivalent한 $v_i$들의 집합으로 정의합니다. 이미지는 VEQ 원본 논문의 이미지인데, 말로 설명하면 조금 귀찮지만 개념 자체는 직관적입니다.&lt;/p&gt;

&lt;p style=&quot;text-align: center;&quot;&gt;
&lt;img src=&quot;/images/337968b2f03d6ee99afdeed8b69da7c4e989a3071b5c6d6a0180f8525a86a1df.png&quot; alt=&quot;figure&quot; width=&quot;60%&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Partial embedding $M$과, $C(u)$에서 equivalent한 노드 $v_i, v_j$가 있을때, $u \to v_i$를 매칭해 본 정보를 가지고 있다고 하겠습니다. 이때, $v_j$와 $v_i$는 그 특성이 매우 비슷한 노드이기 때문에, $u \to v_j$를 정말 모두 확인하는 것은 뭔가 기분이 매우 나쁩니다.&lt;/p&gt;

&lt;p&gt;논문에서는 이를 위해, 마지막으로 subtree equivalence를 정의합니다. Partial embedding 을 탐색 트리처럼 쓰고 있다는 점에 주의해서 notation을 읽어야 합니다.&lt;/p&gt;

&lt;p&gt;$M \cup (u, v_i)$를 루트로 하는 서브트리에서, $(u’, v_i)$는 더이상 나타나서는 안 되는 conflict들입니다 ($v_i$는 이미 $u$와 매칭되었으므로) 이들을 $I_M(u, v_i)$라 하고, 이 서브트리에서 $v_i \not\in \pi(u’, v’)$인 모든 매핑 (즉, $v_i$와 equivalence관계를 갖지 않는 매핑) 들의 집합을 $O_M(u, v_i)$ 라 합니다. 이때, Negative cell $\pi^{-}(u, v_i)$를 다음과 같이 정의합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;만약 $v_i$에 대한 conflict가 한번이라도 있었다면, $\pi(u, v_i)$와 $\cap_{(u’, v_i) \in I_M(u, v_i)} \pi(u’, v_i)$의 intersection. 즉, $v_i$와 매칭되고 싶어한다는 이유로 conflict를 만드는 $u’$들에 대해, $v_i$를 따라다니면서 모든 곳에서 $v_i$와 equivalent한 노드의 집합.&lt;/li&gt;
  &lt;li&gt;Conflict가 없었다면 $\pi(u, v_i)$로 그대로 가져갑니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;또한, $\delta_{M}(u, v_i)$를 다음과 같이 정의합니다.
\(\bigcup_{(u', v') \in O_M(u, v_i)} \pi(u', v')\)
직관적으로 이는, $v_i$와 equivalent하지 않은 모든 매핑들에 대해서, 그 equivalence class들을 모은 것입니다.&lt;/p&gt;

&lt;p&gt;이를 이용하여, Equivalence set $\pi_M(u, v_i)$를 정의합니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;한번이라도 이 서브트리에서 성공한 사례가 있는 경우, $\pi^{-}(u, v_i) - \delta_M(u, v_i)$를 씁니다.&lt;/li&gt;
  &lt;li&gt;모두 실패한 경우, $\pi^{-}(u, v_i)$를 씁니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 equivalence class는, 진정한 subtree equivalence이기 때문에, $v_j \in \pi_M(u, v_i)$ 인 경우, $v_j$를 $v_i$대신 이용하는 모든 임베딩이 대칭적으로 존재합니다. 따라서, $u \to v_j$ 매칭을 아예 시도하지 않고 버릴 수 있습니다.&lt;/p&gt;

&lt;h2 id=&quot;dynamic-equivalence-예시&quot;&gt;Dynamic Equivalence 예시&lt;/h2&gt;
&lt;p&gt;아래 그림도 VEQ 논문의 그림인데, 일부만 해석해 보도록 하겠습니다.&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;
&lt;img src=&quot;/images/89c1e22afed14b52504b0155821bff13faec7d6422f021a7f423b42fdb77d10f.png&quot; alt=&quot;figure&quot; width=&quot;90%&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;$\pi_M(u_2, v_3)$ 을 생각해 보겠습니다. (이 equivalence set을 완전히 아는 것은 $u_2 \to v_3$ 쪽의 서브트리를 모두 돌고 난 뒤입니다) 트리를 관찰해 보면, $v_3$ 와 매칭되고 싶어해서 conflict를 내는 노드 $u_5$ 가 보입니다. 따라서, $I_M(u_2, v_3) = \set{(u_5, v_3)}$ 입니다. Conflict가 발생한 적이 있으므로, $\pi^{-}(u_2, v_3)$ 을 계산할 때 $\pi(u_2, v_3)$ 와 $\pi(u_5, v_3)$의 intersection을 구합니다. 이는 figure 5를 보고 구하면 $\set{v_4}$고, 서브트리에서 성공해본 적이 없으므로 $\pi_M(u_2, v_3) = \pi^{-}(u_2, v_3) = \set{v_4}$ 입니다. 그러므로 $v_3 \equiv v_4$ 이고, $u_2 \to v_3$에서 성공해 본 적이 없으므로 $u_2 \to v_4$도 성공하는 임베딩이 없음을 알게 되어 탐색하지 않고 prune할수 있습니다.&lt;/p&gt;

&lt;p&gt;이 $\pi_M(u, v)$가 subtree equivalence의 필요충분이라는 증명은 proceeding에 발표된 버전에서는 빠져 있는데, 이후에 증명하게 된다면 채워 넣겠습니다. 직관적으로는, 이후의 서브트리 매칭 시도에서 생기는 모든 conflict와 equivalence를 기억해서 반영하고 있기 때문에 증명은 technical하겠지만 그렇게 이상하지는 않은것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;실험-performance-analysis&quot;&gt;실험 (Performance Analysis)&lt;/h2&gt;
&lt;p&gt;이 논문의 저자들은 VEQ 알고리즘을 기존의 SOTA 알고리즘들과 비교하여 성능을 측정하는 실험을 실행했고, 절대적인 소요 시간을 많이 줄일 수 있었습니다. 특히, 재미있는 결과 몇가지만 소개합니다. 비교 대상인 알고리즘들은 같은 큰 틀을 공유하는 CFL-Match, DAF, GQL, RI와 Constraint programming 기반의 Glasgow (시간만 비교) 입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Matching order는 차치하고, 결국은 필터링을 빡세게 걸고 백트래킹하는게 알고리즘들의 틀입니다. 여기서, 필터링을 열심히 할수록 백트래킹할게 적은데, 백트래킹은 최악의 경우 지수 시간이 걸리지만 필터링은 어쨌든 다항시간에 할 수 있으므로, 필터링 시간이 크고 백트래킹 시간이 작다면 알고리즘의 성능이 데이터셋에 대해 좀더 stable합니다. 이 점에서 VEQ는 필터링을 extended DP로 강하게 하고, Dynamic pruning으로 백트래킹 시간을 많이 줄이기 때문에 최소 50%에서 최대 95% 정도의 시간을 필터링에 쓰고, 백트래킹은 정말 최소화합니다.&lt;/li&gt;
  &lt;li&gt;이것은, Extended DP를 했기 때문이기도 하지만, 필터링 결과 자체의 차이보다도 오히려 필터링 과정에서 얻는 Cell이라는 엄청나게 강한 정보를 이후에 이용할 수 있었던 점이 가장 중요해 보입니다. 즉, 다항시간에 할수있는 일들을 최대한 처리했기 때문에 가능했을 것입니다.&lt;/li&gt;
  &lt;li&gt;실제로, Dynamic Equivalence를 수행하여 날릴 수 있었던 search space가 많은 케이스에서 99% 가까이 나오기도 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;Neighbor safety에서, 이 논문에서는 1-neighbor만을 고려하여 safety를 계산합니다. 더 많은, 예를들어 2-neighbor (거리가 2인 노드들까지) 까지 고려하면 더 강한 필터링이 가능할텐데, 그러지 않은 이유는 아마도 필터링에 소요하는 시간에 비해 필터링의 효용이 크지 않다고 보았기 때문일 것입니다. 그렇다면, label의 frequency가 높을 때 (즉 label frequency가 생각보다 더 중요할 때) 는 고려하는 neighbor의 수를 더 늘리는 방식처럼 뭔가 다이나믹하게 계산가능한 파라미터를 잡을수는 없을까요?&lt;/li&gt;
  &lt;li&gt;Equivalence를 Hashing 등을 통해 잘 관리하면 더 빠르게 처리할 수 있을까요?&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="cs-adventure" /><summary type="html">Contents Introduction Key Ideas Filtering : DAG Graph DP Adaptive Matching Order : Static Equivalence Run time pruning : Dynamic Equivalence Dynamic Equivalence 예시 실험 (Performance Analysis) Thoughts Kim, H., Choi, Y., Park, K., Lin, X., Hong, S. H., &amp;amp; Han, W. S. (2021). Versatile Equivalences: Speeding up Subgraph Query Processing and Subgraph Matching. Proceedings of the ACM SIGMOD International Conference on Management of Data, 925–937. https://doi.org/10.1145/3448016.3457265 관련 포스팅 : Subgraph Isomorphism : Introduction 을 먼저 읽어주세요! Introduction 이번에 정리할 논문은 제가 2020년 2학기에 연구실 학부생 인턴으로 지도 받았던 서울대학교 컴퓨터이론 및 응용 연구실 (박근수 교수님 연구팀) 에서 이번 2021년 SIGMOD에 발표한 논문이자, 제 이번 창의통합설계와 밀접한 관련이 있는 논문입니다. (그래서 다른 논문에 비해 훨씬 자세히 읽었습니다. 이 논문을 똑같이 구현할 각오(?) 를 하고 있었기 때문에…) Subgraph isomorphism에 관한 논문 정리할게 2편 더 남았는데, introduction에 매우 큰 공통점이 있으므로, Subgraph Isomorphism : Introduction 라는 포스팅을 별도로 작성했습니다. 이 포스팅으로 Intro 내용 대부분을 때우게 되었습니다. 이 알고리즘도 크게는 위 포스팅에서 다룬, Filtering - Matching order - Backtracking 의 틀 위에서 설명될 수 있습니다. Key Ideas Filtering : DAG Graph DP 더 강한 필터링을 위해, 우리는 어떤 적당한 순서로 DP를 돌려서 Candidate Set (CS) 라는 자료구조를 구축합니다. 그래프에서 DP를 돌리기 위해서는 DP할 순서가 필요하기 때문에, Query Graph로부터 DAG를 만듭니다. 이때 DAG는 label이 좀 unique하면서 degree가 큰 정점을 하나 잡아서, 그 정점에서 BFS를 돌려서 얻을 것입니다. 이를 $q_D$라고 하고, 나중에 역방향으로 돌리기 위해 $q_D$의 inverse DAG $q_D^{-1}$ 로 만듭니다. CS는 각 $u \in V_q$에 대해, 집합 $C(u)$ 와 그 집합의 $v_{ip} \in C(u_i)$, $v_{jq} \in C(u_j)$ 사이에 이어진 간선을 저장하는 자료구조입니다. 이 자료구조는 DAF[^ref-daf] 에서 제시된 자료구조이지만, VEQ에서는 더 개선된 버전으로 적용됩니다. 최초의 CS는 label과 $G$에서의 연결관계만 가지고 대충 만들어 놓고 (label이 같은 정점들을 집어넣고, 그 정점과 연결되어 있는 정점을 BFS 순서로 돌면서 빌드) 이를 줄여나갈 것입니다. DAG DP는 기본적으로 $\abs{V_q}\abs{V_G}$ 크기의 큰 boolean DP 테이블을 채워나가는 방법입니다. 이 테이블 D는 $D(u_i, v_j)$ 가 곧 $v_j \in C(u_i)$를 의미하는 DP가 됩니다. DAG의 리프부터 시작해서 올라오면서, 다음을 계산합니다. $D(u, v)$ 가 1일 필요충분조건 : $u$의 모든 자식 노드 $u_c$에 대해, $^\exists v_c$ adjacent to $v$, $D(u_c, v_c) = 1$ 이 조건까지는 DAF에서 사용한 DP의 정의입니다. VEQ에서는 여기서 더 강한 조건을 요구하여 더 강한 필터링을 달성합니다. $D(u, v)$ 가 1일 필요충분조건 : $u$의 모든 자식 노드 $u_c$에 대해 DAF에서의 조건을 만족하며, $(u, v)$가 모든 label $l$에 대해 다음을 만족한다. label이 $l$인 $u$의 인접 노드 $u_{l_i}$들에 대해, $C(u_{l_i})$에 포함되는 정점들을 모두 모은 다음, 그들 중 $v$와 연결되어 있는 정점들 (즉, $v$에서 extend 가능한) 만 챙겨서, 이를 $N(u, v, l)$ 이라 합니다. 이 $N(u, v, l)$의 크기가, 적어도 $u$의 인접 노드들 중 label이 $l$인 노드보다는 많아야 합니다. 즉, 직관적으로, 만약 $u_1$을 $v_1$에 매핑해놓고 보니까 $u_1$에는 라벨이 $l$인 이웃이 여섯개 있는데 $v_1$에서 extend가능한 라벨 $l$인 이웃이 네개밖에 없는 상황을 미리 판단해서 방지한다는 것입니다. 이 조건을 VEQ 논문에서는 “Neighbor-Safety”라고 정의했습니다. 이 조건은 미리 preprocessing을 빡세게 해서 잘 구현하면 원래의 DP와 같은 시간 복잡도 $O(\abs{E_q}\abs{E_G})$에 가능하다고 합니다. 또한, 이 DP를 최대한 잘 줄이기 위해, query DAG를 여러개 쓰면 더 좋은 결과를 얻을 수 있습니다. 실제로는 $q_D, q_D^{-1}, q_D$ 순서로 반복하면서 쓰면 되는데, 논문에 의하면 3번만 하면 더이상 큰 의미 없다고 합니다. Adaptive Matching Order : Static Equivalence Adaptive Matching Order란, Matching order를 미리 정하지 않고, 백트래킹 하는 중에 다이나믹하게 정해 나가겠다는 의미입니다. 현재까지 찾은 partial embedding $M$에 대해, $M$에 이미 포함된 정점과 이웃한 정점들을 extendable하다고 정의하고, 이때 Candidate set $C(u)$에 들어 있는 정점들 중 partial embedding $M$을 고려할 때 $u$와 매칭 가능한 정점들을 $C_M(u)$ 라고 정의하겠습니다. (즉, $C(u)$에 있더라도, 이미 $M$에서 이웃들을 매칭했을 때 $u_c$를 $v_c$에다가 대고 매치했다면, $v_c$와 이웃하는 점만 남기고 나머지는 날리겠다는 말입니다) Extendable vertex중 하나를 택해서 다음 정점으로 삼고 backtracking해야 합니다. CFL-Match와 DAF의 경우 이부분에서 vertex를 core-forest-leaf 또는 core-leaf로 나눠서 매칭하는 전략을 쓰는데, 이 논문에서는 이와 같은 decomposition전략이 leaf가 적을 때 느려서 별로 좋지 않다고 주장합니다. 대신에, 다음과 같은 방법을 씁니다. DAG DP를 할 때, 미리 query에 대해서 NEC (Neighbor Equivalence Class) 라는 기법을 이용해서 리프 노드를 합칠 것입니다. NEC는 2013년 Turbo-Iso라는 알고리즘 (Postech의 한욱신 교수님 연구팀) 논문 중에 제시된 방법으로, label이 같고 이웃하는 vertex가 같은 leaf를 하나로 합쳐버린 다음 (즉, $u_3$에 리프 $u_4$ 와 $u_5$가 달려있는데 두 라벨이 같으면) 이를 기록해두는 것입니다. 이게 말이 되는 이유는 어차피 $u_4$가 매칭될 수 있는 노드라면 $u_5$도 항상 매칭 가능해서, 두개의 임베딩이 동시에 찾아지기 때문입니다 (둘다 리프이므로 다른 노드를 고려할 필요가 없습니다) 만약 리프 $u$가 존재하여, $\abs{NEC(u)}$의 개수를 고려할 때 아직 매칭되지 않은 $C_M(u)$의 노드가 충분히 있다면 이쪽으로 가서 매칭합니다. 그렇지 않다면, 리프를 우선적으로 매칭하고, 리프가 없으면, $\abs{C_M(u)}$가 작은 노드부터 매칭합니다. 참고로, DAF의 경우 두개의 adaptive matching order 중 하나를 사용합니다. 이때 두 가지 중 하나가 $C_M(u)$의 크기가 작은 노드부터 매칭하는 것입니다. Run time pruning : Dynamic Equivalence 백트래킹을 하는 중에도, 계속 Search space를 줄이고 싶습니다. 이를 위해서, Candidate Space를 잘 관찰하여 Equivalence Tree의 개념을 정립합니다. $C(u)$의 원소 $v_i, v_j$에 대해, $v_i, v_j$와 연결된 $C(u_c)$의 vertex 가 모든 $u$의 이웃 $u_c$ 에 대해 같으면, 두 노드를 Neighbor equivalent in $C(u)$라고 정의합니다. 이를 통해, Cell 이라는 개념을 정의하는데, cell $\pi(u, v)$는 $C(u)$에서 $v$와 equivalent한 $v_i$들의 집합으로 정의합니다. 이미지는 VEQ 원본 논문의 이미지인데, 말로 설명하면 조금 귀찮지만 개념 자체는 직관적입니다. Partial embedding $M$과, $C(u)$에서 equivalent한 노드 $v_i, v_j$가 있을때, $u \to v_i$를 매칭해 본 정보를 가지고 있다고 하겠습니다. 이때, $v_j$와 $v_i$는 그 특성이 매우 비슷한 노드이기 때문에, $u \to v_j$를 정말 모두 확인하는 것은 뭔가 기분이 매우 나쁩니다. 논문에서는 이를 위해, 마지막으로 subtree equivalence를 정의합니다. Partial embedding 을 탐색 트리처럼 쓰고 있다는 점에 주의해서 notation을 읽어야 합니다. $M \cup (u, v_i)$를 루트로 하는 서브트리에서, $(u’, v_i)$는 더이상 나타나서는 안 되는 conflict들입니다 ($v_i$는 이미 $u$와 매칭되었으므로) 이들을 $I_M(u, v_i)$라 하고, 이 서브트리에서 $v_i \not\in \pi(u’, v’)$인 모든 매핑 (즉, $v_i$와 equivalence관계를 갖지 않는 매핑) 들의 집합을 $O_M(u, v_i)$ 라 합니다. 이때, Negative cell $\pi^{-}(u, v_i)$를 다음과 같이 정의합니다. 만약 $v_i$에 대한 conflict가 한번이라도 있었다면, $\pi(u, v_i)$와 $\cap_{(u’, v_i) \in I_M(u, v_i)} \pi(u’, v_i)$의 intersection. 즉, $v_i$와 매칭되고 싶어한다는 이유로 conflict를 만드는 $u’$들에 대해, $v_i$를 따라다니면서 모든 곳에서 $v_i$와 equivalent한 노드의 집합. Conflict가 없었다면 $\pi(u, v_i)$로 그대로 가져갑니다. 또한, $\delta_{M}(u, v_i)$를 다음과 같이 정의합니다. \(\bigcup_{(u', v') \in O_M(u, v_i)} \pi(u', v')\) 직관적으로 이는, $v_i$와 equivalent하지 않은 모든 매핑들에 대해서, 그 equivalence class들을 모은 것입니다. 이를 이용하여, Equivalence set $\pi_M(u, v_i)$를 정의합니다. 한번이라도 이 서브트리에서 성공한 사례가 있는 경우, $\pi^{-}(u, v_i) - \delta_M(u, v_i)$를 씁니다. 모두 실패한 경우, $\pi^{-}(u, v_i)$를 씁니다. 이 equivalence class는, 진정한 subtree equivalence이기 때문에, $v_j \in \pi_M(u, v_i)$ 인 경우, $v_j$를 $v_i$대신 이용하는 모든 임베딩이 대칭적으로 존재합니다. 따라서, $u \to v_j$ 매칭을 아예 시도하지 않고 버릴 수 있습니다. Dynamic Equivalence 예시 아래 그림도 VEQ 논문의 그림인데, 일부만 해석해 보도록 하겠습니다. $\pi_M(u_2, v_3)$ 을 생각해 보겠습니다. (이 equivalence set을 완전히 아는 것은 $u_2 \to v_3$ 쪽의 서브트리를 모두 돌고 난 뒤입니다) 트리를 관찰해 보면, $v_3$ 와 매칭되고 싶어해서 conflict를 내는 노드 $u_5$ 가 보입니다. 따라서, $I_M(u_2, v_3) = \set{(u_5, v_3)}$ 입니다. Conflict가 발생한 적이 있으므로, $\pi^{-}(u_2, v_3)$ 을 계산할 때 $\pi(u_2, v_3)$ 와 $\pi(u_5, v_3)$의 intersection을 구합니다. 이는 figure 5를 보고 구하면 $\set{v_4}$고, 서브트리에서 성공해본 적이 없으므로 $\pi_M(u_2, v_3) = \pi^{-}(u_2, v_3) = \set{v_4}$ 입니다. 그러므로 $v_3 \equiv v_4$ 이고, $u_2 \to v_3$에서 성공해 본 적이 없으므로 $u_2 \to v_4$도 성공하는 임베딩이 없음을 알게 되어 탐색하지 않고 prune할수 있습니다. 이 $\pi_M(u, v)$가 subtree equivalence의 필요충분이라는 증명은 proceeding에 발표된 버전에서는 빠져 있는데, 이후에 증명하게 된다면 채워 넣겠습니다. 직관적으로는, 이후의 서브트리 매칭 시도에서 생기는 모든 conflict와 equivalence를 기억해서 반영하고 있기 때문에 증명은 technical하겠지만 그렇게 이상하지는 않은것 같습니다. 실험 (Performance Analysis) 이 논문의 저자들은 VEQ 알고리즘을 기존의 SOTA 알고리즘들과 비교하여 성능을 측정하는 실험을 실행했고, 절대적인 소요 시간을 많이 줄일 수 있었습니다. 특히, 재미있는 결과 몇가지만 소개합니다. 비교 대상인 알고리즘들은 같은 큰 틀을 공유하는 CFL-Match, DAF, GQL, RI와 Constraint programming 기반의 Glasgow (시간만 비교) 입니다. Matching order는 차치하고, 결국은 필터링을 빡세게 걸고 백트래킹하는게 알고리즘들의 틀입니다. 여기서, 필터링을 열심히 할수록 백트래킹할게 적은데, 백트래킹은 최악의 경우 지수 시간이 걸리지만 필터링은 어쨌든 다항시간에 할 수 있으므로, 필터링 시간이 크고 백트래킹 시간이 작다면 알고리즘의 성능이 데이터셋에 대해 좀더 stable합니다. 이 점에서 VEQ는 필터링을 extended DP로 강하게 하고, Dynamic pruning으로 백트래킹 시간을 많이 줄이기 때문에 최소 50%에서 최대 95% 정도의 시간을 필터링에 쓰고, 백트래킹은 정말 최소화합니다. 이것은, Extended DP를 했기 때문이기도 하지만, 필터링 결과 자체의 차이보다도 오히려 필터링 과정에서 얻는 Cell이라는 엄청나게 강한 정보를 이후에 이용할 수 있었던 점이 가장 중요해 보입니다. 즉, 다항시간에 할수있는 일들을 최대한 처리했기 때문에 가능했을 것입니다. 실제로, Dynamic Equivalence를 수행하여 날릴 수 있었던 search space가 많은 케이스에서 99% 가까이 나오기도 합니다. Thoughts Neighbor safety에서, 이 논문에서는 1-neighbor만을 고려하여 safety를 계산합니다. 더 많은, 예를들어 2-neighbor (거리가 2인 노드들까지) 까지 고려하면 더 강한 필터링이 가능할텐데, 그러지 않은 이유는 아마도 필터링에 소요하는 시간에 비해 필터링의 효용이 크지 않다고 보았기 때문일 것입니다. 그렇다면, label의 frequency가 높을 때 (즉 label frequency가 생각보다 더 중요할 때) 는 고려하는 neighbor의 수를 더 늘리는 방식처럼 뭔가 다이나믹하게 계산가능한 파라미터를 잡을수는 없을까요? Equivalence를 Hashing 등을 통해 잘 관리하면 더 빠르게 처리할 수 있을까요?</summary></entry><entry><title type="html">Subgraph Isomorphism : Introduction</title><link href="http://localhost:4000/cs-adventure/sub-iso-note/" rel="alternate" type="text/html" title="Subgraph Isomorphism : Introduction" /><published>2021-09-11T00:00:00+09:00</published><updated>2021-09-11T00:00:00+09:00</updated><id>http://localhost:4000/cs-adventure/sub-iso-note</id><content type="html" xml:base="http://localhost:4000/cs-adventure/sub-iso-note/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#subgraph-isomorphism-문제-소개&quot; id=&quot;markdown-toc-subgraph-isomorphism-문제-소개&quot;&gt;Subgraph Isomorphism 문제 소개&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#subgraph-isomorphism-algorithms&quot; id=&quot;markdown-toc-subgraph-isomorphism-algorithms&quot;&gt;Subgraph Isomorphism Algorithms&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#backtracking-algorithms&quot; id=&quot;markdown-toc-backtracking-algorithms&quot;&gt;Backtracking Algorithms&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#filtering&quot; id=&quot;markdown-toc-filtering&quot;&gt;Filtering&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#matching-order&quot; id=&quot;markdown-toc-matching-order&quot;&gt;Matching Order&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#backtracking&quot; id=&quot;markdown-toc-backtracking&quot;&gt;Backtracking&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#references--papers&quot; id=&quot;markdown-toc-references--papers&quot;&gt;References / Papers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;subgraph-isomorphism-문제-소개&quot;&gt;Subgraph Isomorphism 문제 소개&lt;/h2&gt;

&lt;p&gt;Subgraph Isomorphism이란, 쿼리 그래프 $q$와 데이터 그래프 $G$가 주어지는 상황에서, $G$가 $q$와 isomorphic한 subgraph를 갖는지 여부를 판단하는 문제입니다. 이 문제는 NP-Complete임이 증명되어 있습니다. NP-Complete를 증명하는 것은 우리의 논의에 그렇게 중요하지 않지만, 잠깐 생각해 보면, Clique Problem (Subgraph Isomorphism에서, $q$가 정점 $n$개짜리 완전그래프 $K_n$으로 한정되는 버전) 보다는 적어도 어려운 문제임을 알 수 있습니다. Clique 문제는 Karp가 NP-Complete라는 개념을 정의하고 증명했을 때 나온 21개의 오리지널한 NP-Complete 문제 중 하나로, General SAT로부터 환원되므로 NP-Complete입니다.&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;우리는 Subgraph에 관한 문제를 접근하면서, 다음과 같이 Embedding을 정의합니다.&lt;br /&gt;
Vertex Labeled graph $G, q$가 주어졌을 때, 함수 $f : V_q \to V_G$가 존재하여, $q$에서 edge $(u_1, u_2)$에 대해 항상 $G$에서 edge $(v_1 = f(u_1), v_2 = f(u_2))$ 를 찾을 수 있을 때, 이를 Embedding 이라 합니다. 단, Labeled graph이므로 $q$에서 $u$의 label과 $G$에서 $f(u)$의 label이 항상 같아야 합니다. 앞으로 편의상 $u_1 \dots u_n$은 $q$의, $v_1 \dots v_n$은 $G$의 vertex를 의미하는 것으로 쓰겠습니다.&lt;/p&gt;

&lt;p&gt;비슷하지만 좀더 Application 스러운 문제 두 개인 Subgraph search와 matching은, 다음과 같이 정의됩니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Subgraph Search란, 데이터 그래프가 하나가 아니라 여러 개 $G_1, G_2, \dots G_n$의 집합이 주어지고, $q$의 embedding을 갖는 그래프들을 모두 찾는 문제입니다.&lt;/li&gt;
  &lt;li&gt;Subgraph Matching이란, 데이터 그래프가 하나 주어지고, 쿼리 그래프가 주어져서, 데이터 그래프에서 $q$의 embedding을 모두 (또는 좀더 현실적으로, 가능한한 많이) 찾는 문제입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉, subgraph matching을 푸는 알고리즘에게 embedding을 하나 찾고 return true 하도록 하면, subgraph isomorphism이 되고, 다시 이것을 여러 데이터 그래프에 대해 반복하면 subgraph search가 됩니다. 이 글에서는, 세 문제 모두를 대충 Subgraph Isomorphism이라고 퉁치고 맥락상 이해하기로 하겠습니다.&lt;/p&gt;

&lt;h2 id=&quot;subgraph-isomorphism-algorithms&quot;&gt;Subgraph Isomorphism Algorithms&lt;/h2&gt;
&lt;p&gt;이런 어려운 문제에 대한 접근에는 크게 세 가지가 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;문제의 제약 있는 버전을 만들어서, 그 문제를 빠르게 풀고자 시도합니다. 주로 사용하는 접근으로는 &lt;strong&gt;Chromatic Number&lt;/strong&gt;가 $k$ 이하인 그래프, &lt;strong&gt;평면&lt;/strong&gt; 그래프, &lt;strong&gt;Sparse&lt;/strong&gt;한 그래프 등에 대해 시도합니다. 이 방향의 연구는 주로 알고리즘이 다항 시간 비슷하게 줄어들며 (NP-Complete한 문제의 일부긴 하지만, 추가적인 조건을 제약했으므로 이게 가능합니다) 수학적으로 엄밀하게 증명합니다.&lt;/li&gt;
  &lt;li&gt;Randomized 알고리즘이나 최적화 형태의 알고리즘을 만들어서, expected time complexity를 줄이고자 합니다.&lt;/li&gt;
  &lt;li&gt;일반적인 Case에 대해, 휴리스틱하게 빠른 알고리즘을 찾고, 이를 큰 데이터셋에 대해 실험을 통해 검증하는 방향이 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2020년 2학기에 인턴십을 진행하면서 주로 3번에 해당하는 쪽을 공부했는데, Sub-iso에서 2번은 어떤 식인지 잘 모르겠고 (본적 없습니다) 1번은 여러 재미있는 결과들이 있지만 아직 자세히 읽어보지는 못했습니다.&lt;/p&gt;

&lt;p&gt;이 문제의 3번 접근에는 다시 크게 세가지 접근이 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ullmann (1976) 으로부터 시작하는 Backtracking 기반의 알고리즘으로, 가장 자연스럽게 생각할 수 있는 백트래킹에 기반합니다.&lt;/li&gt;
  &lt;li&gt;Artificial Intelligence 쪽에서도 이 문제를 상당히 중요하게 보고 있어서, 이쪽의 접근도 있습니다. Graph 위에서 뭔가를 열심히 학습시키는 방법입니다.&lt;/li&gt;
  &lt;li&gt;Contraint Programming 이라는 신기한 방법론에 기반하는 접근이 있습니다. 저는 이쪽을 잘 모르지만, 이론적으로 상당히 재밌는 내용들이 많다고 들었습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2번은 주로 Graph mining 같은 방향으로 접근하여 약간 방향성이 다르기 때문에, 1번과 3번을 실질적으로 알고리즘적인 접근으로 볼 수 있습니다. 3번의 현재 SOTA는 Glasgow라는 프로그램이 있고, 1번의 경우 CFL-Match라는 알고리즘을 기점으로 CECI, DAF 등이 연구되었습니다.&lt;/p&gt;

&lt;h2 id=&quot;backtracking-algorithms&quot;&gt;Backtracking Algorithms&lt;/h2&gt;
&lt;p&gt;CFL-Match, CECI, DAF를 비롯하여 많은 알고리즘들이 크게 3단계로 이 문제를 해결합니다. Filtering - Matching order generation - Backtracking인데, 각각이 어떤 느낌인지 알아보겠습니다.&lt;/p&gt;

&lt;h3 id=&quot;filtering&quot;&gt;Filtering&lt;/h3&gt;
&lt;p&gt;Filtering이란, 도저히 매칭이 안되는 점들을 먼저 쳐내는 방법입니다. 이때 Candidate Vertex Set이라는 개념이 등장하는데, $q$의 정점 $u$에 대해 $u$가 매핑될 수 있는 $G$의 vertex들이라고 볼 수 있습니다. 예를 들어, Label이 다른 정점은 아예 고려할 필요가 없습니다. 조금 더 복잡한 예시로는, $q$에서 1번 정점으로부터 label이 $a$인 정점으로 가는 간선이 있는 상황을 생각해 보겠습니다. $G$의 정점 10번에 대해, 10번 정점의 neighbor들 중 label이 $a$인 정점이 하나도 없다면, $u_1$ 을 $v_{10}$으로 매칭하는 매핑은 존재할 수 없습니다. 이러한 정점들을 최대한 강하게 필터링해서 제거하면, 백트래킹할 대상이 줄어들 것입니다. 이때 Candidate vertex set은 $u_i$가 매핑될 수 있는 $v_j$ 들의 집합 $C_i$를 말하며, 알고리즘에 따라서는 이 과정을 좀더 잘 하는 방법을 제시하는 경우 자료구조의 이름이 달라지기도 하지만 대략적으로는 이렇습니다.&lt;/p&gt;

&lt;h3 id=&quot;matching-order&quot;&gt;Matching Order&lt;/h3&gt;
&lt;p&gt;문제의 특징 상, 어떤 순서로 정점들을 matching해 나가는지는 search space가 감소하는 속도를 좌우하는 매우 중요한 요소입니다. Backtracking을 하기 위해서는 이 matching order가 필요한데, 이후 백트래킹을 수행하는 순서 (정의상 $q_V$의 permutation) 를 matching order라고 부릅니다. 알고리즘마다 다른 matching order를 사용하게 됩니다.&lt;/p&gt;

&lt;h3 id=&quot;backtracking&quot;&gt;Backtracking&lt;/h3&gt;
&lt;p&gt;백트래킹은 단순히 하면 되지만, 이 과정에서 다양한 최적화가 가능합니다. 먼저 백트래킹을 위해서는 extendable한 candidate를 잡아야 하는데…&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;현재의 partial embedding $M$에서 사용했던 점들은 다시 사용할 수 없고&lt;/li&gt;
  &lt;li&gt;지금 내가 $u$를 보고 있다면, $u$의 neighbor들 중 $M$에서 이미 매핑된 정점들에 대해, 그 정점들 모두와 연결이 가능해야 합니다. 즉, $u_3$이 $u_1$, $u_2$ 와 연결되어 있고, $u_1, u_2$를 각각 $v_a, v_b$와 연결되어 있으면, $u_3$은 적어도 $v_a, v_b$와 연결된 점들 중에 골라야 한다는 것입니다. 
이 두가지가 가장 기본이 됩니다. 여기서 추가로 DAF의 경우 Failing set과 같은 최적화 기법들을 제시하기도 했습니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;references--papers&quot;&gt;References / Papers&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Sun, S., &amp;amp; Luo, Q. (2020). &lt;strong&gt;In-Memory Subgraph Matching: An In-depth Study&lt;/strong&gt;. Proceedings of the ACM SIGMOD International Conference on Management of Data, 1083–1098. https://doi.org/10.1145/3318464.3380581 : Subgraph Isomorphism 방법들을 비교하고, 이들을 모두 구현하여 통일된 프레임워크 위에서 실험한 논문입니다. 이 글은 거의 이 논문에 기반한 정리 포스팅인데, 논문의 메인인 실험 결과를 정리하지 않았기 때문에 그렇게 분류해놓지는 않았습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;이부분의 증명은 이 글의 Scope를 너무 많이 벗어납니다. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="cs-adventure" /><summary type="html">Contents Subgraph Isomorphism 문제 소개 Subgraph Isomorphism Algorithms Backtracking Algorithms Filtering Matching Order Backtracking References / Papers Subgraph Isomorphism 문제 소개 Subgraph Isomorphism이란, 쿼리 그래프 $q$와 데이터 그래프 $G$가 주어지는 상황에서, $G$가 $q$와 isomorphic한 subgraph를 갖는지 여부를 판단하는 문제입니다. 이 문제는 NP-Complete임이 증명되어 있습니다. NP-Complete를 증명하는 것은 우리의 논의에 그렇게 중요하지 않지만, 잠깐 생각해 보면, Clique Problem (Subgraph Isomorphism에서, $q$가 정점 $n$개짜리 완전그래프 $K_n$으로 한정되는 버전) 보다는 적어도 어려운 문제임을 알 수 있습니다. Clique 문제는 Karp가 NP-Complete라는 개념을 정의하고 증명했을 때 나온 21개의 오리지널한 NP-Complete 문제 중 하나로, General SAT로부터 환원되므로 NP-Complete입니다.1 우리는 Subgraph에 관한 문제를 접근하면서, 다음과 같이 Embedding을 정의합니다. Vertex Labeled graph $G, q$가 주어졌을 때, 함수 $f : V_q \to V_G$가 존재하여, $q$에서 edge $(u_1, u_2)$에 대해 항상 $G$에서 edge $(v_1 = f(u_1), v_2 = f(u_2))$ 를 찾을 수 있을 때, 이를 Embedding 이라 합니다. 단, Labeled graph이므로 $q$에서 $u$의 label과 $G$에서 $f(u)$의 label이 항상 같아야 합니다. 앞으로 편의상 $u_1 \dots u_n$은 $q$의, $v_1 \dots v_n$은 $G$의 vertex를 의미하는 것으로 쓰겠습니다. 비슷하지만 좀더 Application 스러운 문제 두 개인 Subgraph search와 matching은, 다음과 같이 정의됩니다. Subgraph Search란, 데이터 그래프가 하나가 아니라 여러 개 $G_1, G_2, \dots G_n$의 집합이 주어지고, $q$의 embedding을 갖는 그래프들을 모두 찾는 문제입니다. Subgraph Matching이란, 데이터 그래프가 하나 주어지고, 쿼리 그래프가 주어져서, 데이터 그래프에서 $q$의 embedding을 모두 (또는 좀더 현실적으로, 가능한한 많이) 찾는 문제입니다. 즉, subgraph matching을 푸는 알고리즘에게 embedding을 하나 찾고 return true 하도록 하면, subgraph isomorphism이 되고, 다시 이것을 여러 데이터 그래프에 대해 반복하면 subgraph search가 됩니다. 이 글에서는, 세 문제 모두를 대충 Subgraph Isomorphism이라고 퉁치고 맥락상 이해하기로 하겠습니다. Subgraph Isomorphism Algorithms 이런 어려운 문제에 대한 접근에는 크게 세 가지가 있습니다. 문제의 제약 있는 버전을 만들어서, 그 문제를 빠르게 풀고자 시도합니다. 주로 사용하는 접근으로는 Chromatic Number가 $k$ 이하인 그래프, 평면 그래프, Sparse한 그래프 등에 대해 시도합니다. 이 방향의 연구는 주로 알고리즘이 다항 시간 비슷하게 줄어들며 (NP-Complete한 문제의 일부긴 하지만, 추가적인 조건을 제약했으므로 이게 가능합니다) 수학적으로 엄밀하게 증명합니다. Randomized 알고리즘이나 최적화 형태의 알고리즘을 만들어서, expected time complexity를 줄이고자 합니다. 일반적인 Case에 대해, 휴리스틱하게 빠른 알고리즘을 찾고, 이를 큰 데이터셋에 대해 실험을 통해 검증하는 방향이 있습니다. 2020년 2학기에 인턴십을 진행하면서 주로 3번에 해당하는 쪽을 공부했는데, Sub-iso에서 2번은 어떤 식인지 잘 모르겠고 (본적 없습니다) 1번은 여러 재미있는 결과들이 있지만 아직 자세히 읽어보지는 못했습니다. 이 문제의 3번 접근에는 다시 크게 세가지 접근이 있습니다. Ullmann (1976) 으로부터 시작하는 Backtracking 기반의 알고리즘으로, 가장 자연스럽게 생각할 수 있는 백트래킹에 기반합니다. Artificial Intelligence 쪽에서도 이 문제를 상당히 중요하게 보고 있어서, 이쪽의 접근도 있습니다. Graph 위에서 뭔가를 열심히 학습시키는 방법입니다. Contraint Programming 이라는 신기한 방법론에 기반하는 접근이 있습니다. 저는 이쪽을 잘 모르지만, 이론적으로 상당히 재밌는 내용들이 많다고 들었습니다. 2번은 주로 Graph mining 같은 방향으로 접근하여 약간 방향성이 다르기 때문에, 1번과 3번을 실질적으로 알고리즘적인 접근으로 볼 수 있습니다. 3번의 현재 SOTA는 Glasgow라는 프로그램이 있고, 1번의 경우 CFL-Match라는 알고리즘을 기점으로 CECI, DAF 등이 연구되었습니다. Backtracking Algorithms CFL-Match, CECI, DAF를 비롯하여 많은 알고리즘들이 크게 3단계로 이 문제를 해결합니다. Filtering - Matching order generation - Backtracking인데, 각각이 어떤 느낌인지 알아보겠습니다. Filtering Filtering이란, 도저히 매칭이 안되는 점들을 먼저 쳐내는 방법입니다. 이때 Candidate Vertex Set이라는 개념이 등장하는데, $q$의 정점 $u$에 대해 $u$가 매핑될 수 있는 $G$의 vertex들이라고 볼 수 있습니다. 예를 들어, Label이 다른 정점은 아예 고려할 필요가 없습니다. 조금 더 복잡한 예시로는, $q$에서 1번 정점으로부터 label이 $a$인 정점으로 가는 간선이 있는 상황을 생각해 보겠습니다. $G$의 정점 10번에 대해, 10번 정점의 neighbor들 중 label이 $a$인 정점이 하나도 없다면, $u_1$ 을 $v_{10}$으로 매칭하는 매핑은 존재할 수 없습니다. 이러한 정점들을 최대한 강하게 필터링해서 제거하면, 백트래킹할 대상이 줄어들 것입니다. 이때 Candidate vertex set은 $u_i$가 매핑될 수 있는 $v_j$ 들의 집합 $C_i$를 말하며, 알고리즘에 따라서는 이 과정을 좀더 잘 하는 방법을 제시하는 경우 자료구조의 이름이 달라지기도 하지만 대략적으로는 이렇습니다. Matching Order 문제의 특징 상, 어떤 순서로 정점들을 matching해 나가는지는 search space가 감소하는 속도를 좌우하는 매우 중요한 요소입니다. Backtracking을 하기 위해서는 이 matching order가 필요한데, 이후 백트래킹을 수행하는 순서 (정의상 $q_V$의 permutation) 를 matching order라고 부릅니다. 알고리즘마다 다른 matching order를 사용하게 됩니다. Backtracking 백트래킹은 단순히 하면 되지만, 이 과정에서 다양한 최적화가 가능합니다. 먼저 백트래킹을 위해서는 extendable한 candidate를 잡아야 하는데… 현재의 partial embedding $M$에서 사용했던 점들은 다시 사용할 수 없고 지금 내가 $u$를 보고 있다면, $u$의 neighbor들 중 $M$에서 이미 매핑된 정점들에 대해, 그 정점들 모두와 연결이 가능해야 합니다. 즉, $u_3$이 $u_1$, $u_2$ 와 연결되어 있고, $u_1, u_2$를 각각 $v_a, v_b$와 연결되어 있으면, $u_3$은 적어도 $v_a, v_b$와 연결된 점들 중에 골라야 한다는 것입니다. 이 두가지가 가장 기본이 됩니다. 여기서 추가로 DAF의 경우 Failing set과 같은 최적화 기법들을 제시하기도 했습니다. References / Papers Sun, S., &amp;amp; Luo, Q. (2020). In-Memory Subgraph Matching: An In-depth Study. Proceedings of the ACM SIGMOD International Conference on Management of Data, 1083–1098. https://doi.org/10.1145/3318464.3380581 : Subgraph Isomorphism 방법들을 비교하고, 이들을 모두 구현하여 통일된 프레임워크 위에서 실험한 논문입니다. 이 글은 거의 이 논문에 기반한 정리 포스팅인데, 논문의 메인인 실험 결과를 정리하지 않았기 때문에 그렇게 분류해놓지는 않았습니다. 이부분의 증명은 이 글의 Scope를 너무 많이 벗어납니다. &amp;#8617;</summary></entry><entry><title type="html">논문읽기 : DELTACON</title><link href="http://localhost:4000/cs-adventure/deltacon/" rel="alternate" type="text/html" title="논문읽기 : DELTACON" /><published>2021-09-10T00:00:00+09:00</published><updated>2021-09-10T00:00:00+09:00</updated><id>http://localhost:4000/cs-adventure/deltacon</id><content type="html" xml:base="http://localhost:4000/cs-adventure/deltacon/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#introduction&quot; id=&quot;markdown-toc-introduction&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#key-ideas&quot; id=&quot;markdown-toc-key-ideas&quot;&gt;Key Ideas&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#concepts&quot; id=&quot;markdown-toc-concepts&quot;&gt;Concepts&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#similarity-measure-properties&quot; id=&quot;markdown-toc-similarity-measure-properties&quot;&gt;Similarity measure properties&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#deltacon-algorithm&quot; id=&quot;markdown-toc-deltacon-algorithm&quot;&gt;DELTACON Algorithm&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#scalability&quot; id=&quot;markdown-toc-scalability&quot;&gt;Scalability&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#conclusion&quot; id=&quot;markdown-toc-conclusion&quot;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thoughts&quot; id=&quot;markdown-toc-thoughts&quot;&gt;Thoughts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;Koutra, D., Vogelstein, J. T., &amp;amp; Faloutsos, C. (2013). DeltaCon : A Principled Massive-Graph Similarity Function. Proceedings of the 2013 SIAM International Conference on Data Mining, 10(3), 162–170. https://doi.org/10.1137/1.9781611972832.18&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;이번에 정리할 논문은 &lt;strong&gt;DELTACON&lt;/strong&gt; 이라는 Graph similarity metric을 제시한, DELTACON: A Principled Massive-Graph Similarity Function으로, 2013년 SIAM International Conference on Data Mining에 발표된 논문입니다. (SIAM과 IEEE에서 진행하는 똑같은 이름의 Conference가 있어서, 이쪽을 보통 SDM으로 약칭합니다). 이 논문에서는 그래프 유사도가 만족해야 할 기본적인 기준들을 제시하고, 그 기준에 맞는 실제 유사도 메트릭을 제시하였습니다.&lt;/p&gt;

&lt;p&gt;두 그래프 $G_1 = (V_1, E_1), G_2 = (V_2, E_2)$ 가 주어졌을 때, 우리는 두 그래프의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;유사도&lt;/code&gt; 를 측정하는 어떤 좋은 메트릭을 갖고 싶습니다. 예를 들어, 큰 그래프 $G$가 시간의 흐름에 따라 변화한다면 - 즉, $G_1, \dots G_n$ 에 대해서, $d(G_i, G_{i-1})$ 이 최대인 시점 $i$를 확인하면 anomally를 알 수 있을 것입니다. 이 논문에서는 Node correspondence까지 주어진 상황에서의 그래프 유사도에 대해서만 다룹니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;key-ideas&quot;&gt;Key Ideas&lt;/h1&gt;
&lt;h2 id=&quot;concepts&quot;&gt;Concepts&lt;/h2&gt;
&lt;p&gt;뭔가 노드 간의 연결관계를 수치화해서 알고 있다면, 이를 비교할 수 있을 것 같습니다. 예를 들어, Random walk with Restart 같은 방법을 이용 (이 방법에 대한 설명은 Advanced-algorithm 쪽으로 제가 포스팅한 적이 있습니다. &lt;a href=&quot;/advanced-algorithms/random-walk-on-graphs/&quot;&gt;링크&lt;/a&gt;) 하여, 노드간의 연결정도를 행렬로 만들어 놨다면 이 행렬이 그래프의 어떤 구조를 가지고 있다고 볼 수 있습니다.&lt;/p&gt;

&lt;p&gt;이 논문에서는, RwR은 아니고 이보다 좀더 최신이며 여러 좋은 성질을 갖는 Fast Belief Propagation이라는 방법을 사용합니다. 이 방법을 사용할 때, 노드 간의 연결성을 포함하는 $n \times n$ 행렬은 다음과 같이 계산됩니다. 
\(S = [s_{ij}] = \left(I + \epsilon^2 D - \epsilon A\right)^{-1}\)
여기서, $A$는 그래프의 인접행렬을, $D$는 노드 $i$의 degree를 $d_{ii}$로 하는 대각행렬을 사용합니다.&lt;/p&gt;

&lt;h2 id=&quot;similarity-measure-properties&quot;&gt;Similarity measure properties&lt;/h2&gt;
&lt;p&gt;이 논문에서는 다음과 같은 몇가지 성질들을 &lt;strong&gt;Graph Similarity Measure&lt;/strong&gt;가 가져야 할 성질들이라고 주장합니다. 상당수가 우리의 직관에 기반하였기 때문에 자연스럽게 이해할 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Identity&lt;/strong&gt; : $sim(G, G) = 1$. 매우 자연스럽습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Symmetry&lt;/strong&gt; : $sim(G_1, G_2) = sim(G_2, G_1)$. 역시 매우 자연스럽습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zero Property&lt;/strong&gt; : Complete graph $K_n$ 과 Vertex $n$개에 edge는 하나도 없는 zero graph $Z_n$을 생각해 보겠습니다. 이때, $d(K_n, Z_n) \to 0$ as $n \to \infty$ 를 원합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Edge Importance&lt;/strong&gt; : Edge가 달라지는 변화들 중, connected component의 개수가 바뀌면 특히 더 큰 차이로 간주합니다. 즉, $K_n$ 과 $K_n$을 edge 하나로 이어놓은 그래프에서 bridge는 다른 edge들보다 더 중요합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Weight Awareness&lt;/strong&gt; : Weighted graph에서, weight이 큰 edge에서 일어나는 변화는 더 중요합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Submodularity&lt;/strong&gt; : 같은 크기의 그래프에서, edge 하나의 중요도는 dense graph에서가 sparse graph에서보다 덜 중요합니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Focus Awareness&lt;/strong&gt; : 그래프에서 edge들에 변화 (추가 또는 제거) 가 이루어질 때, 한 점을 노리고 한쪽에 집중된 변화는 랜덤한 변화보다 더 중요합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;deltacon-algorithm&quot;&gt;DELTACON Algorithm&lt;/h2&gt;
&lt;p&gt;DELTACON은 앞서 제시한 행렬 $S$를 이용, 다음과 같은 distance를 계산합니다. 
\(d(G_1, G_2) = \sqrt{\sum_{i = 1}^{n} \sum_{j = 1}^{n} \left(\sqrt{S_1(i, j)} - \sqrt{S_2(i, j)}\right)^2}\)
행렬간의 거리가 굉장히 특이하게 정의되는데, 이를 Jefries-Matusita distance 라고 부른다고 합니다. 루트의 차를 제곱하는 신기한 방식으로 동작하는데, 일반적인 Euclidean distance와는 달리 이 distance를 사용할 때 위 &lt;strong&gt;성질들&lt;/strong&gt; 을 잘 만족합니다. 이 부분은 이 논문에서 수학적으로 엄밀하게 논증되지는 않았고, 데이터 그래프에 대해 실험적으로 검증되었습니다.&lt;/p&gt;

&lt;p&gt;우리는 그래프 유사도를 $[0, 1]$ 에 집어넣고 싶기 때문에, $sim(G_1, G_2) = \frac{1}{1 + d(G_1, G_2)}$ 를 사용합니다.&lt;/p&gt;

&lt;p&gt;이 sim 함수를 DELTACON이라고 부릅니다.&lt;/p&gt;

&lt;h2 id=&quot;scalability&quot;&gt;Scalability&lt;/h2&gt;
&lt;p&gt;Anomally detection 등에 쓰인다는 것을 통해 알 수 있듯이, 그래프 유사도는 많은 수의 그래프를 대상으로 해야 할 수도 있기 때문에, 가능한 빨라야 합니다.&lt;/p&gt;

&lt;p&gt;Deltacon 알고리즘에서 가장 오래 걸리는 부분은 $S$행렬의 계산입니다. $S$행렬은 $S = [s_{ij}] = \left(I + \epsilon^2 D - \epsilon A\right)^{-1}$ 와 같이 역행렬로 정의되는데, 일반적인 matrix가 아니라 특수한 graph structure가 있기 때문에 FaBP 알고리즘을 이용하여 $O(n^2)$ 시간에 계산할 수 있다고 합니다. 이후의 Matusita distance는 당연히 $O(n^2)$에 계산 가능하므로, 이 알고리즘은 $O(n^2)$ 입니다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 DELTACON의 좀더 빠르게 작동하는 approximation 버전을 제시하고 있습니다. $n^2$보다 빠르게 하기 위해서는, Matusita distance 계산이 일단 $O(n^2)$ 시간은 무조건 걸리기 때문에 행렬 자체를 줄여야 합니다. 이를 위해, affinity를 계산하기는 하는데 노드 $i$에 대해 모든 노드 $j$의 affinity가 아닌, 노드를 적당히 묶어 $g$개의 그룹으로 만들어서 $i$에서 $j$번 그룹으로의 affinity를 계산합니다. 이는 즉, $S$행렬에서 임의로 열들을 $g$개의 group으로 묶어서 더함으로써 $n \times g$행렬을 묶는다는 것입니다. $g$를 충분히 작게 하고, 구현을 잘 하면 이 알고리즘을 edge 개수에 대해 linear하게 돌게 할 수 있다고 합니다.&lt;/p&gt;

&lt;p&gt;이때, 이렇게 approximate한 similarity는 항상 실제 similarity보다 큰 값을 갖습니다. (증명은 부록에만 수록되어 있으며, 그렇게 어렵지는 않습니다. 증명이 공개된 링크를 첨부합니다. &lt;a href=&quot;https://web.eecs.umich.edu/~dkoutra/papers/DeltaCon_KoutraVF_withAppendix.pdf&quot;&gt;링크&lt;/a&gt;)&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;DELTACON은 무엇보다 Graph Similarity Measure가 가져야 할 좋은 성질들을 (정성적으로나마) 제시하였고, 이 성질들을 만족하는 실제 similarity measure를 찾아냈으며, 실험적으로 이를 검증하였다는 의의가 있습니다. 특히 다른 Similarity measure (Graph edit distance, spectral methods 등) 들은 이러한 그래프에 대한 직관적인 성질들이 전혀 고려되지 않았는데, 이런 유사도들에 비해 DELTACON이 얼마나 제시한 조건들을 잘 맞추는지를 상당히 extensive한 실험을 통해 검증하였습니다. 특히 Graph edit distance 등 계산 시간이 굉장히 오래 걸리는 알고리즘들에 비해, exact도 quadratic이고 이를 edge 개수에 선형이 되게 더 개선했기 때문에 다양한 활용이 가능할 것 같습니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;thoughts&quot;&gt;Thoughts&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Graph의 노드 대신 edge에 label이 주어진다면, 이를 자연스럽게 확장할 수 있을까요?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;실험적 검증을 넘어서서, 성질들을 수식으로 표현하고 논증하는 방법은 없을까요?
    &lt;ul&gt;
      &lt;li&gt;부록에는 Edge importance 성질과 zero property에 대해서는 증명하고 있으며, 나머지 성질들에 대해서는 &lt;strong&gt;interesting future work&lt;/strong&gt; 라고 남겨두었습니다.&lt;/li&gt;
      &lt;li&gt;Focus Awareness와 같은 성질들이 문제인데.. 잠깐 생각해보면, edge 하나가 변화할 때, 각 점 $i$에 대해 새로 생긴/제거된 edge까지의 거리를 잴 수 있습니다. 이 거리를 $x_i$라고 하면, 변화 $m$번에 대해 행렬 $x_{m, i}$를 생각할 수 있겠습니다. Edge가 한쪽을 타겟팅한다는 것은, $x_{m, i}$의 각 열 - 즉, $m$번의 변화가 이 vertex로부터 얼마의 거리에서 일어나는지를 모은 벡터 - 의 표준편차 같은 통계적인 성질들을 이용하여 측정할 수 있을 것 같기도 합니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Edge 하나가 변화하면서, 변화 전 그래프 $G$와 변화 후 그래프 $G’$간의 deltacon similarity 또는 그 근사값을 측정하는 더 빠른 방법은 없을까요? 바뀌는 edge가 1개인데 $n^2$ 이나 $n$ 시간을 지불하기는 좀 아깝습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Zero Property에서, $d(K_n, G_n)$ 이 항상 0이 아니라 0으로 수렴한다는 것이 약간 오묘합니다. 전체적으로 그래프 유사도가 크기에 많은 영향을 받는 것 같습니다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;FaBP가 왜 $O(n^2)$ 에 작동하는지는 아직 공부하지 못했습니다. 전반적으로 후반부의 시간 복잡도 증명이 약간 &lt;strong&gt;잘 구현하면 된다&lt;/strong&gt; 는 식으로 쓰여 있고, 엄밀하게 증명되어 있지 않다는 점은 조금 아쉬웠는데, &lt;a href=&quot;https://github.com/ZhenguoChen/DeltaCon&quot;&gt;Github Repo&lt;/a&gt; 에 꽤 읽기 쉬운 코드가 있어서 그럭저럭 납득할 수 있었습니다. Sparse matrix의 성질을 잘 사용하는 것 같습니다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="cs-adventure" /><category term="graph theory" /><summary type="html">Contents</summary></entry><entry><title type="html">Introduction to Optimization / Gradient Descent</title><link href="http://localhost:4000/deep-learning-study/opt-and-gd/" rel="alternate" type="text/html" title="Introduction to Optimization / Gradient Descent" /><published>2021-09-03T00:00:00+09:00</published><updated>2021-09-03T00:00:00+09:00</updated><id>http://localhost:4000/deep-learning-study/opt-and-gd</id><content type="html" xml:base="http://localhost:4000/deep-learning-study/opt-and-gd/">&lt;div id=&quot;toc&quot;&gt;
  &lt;p&gt;Contents&lt;/p&gt;
&lt;/div&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#intro-to-optimization&quot; id=&quot;markdown-toc-intro-to-optimization&quot;&gt;Intro to Optimization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gradient-descent&quot; id=&quot;markdown-toc-gradient-descent&quot;&gt;Gradient Descent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;심층 신경망의 수학적 기초&lt;/strong&gt; 1강 (9월 2일) 에 기반합니다.&lt;/p&gt;

&lt;p&gt;이 문서는 $\LaTeX$를 pandoc으로 변환하여 작성하였기 때문에, 레이아웃 등이 깔끔하지 않을 수 있습니다. 언젠가 pdf 버전의 노트를 공개한다면 그쪽을 참고하면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;intro-to-optimization&quot;&gt;Intro to Optimization&lt;/h2&gt;

&lt;p&gt;우리는 다음과 같은 최적화 문제를 생각한다.&lt;/p&gt;

&lt;p&gt;최적화 문제란, 어떤 Decision variable $x$를 조절하여 Objective function
$f$를 최소화 / 최대화 하는 문제를 말한다. 이때, equality 또는 inequality
constraint (제약조건) 들이 주어질 수 있다. 즉 다음과 같은 형태의 문제들.
\(\underset{x \in \R^p}{\minimize} \ f(x)  \ \subto \  h(x) = 0,\ g(x) \leq 0\)&lt;/p&gt;

&lt;p&gt;어차피 최소화와 최대화는 부호를 바꾸면 동치이므로, 앞으로는 최소화
문제만 생각한다.&lt;/p&gt;

&lt;p&gt;모든 제약 조건을 만족하는 점을 &lt;strong&gt;Feasible point&lt;/strong&gt;라 한다. Feasible
point가 아예 없는 경우 &lt;strong&gt;infeasible&lt;/strong&gt;하다.&lt;/p&gt;

&lt;p&gt;최적화 문제를 Constraint 유무에 따라 Unconstrained / Constrained로
나눈다.&lt;/p&gt;

&lt;p&gt;최적화 문제의 답은 Optimal value $p^\star$ 와 solution $x^\star$를 찾는 것이다.
즉…
\(p^* = \inf \Setcond{f(x)}{x \in \R^n, x \text{ feasible }}, \quad f(x^*) = p^*\)
ML 세팅에서는, $0 \leq p^* &amp;lt; \infty$ 인 경우를 주로 생각한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;예시&lt;/strong&gt; : Curve-Fitting, 즉 입력 데이터 $x_1 \dots x_n$ 과 그 label
$y_1 \dots y_n$에 대해, 입력값과 label의 관계를 찾는 문제. 대표적으로, Least square 문제를 생각할 수 있다. 주어진 입력과 결과를
가장 가깝게 근사하는 일차함수 찾기.&lt;/p&gt;

&lt;p&gt;최적화 문제에서는 극소 (Local minima) 와 최소 (Global minima) 를
생각해야 한다. 일반적으로, non-convex 함수의 global minima를 찾는 것은
어렵다.&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h2&gt;

&lt;p&gt;미분가능한 함수 $f$에 대해, 가장 간단한 unconstrained optimization
problem을 해결하고자 한다. \(\underset{x \in \R^p}{\minimize} \ f(x)\)
ML 세팅에서는 almost everywhere differentiable이면 대충 미분가능하다고
말하는 경우 많음.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm (Gradient Descent)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;임의의 시작점 $x^0 \in \R^p$ 를 잡고, 적절한 $\alpha_k &amp;gt; 0$ 에 대해
다음을 반복한다. \(x^{k+1} = x^k - \alpha_k \nabla{f(x^k)}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;대략의 아이디어&lt;/strong&gt; :
$x^k$ 근처에서 $f$를 테일러 전개하면,
\(f(x) = f(x^k) + \nabla f (x^k)^T (x - x^k) + \order{\norm{x - x^k}^2}\)
즉, $x = x^{k+1} = x^k - \alpha_k \nabla{f(x^k)}$ 대입하면,
\(f(x^{k+1}) = f(x^k) - \alpha_k \norm{\nabla{f(x^k)}}^2 + \order{\alpha_k^2}\)
적당히 $\alpha_k$를 충분히 작게 잡으면, $f(x^{k+1})$ 이 $f(x^k)$보다
작게 할 수 있을 것 같다.&lt;/p&gt;

&lt;p&gt;일반적으로, Gradient Descent는 Global 한 최적해를 보장하지 않는다.
Local한 최적해를 찾아간다는 것도 일반적인 조건에서는 안 되고… 대신에,
조건이 충분히 좋으면 거의 비슷한 명제, $\nabla f(x^k) \to 0$ 을 보일 수
있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;정리 (Gradient Descent의 수렴성)&lt;/strong&gt;&lt;br /&gt;
$f : \R^n \to \R$ 이 미분가능하고, $\nabla f$ 가 $L$-Lipschitz 연속이며,
$f$가 $-\infty$가 아닌 최소값을 가질 때, Gradient descent
\(x^{k+1} = x^k - \alpha \nabla{f(x^k)}\) 은,
$\alpha \in \left(0, \frac{2}{L}\right)$에 대해, $\nabla f(x^k) \to 0$
을 보장한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt;
$L$-Lipschitz 조건이 필요한 이유는, $\nabla f$ 가 적당히 smooth 해야
테일러 전개의 근사가 잘 맞기 때문.&lt;/p&gt;

&lt;p&gt;이 생각을 보조정리로 활용한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lemma (Lipschitz Gradient Lemma)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$f : \R^n \to R$ 이 미분가능하고, $\nabla f$ 가 $L$-Lipschitz 연속이면, 다음이 성립한다.
\(f(x + \delta) \leq f(x) + \nabla f(x)^T \delta + \frac{L}{2}\norm{\delta}^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lemma의 증명(살짝 Rough하게)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$g(t) = f(x + t\delta)$ 로 두면, $g’(t) = \nabla f(x + t\delta)^T \delta$ 가 된다. 이때 $g’$는 직접
계산해 보면 $L\norm{\delta}^2$-Lipschitz 임을 알 수 있다.&lt;/li&gt;
  &lt;li&gt;이제, $f(x + \delta) = g(1)$ 은, 다음과 같이 계산한다.
\(f(x + \delta) = g(1) = g(0) + \int_{0}^{1} g'(t) \dd{t} \leq f(x) + \int_{0}^{1} (g'(0) + L\norm{\delta}^2 t) \dd{t} = f(x) + \nabla f(x)^T \delta + \frac{L}{2}\norm{\delta}^2\)&lt;/li&gt;
  &lt;li&gt;따라서 주어진 부등식이 성립한다. ◻&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;수학적으로 깔끔하게 증명하기 위해, 보조정리를 하나 더 쓰자.&lt;br /&gt;
&lt;strong&gt;Lemma (Summability Lemma)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Non-negative sequence $V_i$, $S_i$ 가 $V_{k+1} \leq V_k - S_k$ 를 만족할 때, $S_k \to 0$ 이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lemma의 증명&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$V_{k+1} + \sum_{i = 0}^{k} S_i \leq V_0$에서, $k \to \infty$ 를 취하면, $\sum_{i = 0}^{\infty} S_i \leq V_0 &amp;lt; \infty$ 이다. 급수가 수렴할 때, 일반항이 0으로 수렴함이 알려져 있으므로, 주어진 명제가 성립한다. ◻&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 마지막으로 앞선 정리 - Gradient Descent의 수렴성 비슷한 정리 - 를 증명한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Lipchitz Gradient Lemma에 의해, $f(x^{k+1}) \leq f(x^k) - \alpha\left(1 - \frac{\alpha L}{2}\right)\norm{\nabla(x^k)}^2$ 이다.&lt;/li&gt;
  &lt;li&gt;또한, $V_k = f(x^k) - f(x^\star)$, $S_k = \alpha\left(1 - \frac{\alpha L}{2}\right)\norm{\nabla(x^k)}^2$ 라 하면, 주어진 수열들이 음수가 아니며 Summability Lemma의 조건을 만족함을 안다. 따라서, $S_k \to 0$, 즉 $\norm{\nabla(x^k)}^2 \to 0$ 이므로 $\nabla f(x^k) \to 0$ 이다. ◻&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Wonseok Shin</name><email>gratus907@snu.ac.kr</email></author><category term="deep-learning-study" /><summary type="html">Contents</summary></entry></feed>